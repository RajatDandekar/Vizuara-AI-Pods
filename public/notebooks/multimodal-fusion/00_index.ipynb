{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Multimodal Fusion Architectures \u2014 Notebook Index \u2014 Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\u2705 GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "print(f\"\\n\ud83d\udce6 Python {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udd25 PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\ud83c\udfb2 Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Fusion Architectures \u2014 Notebook Series\n",
    "\n",
    "*Vizuara AI*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "This series of 3 notebooks will take you from the fundamentals of multimodal fusion all the way to building real vision-language architectures (LLaVA, Flamingo) and training them with contrastive learning.\n",
    "\n",
    "Each notebook is self-contained and can be run independently in Google Colab with a T4 GPU.\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "| # | Notebook | What You Will Build | Time |\n",
    "|---|----------|-------------------|------|\n",
    "| 1 | **Fusion Strategies from First Principles** | Early, Late, and Cross-Attention fusion models trained on a synthetic multimodal task | 45 min |\n",
    "| 2 | **Building LLaVA and Flamingo from Scratch** | Simplified LLaVA and Flamingo architectures for visual question answering on CIFAR-10 | 60 min |\n",
    "| 3 | **Training Multimodal Models** | A mini-CLIP model trained with contrastive loss for zero-shot image retrieval | 50 min |\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic PyTorch (tensors, nn.Module, training loops)\n",
    "- Understanding of Transformer self-attention (recommended but not required -- we explain cross-attention from scratch)\n",
    "- Familiarity with CNNs (convolutions, pooling)\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. Open each notebook in Google Colab\n",
    "2. Run cells sequentially from top to bottom\n",
    "3. Complete the TODO exercises (they have scaffolding and verification cells)\n",
    "4. Reflect on the questions at the end of each notebook"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ready to explore multimodal fusion architectures!\")\n",
    "print(\"Start with Notebook 01: Fusion Strategies from First Principles\")"
   ],
   "id": "cell_3"
  }
 ]
}