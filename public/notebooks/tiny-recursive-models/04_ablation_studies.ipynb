{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Ablation Studies ‚Äî Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1bBtLgEU0TdHr55w7SYOhyDG1BKljPaRc\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/04_00_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Ablation Studies: What Really Matters in Recursive Reasoning?\n",
    "\n",
    "*Part 4 of the Vizuara series on Tiny Recursive Models*\n",
    "*Estimated time: 35 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "We have built and trained a Tiny Recursive Model. It works. But **why** does it work?\n",
    "\n",
    "The TRM paper's ablation study is one of its most valuable contributions. It systematically removes or changes components to reveal which design choices matter and which are just noise. The findings are surprising:\n",
    "\n",
    "- Full backpropagation: **+30.9 percentage points**\n",
    "- MLP over attention (for small grids): **+13.0 points**\n",
    "- More recursion over more layers: **+7.9 points**\n",
    "- EMA: **+7.5 points**\n",
    "\n",
    "In this notebook, you will run these ablation experiments yourself and see firsthand what makes recursive reasoning tick."
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_01_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_01_intuition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "### What Is an Ablation Study?\n",
    "\n",
    "In medicine, \"ablation\" means removing a specific tissue or structure. In machine learning, an ablation study removes or changes one component at a time to measure its contribution.\n",
    "\n",
    "Think of it like debugging a recipe. If your cake tastes amazing, you want to know: Is it the vanilla extract? The extra egg? The longer baking time? You bake the cake multiple times, each time leaving out one ingredient, and compare results.\n",
    "\n",
    "### The Paper's Key Findings (Sudoku-Extreme)\n",
    "\n",
    "| Change | Accuracy Impact |\n",
    "|--------|----------------|\n",
    "| Full backprop (vs 1-step approx) | **+30.9%** |\n",
    "| MLP mixing (vs attention) | **+13.0%** |\n",
    "| 2 layers + more recursion (vs 4 layers) | **+7.9%** |\n",
    "| EMA (vs no EMA) | **+7.5%** |\n",
    "| Two features y+z (vs y only) | Essential |\n",
    "\n",
    "### ü§î Think About This\n",
    "\n",
    "Before running the experiments, make your predictions:\n",
    "1. Will more recursion really beat more layers? It seems counterintuitive...\n",
    "2. Why would a simple MLP beat powerful self-attention?\n",
    "3. How much does the reasoning scratchpad z actually help?\n",
    "\n",
    "Write down your predictions. Then compare them to the experimental results."
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Math\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_02_math.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_02_math"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics (Quick Reference)\n",
    "\n",
    "All the math was covered in Notebooks 2 and 3. Here is a quick reference:\n",
    "\n",
    "**Recursion:**\n",
    "$$z \\leftarrow \\text{net}(x, y, z), \\quad y \\leftarrow \\text{net}(y, z)$$\n",
    "\n",
    "**Prediction loss:** $\\mathcal{L}_{\\text{pred}} = -\\sum_i y_i^{\\text{true}} \\log(\\hat{y}_i)$\n",
    "\n",
    "**Effective depth:** $T \\times (n+1) \\times n_{\\text{layers}}$\n",
    "\n",
    "The key insight for ablations: we keep total training time roughly constant and vary one factor at a time."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Setup\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_03_setup.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_03_setup"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It ‚Äî The Ablation Framework\n",
    "\n",
    "### 4.1 Model and Data Setup"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse components from previous notebooks\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    def forward(self, x):\n",
    "        rms = torch.sqrt(torch.mean(x**2, dim=-1, keepdim=True) + self.eps)\n",
    "        return (x / rms) * self.weight\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        hidden_dim = hidden_dim or dim * 4\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n",
    "\n",
    "class MLPMixer(nn.Module):\n",
    "    def __init__(self, seq_len, dim):\n",
    "        super().__init__()\n",
    "        self.token_mix = nn.Linear(seq_len, seq_len, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.token_mix(x.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.qkv = nn.Linear(dim, 3 * dim, bias=False)\n",
    "        self.out_proj = nn.Linear(dim, dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        B, L, D = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, L, 3, self.n_heads, self.head_dim)\n",
    "        q, k, v = qkv.unbind(dim=2)\n",
    "        q, k, v = q.transpose(1,2), k.transpose(1,2), v.transpose(1,2)\n",
    "        attn = (q @ k.transpose(-2,-1)) * (self.head_dim ** -0.5)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = (attn @ v).transpose(1,2).reshape(B, L, D)\n",
    "        return self.out_proj(out)\n",
    "\n",
    "class TRMLayer(nn.Module):\n",
    "    def __init__(self, dim, seq_len, use_attention=False, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(dim)\n",
    "        self.norm2 = RMSNorm(dim)\n",
    "        self.mixer = SelfAttention(dim, n_heads) if use_attention else MLPMixer(seq_len, dim)\n",
    "        self.ffn = SwiGLU(dim, hidden_dim=dim * 4)\n",
    "    def forward(self, x):\n",
    "        x = x + self.mixer(self.norm1(x))\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AblationTRM(nn.Module):\n",
    "    \"\"\"\n",
    "    TRM with configurable components for ablation studies.\n",
    "\n",
    "    Configurable:\n",
    "    - n_layers: number of layers in the recursive block\n",
    "    - use_attention: MLP vs self-attention mixing\n",
    "    - use_z: whether to use the latent reasoning feature z\n",
    "    - full_backprop: whether to backprop through all recursions or use stop-grad\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=4, grid_size=4, dim=48,\n",
    "                 n_layers=2, use_attention=False, use_z=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.grid_size = grid_size\n",
    "        self.n_classes = n_classes\n",
    "        self.use_z = use_z\n",
    "        seq_len = grid_size * grid_size\n",
    "\n",
    "        # Feature dimension depends on whether we use z\n",
    "        feat_mult = 3 if use_z else 2  # [x, y, z] or [x, y]\n",
    "\n",
    "        self.input_embed = nn.Linear(n_classes + 1, dim, bias=False)\n",
    "        self.y_init = nn.Parameter(torch.randn(1, 1, dim) * 0.02)\n",
    "        if use_z:\n",
    "            self.z_init = nn.Parameter(torch.randn(1, 1, dim) * 0.02)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TRMLayer(dim * feat_mult, seq_len=seq_len, use_attention=use_attention)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.split_proj_y = nn.Linear(dim * feat_mult, dim, bias=False)\n",
    "        if use_z:\n",
    "            self.split_proj_z = nn.Linear(dim * feat_mult, dim, bias=False)\n",
    "        self.output_head = nn.Linear(dim, n_classes)\n",
    "\n",
    "    def embed_input(self, x):\n",
    "        B = x.shape[0]\n",
    "        x_flat = x.reshape(B, -1)\n",
    "        x_onehot = F.one_hot(x_flat.long(), num_classes=self.n_classes + 1).float()\n",
    "        return self.input_embed(x_onehot)\n",
    "\n",
    "    def recurse(self, x_emb, y, z=None):\n",
    "        if self.use_z and z is not None:\n",
    "            combined = torch.cat([x_emb, y, z], dim=-1)\n",
    "        else:\n",
    "            combined = torch.cat([x_emb, y], dim=-1)\n",
    "        for layer in self.layers:\n",
    "            combined = layer(combined)\n",
    "        y_new = self.split_proj_y(combined)\n",
    "        z_new = self.split_proj_z(combined) if self.use_z else None\n",
    "        return y_new, z_new\n",
    "\n",
    "    def forward_with_supervision(self, x, T=3, n=4, full_backprop=True):\n",
    "        B = x.shape[0]\n",
    "        seq_len = self.grid_size * self.grid_size\n",
    "        x_emb = self.embed_input(x)\n",
    "        y = self.y_init.expand(B, seq_len, -1)\n",
    "        z = self.z_init.expand(B, seq_len, -1) if self.use_z else None\n",
    "\n",
    "        checkpoints = []\n",
    "        for t in range(T):\n",
    "            for i in range(n - 1):\n",
    "                if full_backprop:\n",
    "                    y, z = self.recurse(x_emb, y, z)\n",
    "                else:\n",
    "                    # Stop-grad: detach y and z to prevent gradient flow\n",
    "                    y_d = y.detach()\n",
    "                    z_d = z.detach() if z is not None else None\n",
    "                    y, z = self.recurse(x_emb, y_d, z_d)\n",
    "\n",
    "            # Last recursion always has gradients\n",
    "            y, z = self.recurse(x_emb, y, z)\n",
    "            logits = self.output_head(y)\n",
    "            checkpoints.append(logits)\n",
    "\n",
    "        return checkpoints\n",
    "\n",
    "print(\"Ablation model ready!\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Generation"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_4x4(grid, r, c, num):\n",
    "    if num in grid[r, :]: return False\n",
    "    if num in grid[:, c]: return False\n",
    "    box_r, box_c = 2*(r//2), 2*(c//2)\n",
    "    if num in grid[box_r:box_r+2, box_c:box_c+2]: return False\n",
    "    return True\n",
    "\n",
    "def solve_4x4(grid):\n",
    "    for r in range(4):\n",
    "        for c in range(4):\n",
    "            if grid[r, c] == 0:\n",
    "                nums = list(range(1, 5))\n",
    "                np.random.shuffle(nums)\n",
    "                for num in nums:\n",
    "                    if is_valid_4x4(grid, r, c, num):\n",
    "                        grid[r, c] = num\n",
    "                        if solve_4x4(grid): return True\n",
    "                        grid[r, c] = 0\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def generate_dataset(n, n_remove=8, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    puzzles, solutions = [], []\n",
    "    for _ in range(n):\n",
    "        grid = np.zeros((4,4), dtype=np.int64)\n",
    "        solve_4x4(grid)\n",
    "        sol = grid.copy()\n",
    "        idxs = np.random.choice(16, size=n_remove, replace=False)\n",
    "        puz = sol.copy()\n",
    "        for idx in idxs: puz[idx//4, idx%4] = 0\n",
    "        puzzles.append(puz); solutions.append(sol)\n",
    "    return np.array(puzzles), np.array(solutions)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_puz, train_sol = generate_dataset(1000, n_remove=8, seed=42)\n",
    "test_puz, test_sol = generate_dataset(200, n_remove=8, seed=999)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(train_puz), torch.tensor(train_sol)),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(test_puz), torch.tensor(test_sol)),\n",
    "    batch_size=64, shuffle=False\n",
    ")\n",
    "print(f\"Train: {len(train_puz)} puzzles | Test: {len(test_puz)} puzzles\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Unified Training Function"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config, n_epochs=25, verbose=True):\n",
    "    \"\"\"\n",
    "    Run a single ablation experiment.\n",
    "\n",
    "    config: dict with keys:\n",
    "        name, dim, n_layers, use_attention, use_z, T, n, full_backprop, use_ema\n",
    "    \"\"\"\n",
    "    name = config['name']\n",
    "    dim = config.get('dim', 48)\n",
    "    n_layers = config.get('n_layers', 2)\n",
    "    use_attention = config.get('use_attention', False)\n",
    "    use_z = config.get('use_z', True)\n",
    "    T = config.get('T', 3)\n",
    "    n = config.get('n', 4)\n",
    "    full_backprop = config.get('full_backprop', True)\n",
    "    use_ema = config.get('use_ema', True)\n",
    "\n",
    "    model = AblationTRM(\n",
    "        n_classes=4, grid_size=4, dim=dim,\n",
    "        n_layers=n_layers, use_attention=use_attention, use_z=use_z\n",
    "    ).to(device)\n",
    "\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "\n",
    "    # EMA setup\n",
    "    ema_shadow = None\n",
    "    if use_ema:\n",
    "        ema_shadow = {n: p.data.clone() for n, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "    history = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for bx, by in train_loader:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            mask = (bx.reshape(bx.shape[0], -1) == 0)\n",
    "            targets = by.reshape(by.shape[0], -1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            checkpoints = model.forward_with_supervision(bx, T=T, n=n, full_backprop=full_backprop)\n",
    "\n",
    "            loss = 0\n",
    "            for logits in checkpoints:\n",
    "                targets_0idx = (targets - 1).clamp(min=0)\n",
    "                per_elem = F.cross_entropy(logits.reshape(-1, 4), targets_0idx.reshape(-1), reduction='none')\n",
    "                loss = loss + (per_elem * mask.reshape(-1).float()).sum() / mask.float().sum().clamp(min=1)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if use_ema and ema_shadow:\n",
    "                with torch.no_grad():\n",
    "                    for n_param, p in model.named_parameters():\n",
    "                        if p.requires_grad:\n",
    "                            ema_shadow[n_param] = 0.999 * ema_shadow[n_param] + 0.001 * p.data\n",
    "\n",
    "        # Evaluate (with EMA if enabled)\n",
    "        if use_ema and ema_shadow:\n",
    "            backup = {n: p.data.clone() for n, p in model.named_parameters() if p.requires_grad}\n",
    "            for n_param, p in model.named_parameters():\n",
    "                if p.requires_grad: p.data = ema_shadow[n_param]\n",
    "\n",
    "        model.eval()\n",
    "        correct, total, puzzles_correct, puzzles_total = 0, 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for bx, by in test_loader:\n",
    "                bx, by = bx.to(device), by.to(device)\n",
    "                mask = (bx.reshape(bx.shape[0], -1) == 0)\n",
    "                targets = by.reshape(by.shape[0], -1)\n",
    "                checkpoints = model.forward_with_supervision(bx, T=T, n=n, full_backprop=True)\n",
    "                preds = checkpoints[-1].argmax(dim=-1) + 1\n",
    "                c = (preds == targets) & mask\n",
    "                correct += c.sum().item()\n",
    "                total += mask.sum().item()\n",
    "                for i in range(bx.shape[0]):\n",
    "                    m = mask[i]\n",
    "                    if m.sum() > 0:\n",
    "                        puzzles_correct += c[i][m].all().item()\n",
    "                    puzzles_total += 1\n",
    "\n",
    "        if use_ema and ema_shadow:\n",
    "            for n_param, p in model.named_parameters():\n",
    "                if p.requires_grad: p.data = backup[n_param]\n",
    "\n",
    "        cell_acc = 100 * correct / max(total, 1)\n",
    "        puzzle_acc = 100 * puzzles_correct / max(puzzles_total, 1)\n",
    "        history.append(puzzle_acc)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    final_acc = history[-1]\n",
    "\n",
    "    if verbose:\n",
    "        eff_depth = T * (n+1) * n_layers if full_backprop else T * n_layers\n",
    "        print(f\"  {name:<35s} | Params: {n_params:>7,} | Eff.Depth: {eff_depth:>3} | \"\n",
    "              f\"Puzzle Acc: {final_acc:>5.1f}% | Time: {elapsed:.0f}s\")\n",
    "\n",
    "    return {\n",
    "        'name': name, 'final_acc': final_acc, 'n_params': n_params,\n",
    "        'history': history, 'time': elapsed, 'config': config\n",
    "    }"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo Rankings\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_04_todo_rankings.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_04_todo_rankings"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Your Turn: Predict the Rankings\n",
    "\n",
    "Before running the experiments, make your predictions!\n",
    "\n",
    "### TODO: Rank the ablation impacts"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ TODO ============\n",
    "# Based on your understanding from Notebooks 1-3, rank these ablations\n",
    "# from MOST impactful to LEAST impactful (which removal hurts the most?).\n",
    "#\n",
    "# Assign ranks 1-5 (1 = most impactful removal, 5 = least impactful):\n",
    "# ==============================\n",
    "\n",
    "your_rankings = {\n",
    "    'No full backprop':     ???,  # Rank 1-5\n",
    "    'Attention vs MLP':     ???,  # Rank 1-5\n",
    "    '4 layers vs 2+recur':  ???,  # Rank 1-5\n",
    "    'No z feature':         ???,  # Rank 1-5\n",
    "    'No EMA':               ???,  # Rank 1-5\n",
    "}\n",
    "\n",
    "print(\"Your predicted impact rankings (1=most impactful removal):\")\n",
    "for name, rank in sorted(your_rankings.items(), key=lambda x: x[1]):\n",
    "    print(f\"  #{rank}: {name}\")\n",
    "print(\"\\nLet's see if you're right! Running experiments now...\\n\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Experiments\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_05_experiments.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_05_experiments"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Running the Ablation Experiments\n",
    "\n",
    "Now let us run the experiments. We will test 6 configurations:"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"  ABLATION STUDY ‚Äî 4√ó4 Sudoku\")\n",
    "print(\"=\" * 90)\n",
    "print()\n",
    "\n",
    "experiments = [\n",
    "    # Baseline: full TRM configuration\n",
    "    {'name': '1. Full TRM (baseline)',\n",
    "     'n_layers': 2, 'use_attention': False, 'use_z': True,\n",
    "     'T': 3, 'n': 4, 'full_backprop': True, 'use_ema': True},\n",
    "\n",
    "    # Ablation: stop-grad (no full backprop)\n",
    "    {'name': '2. No full backprop (stop-grad)',\n",
    "     'n_layers': 2, 'use_attention': False, 'use_z': True,\n",
    "     'T': 3, 'n': 4, 'full_backprop': False, 'use_ema': True},\n",
    "\n",
    "    # Ablation: attention instead of MLP\n",
    "    {'name': '3. Attention (instead of MLP)',\n",
    "     'n_layers': 2, 'use_attention': True, 'use_z': True,\n",
    "     'T': 3, 'n': 4, 'full_backprop': True, 'use_ema': True},\n",
    "\n",
    "    # Ablation: 4 layers with less recursion\n",
    "    {'name': '4. 4 layers, n=2 recursions',\n",
    "     'n_layers': 4, 'use_attention': False, 'use_z': True,\n",
    "     'T': 3, 'n': 2, 'full_backprop': True, 'use_ema': True},\n",
    "\n",
    "    # Ablation: no z feature\n",
    "    {'name': '5. No z (solution only)',\n",
    "     'n_layers': 2, 'use_attention': False, 'use_z': False,\n",
    "     'T': 3, 'n': 4, 'full_backprop': True, 'use_ema': True},\n",
    "\n",
    "    # Ablation: no EMA\n",
    "    {'name': '6. No EMA',\n",
    "     'n_layers': 2, 'use_attention': False, 'use_z': True,\n",
    "     'T': 3, 'n': 4, 'full_backprop': True, 'use_ema': False},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for config in experiments:\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    result = run_experiment(config, n_epochs=25)\n",
    "    results.append(result)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 90)"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Bar chart of ablation results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "names = [r['name'] for r in results]\n",
    "accs = [r['final_acc'] for r in results]\n",
    "colors = ['#2e7d32'] + ['#ef5350', '#ff9800', '#42a5f5', '#ab47bc', '#78909c']\n",
    "\n",
    "bars = ax.barh(range(len(names)), accs, color=colors, edgecolor='gray', linewidth=1.5, height=0.6)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, acc) in enumerate(zip(bars, accs)):\n",
    "    ax.text(acc + 0.5, i, f'{acc:.1f}%', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_yticks(range(len(names)))\n",
    "ax.set_yticklabels(names, fontsize=11)\n",
    "ax.set_xlabel('Test Puzzle Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Ablation Study: What Matters in TRM?', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim(0, max(accs) + 10)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Curves\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_06_curves.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_06_curves"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Training curves for all experiments\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "colors_line = ['#2e7d32', '#ef5350', '#ff9800', '#42a5f5', '#ab47bc', '#78909c']\n",
    "for result, color in zip(results, colors_line):\n",
    "    ax.plot(result['history'], label=result['name'], linewidth=2, color=color)\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Test Puzzle Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Training Progression Across Ablation Experiments', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9, loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo Custom\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_07_todo_custom.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_07_todo_custom"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üîß Your Turn\n",
    "\n",
    "### TODO: Design Your Own Ablation\n",
    "\n",
    "Choose one hypothesis and test it by designing a new configuration."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ TODO ============\n",
    "# Pick ONE hypothesis and create a config to test it:\n",
    "#\n",
    "# Hypothesis A: \"More recursion always helps\"\n",
    "#   ‚Üí Test n=8 vs n=4 vs n=2 (keep everything else the same)\n",
    "#\n",
    "# Hypothesis B: \"Bigger hidden dimension helps\"\n",
    "#   ‚Üí Test dim=32 vs dim=48 vs dim=64\n",
    "#\n",
    "# Hypothesis C: \"Deep supervision steps matter\"\n",
    "#   ‚Üí Test T=1 vs T=3 vs T=5\n",
    "#\n",
    "# Write your config below:\n",
    "# ==============================\n",
    "\n",
    "my_configs = [\n",
    "    # Example: testing more recursion\n",
    "    {'name': 'Custom: n=2 recursions',\n",
    "     'n_layers': 2, 'use_attention': False, 'use_z': True,\n",
    "     'T': 3, 'n': 2, 'full_backprop': True, 'use_ema': True},\n",
    "\n",
    "    {'name': 'Custom: n=4 recursions (baseline)',\n",
    "     'n_layers': 2, 'use_attention': False, 'use_z': True,\n",
    "     'T': 3, 'n': 4, 'full_backprop': True, 'use_ema': True},\n",
    "\n",
    "    # YOUR CONFIG HERE ‚Äî test n=8 or dim=64 or T=5\n",
    "    ???\n",
    "]\n",
    "\n",
    "print(\"Running your custom ablation...\\n\")\n",
    "my_results = []\n",
    "for config in my_configs:\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    result = run_experiment(config, n_epochs=25)\n",
    "    my_results.append(result)"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification: Plot your results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "for result in my_results:\n",
    "    ax.plot(result['history'], label=result['name'], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Test Puzzle Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Your Custom Ablation Results', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nYour ablation results:\")\n",
    "for r in my_results:\n",
    "    print(f\"  {r['name']}: {r['final_acc']:.1f}%\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Big Picture\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_08_big_picture.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_08_big_picture"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together ‚Äî The Parameter vs Compute Trade-off"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä The big picture: parameters vs accuracy\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Parameters vs accuracy\n",
    "params = [r['n_params'] for r in results]\n",
    "accs = [r['final_acc'] for r in results]\n",
    "colors_scatter = ['#2e7d32', '#ef5350', '#ff9800', '#42a5f5', '#ab47bc', '#78909c']\n",
    "\n",
    "for i, (p, a, c, r) in enumerate(zip(params, accs, colors_scatter, results)):\n",
    "    axes[0].scatter(p, a, c=c, s=200, edgecolors='gray', linewidth=1.5, zorder=5)\n",
    "    axes[0].annotate(r['name'].split('.')[0] + '.',\n",
    "                     (p, a), textcoords=\"offset points\",\n",
    "                     xytext=(10, 5), fontsize=9)\n",
    "\n",
    "axes[0].set_xlabel('Parameters', fontsize=12)\n",
    "axes[0].set_ylabel('Test Puzzle Accuracy (%)', fontsize=12)\n",
    "axes[0].set_title('Parameters vs Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Effective depth vs accuracy\n",
    "eff_depths = []\n",
    "for r in results:\n",
    "    c = r['config']\n",
    "    if c['full_backprop']:\n",
    "        ed = c['T'] * (c['n'] + 1) * c['n_layers']\n",
    "    else:\n",
    "        ed = c['T'] * c['n_layers']\n",
    "    eff_depths.append(ed)\n",
    "\n",
    "for i, (d, a, c, r) in enumerate(zip(eff_depths, accs, colors_scatter, results)):\n",
    "    axes[1].scatter(d, a, c=c, s=200, edgecolors='gray', linewidth=1.5, zorder=5)\n",
    "    axes[1].annotate(r['name'].split('.')[0] + '.',\n",
    "                     (d, a), textcoords=\"offset points\",\n",
    "                     xytext=(10, 5), fontsize=9)\n",
    "\n",
    "axes[1].set_xlabel('Effective Depth (layers)', fontsize=12)\n",
    "axes[1].set_ylabel('Test Puzzle Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Effective Depth vs Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('The Parameters vs Compute Trade-off', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Key insight: Effective depth (recursion) matters MORE than parameter count!\")\n",
    "print(\"   The baseline has fewer parameters than config 4 but higher accuracy,\")\n",
    "print(\"   because it achieves greater effective depth through more recursion.\")"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Report\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_09_report.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_09_report"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üéØ Final Output ‚Äî Complete Ablation Report"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a comprehensive ablation report\n",
    "print(\"=\" * 80)\n",
    "print(\"  ABLATION STUDY REPORT ‚Äî Tiny Recursive Models on 4√ó4 Sudoku\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "baseline_acc = results[0]['final_acc']\n",
    "print(f\"  Baseline accuracy: {baseline_acc:.1f}%\")\n",
    "print(f\"  (2 layers, MLP mixing, with z, T=3, n=4, full backprop, EMA)\")\n",
    "print()\n",
    "print(f\"  {'Experiment':<35s} | {'Accuracy':>8s} | {'Œî vs baseline':>13s} | {'Key finding'}\")\n",
    "print(\"  \" + \"-\" * 100)\n",
    "\n",
    "findings = [\n",
    "    \"Reference configuration\",\n",
    "    \"Full backprop is critical for learning\",\n",
    "    \"MLP beats attention on small fixed grids\",\n",
    "    \"More recursion > more layers\",\n",
    "    \"Reasoning scratchpad z is essential\",\n",
    "    \"EMA stabilizes training\"\n",
    "]\n",
    "\n",
    "for r, finding in zip(results, findings):\n",
    "    delta = r['final_acc'] - baseline_acc\n",
    "    delta_str = f\"{'+'if delta>=0 else ''}{delta:.1f}%\"\n",
    "    print(f\"  {r['name']:<35s} | {r['final_acc']:>7.1f}% | {delta_str:>13s} | {finding}\")\n",
    "\n",
    "print()\n",
    "print(\"  \" + \"=\" * 100)\n",
    "print()\n",
    "\n",
    "# Rank by impact\n",
    "impacts = [(r['name'], baseline_acc - r['final_acc'], findings[i])\n",
    "           for i, r in enumerate(results[1:])]\n",
    "impacts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"  Components ranked by impact (removing each one):\")\n",
    "for name, impact, finding in impacts:\n",
    "    if impact > 0:\n",
    "        print(f\"    {impact:+.1f}% ‚Äî {name}: {finding}\")\n",
    "    else:\n",
    "        print(f\"    {impact:+.1f}% ‚Äî {name}: {finding}\")"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Final visualization: impact bar chart\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "names_short = [\n",
    "    'No full backprop',\n",
    "    'Attention\\n(vs MLP)',\n",
    "    '4 layers\\n(vs 2+recursion)',\n",
    "    'No z feature',\n",
    "    'No EMA'\n",
    "]\n",
    "impacts_val = [baseline_acc - r['final_acc'] for r in results[1:]]\n",
    "bar_colors = ['#ef5350' if v > 0 else '#66bb6a' for v in impacts_val]\n",
    "\n",
    "bars = ax.bar(range(len(names_short)), impacts_val, color=bar_colors,\n",
    "              edgecolor='gray', linewidth=1.5, width=0.6)\n",
    "\n",
    "for bar, val in zip(bars, impacts_val):\n",
    "    y_pos = bar.get_height() + 0.3 if val > 0 else bar.get_height() - 1\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, y_pos,\n",
    "            f'{val:+.1f}%', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(range(len(names_short)))\n",
    "ax.set_xticklabels(names_short, fontsize=10)\n",
    "ax.set_ylabel('Accuracy Drop (percentage points)', fontsize=12)\n",
    "ax.set_title('Impact of Removing Each Component\\n(Higher = More Important)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ Congratulations! You have completed the ablation study.\")\n",
    "print(\"   You now understand WHY each component of TRM matters, not just WHAT it does.\")\n",
    "print(f\"\\n   The key lesson: recursive depth (thinking longer) beats parameter count (thinking bigger).\")"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_10_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_10_closing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reflection and Next Steps\n",
    "\n",
    "### üí° Key Takeaways\n",
    "\n",
    "1. **Full backpropagation** is the single most important factor ‚Äî it enables the model to learn from the full recursion chain\n",
    "2. **MLP mixing** beats attention for small, fixed-size grids ‚Äî simpler is better when the context fits in a small matrix\n",
    "3. **More recursion with fewer layers** beats more layers with less recursion ‚Äî computational depth without parameter growth\n",
    "4. **The reasoning scratchpad z** is essential for generalization ‚Äî the model needs internal state that is not directly part of the answer\n",
    "5. **EMA** provides stability, especially on small datasets\n",
    "\n",
    "### ü§î Reflection Questions\n",
    "\n",
    "1. Why does removing full backpropagation hurt so much? (Hint: think about what the model can learn from 1-step gradients vs multi-step gradients.)\n",
    "2. The paper's Sudoku-Extreme results show +30.9% from full backprop ‚Äî much larger than our 4√ó4 result. Why would the impact be larger on harder puzzles?\n",
    "3. If you had unlimited compute but only 1,000 training examples, how would you design the TRM? What T, n, and n_layers would you choose?\n",
    "\n",
    "### üèÜ Optional Challenges\n",
    "\n",
    "1. **Recursion budget ablation:** Fix the total number of forward passes (e.g., 12) and vary the split between T and n. Is T=3, n=4 optimal, or would T=2, n=6 be better?\n",
    "2. **Data efficiency:** Train with 100, 500, and 1000 examples. At what data size does EMA stop helping?\n",
    "3. **Transfer learning:** Train on easy puzzles (4 empty cells), then fine-tune on hard puzzles (10 empty cells). Does pre-training help?\n",
    "\n",
    "### Series Summary\n",
    "\n",
    "Across these 4 notebooks, you have:\n",
    "1. **Understood** recursive reasoning through constraint propagation\n",
    "2. **Built** the complete TRM architecture from scratch (RMSNorm, SwiGLU, RoPE, MLP/Attention variants)\n",
    "3. **Trained** TRM with deep supervision, prediction loss, halting loss, and EMA\n",
    "4. **Validated** each design choice through systematic ablation experiments\n",
    "\n",
    "The central lesson of Tiny Recursive Models: **Less is More.** A tiny model that thinks recursively outperforms giant models that think once. Recursive depth beats parameter count. Thinking longer beats thinking bigger."
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "chatbot"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üí¨ AI Teaching Assistant ‚Äî Click ‚ñ∂ to start\n",
    "#@markdown This AI chatbot reads your notebook and can answer questions about any concept, code, or exercise.\n",
    "\n",
    "import json as _json\n",
    "import requests as _requests\n",
    "from google.colab import output as _output\n",
    "from IPython.display import display, HTML as _HTML, Markdown as _Markdown\n",
    "\n",
    "# --- Read notebook content for context ---\n",
    "def _get_notebook_context():\n",
    "    try:\n",
    "        from google.colab import _message\n",
    "        nb = _message.blocking_request(\"get_ipynb\", request=\"\", timeout_sec=10)\n",
    "        cells = nb.get(\"ipynb\", {}).get(\"cells\", [])\n",
    "        parts = []\n",
    "        for cell in cells:\n",
    "            src = \"\".join(cell.get(\"source\", []))\n",
    "            tags = cell.get(\"metadata\", {}).get(\"tags\", [])\n",
    "            if \"chatbot\" in tags:\n",
    "                continue\n",
    "            if src.strip():\n",
    "                ct = cell.get(\"cell_type\", \"unknown\")\n",
    "                parts.append(f\"[{ct.upper()}]\\n{src}\")\n",
    "        return \"\\n\\n---\\n\\n\".join(parts)\n",
    "    except Exception:\n",
    "        return \"Notebook content unavailable.\"\n",
    "\n",
    "_NOTEBOOK_CONTEXT = _get_notebook_context()\n",
    "_CHAT_HISTORY = []\n",
    "_API_URL = \"https://course-creator-brown.vercel.app/api/chat\"\n",
    "\n",
    "def _notebook_chat(question):\n",
    "    global _CHAT_HISTORY\n",
    "    try:\n",
    "        resp = _requests.post(_API_URL, json={\n",
    "            'question': question,\n",
    "            'context': _NOTEBOOK_CONTEXT[:100000],\n",
    "            'history': _CHAT_HISTORY[-10:],\n",
    "        }, timeout=60)\n",
    "        data = resp.json()\n",
    "        answer = data.get('answer', 'Sorry, I could not generate a response.')\n",
    "        _CHAT_HISTORY.append({'role': 'user', 'content': question})\n",
    "        _CHAT_HISTORY.append({'role': 'assistant', 'content': answer})\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f'Error connecting to teaching assistant: {str(e)}'\n",
    "\n",
    "_output.register_callback('notebook_chat', _notebook_chat)\n",
    "\n",
    "def ask(question):\n",
    "    \"\"\"Ask the AI teaching assistant a question about this notebook.\"\"\"\n",
    "    answer = _notebook_chat(question)\n",
    "    display(_Markdown(answer))\n",
    "\n",
    "print(\"\\u2705 AI Teaching Assistant is ready!\")\n",
    "print(\"\\U0001f4a1 Use the chat below, or call ask(\\'your question\\') in any cell.\")\n",
    "\n",
    "# --- Display chat widget ---\n",
    "display(_HTML('''<style>\n  .vc-wrap{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;max-width:100%;border-radius:16px;overflow:hidden;box-shadow:0 4px 24px rgba(0,0,0,.12);background:#fff;border:1px solid #e5e7eb}\n  .vc-hdr{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:16px 20px;display:flex;align-items:center;gap:12px}\n  .vc-avatar{width:42px;height:42px;background:rgba(255,255,255,.2);border-radius:50%;display:flex;align-items:center;justify-content:center;font-size:22px}\n  .vc-hdr h3{font-size:16px;font-weight:600;margin:0}\n  .vc-hdr p{font-size:12px;opacity:.85;margin:2px 0 0}\n  .vc-msgs{height:420px;overflow-y:auto;padding:16px;background:#f8f9fb;display:flex;flex-direction:column;gap:10px}\n  .vc-msg{display:flex;flex-direction:column;animation:vc-fade .25s ease}\n  .vc-msg.user{align-items:flex-end}\n  .vc-msg.bot{align-items:flex-start}\n  .vc-bbl{max-width:85%;padding:10px 14px;border-radius:16px;font-size:14px;line-height:1.55;word-wrap:break-word}\n  .vc-msg.user .vc-bbl{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border-bottom-right-radius:4px}\n  .vc-msg.bot .vc-bbl{background:#fff;color:#1a1a2e;border:1px solid #e8e8e8;border-bottom-left-radius:4px}\n  .vc-bbl code{background:rgba(0,0,0,.07);padding:2px 6px;border-radius:4px;font-size:13px;font-family:'Fira Code',monospace}\n  .vc-bbl pre{background:#1e1e2e;color:#cdd6f4;padding:12px;border-radius:8px;overflow-x:auto;margin:8px 0;font-size:13px}\n  .vc-bbl pre code{background:none;padding:0;color:inherit}\n  .vc-bbl h3,.vc-bbl h4{margin:10px 0 4px;font-size:15px}\n  .vc-bbl ul,.vc-bbl ol{margin:4px 0;padding-left:20px}\n  .vc-bbl li{margin:2px 0}\n  .vc-chips{display:flex;flex-wrap:wrap;gap:8px;padding:0 16px 12px;background:#f8f9fb}\n  .vc-chip{background:#fff;border:1px solid #d1d5db;border-radius:20px;padding:6px 14px;font-size:12px;cursor:pointer;transition:all .15s;color:#4b5563}\n  .vc-chip:hover{border-color:#667eea;color:#667eea;background:#f0f0ff}\n  .vc-input{display:flex;padding:12px 16px;background:#fff;border-top:1px solid #eee;gap:8px}\n  .vc-input input{flex:1;padding:10px 16px;border:2px solid #e8e8e8;border-radius:24px;font-size:14px;outline:none;transition:border-color .2s}\n  .vc-input input:focus{border-color:#667eea}\n  .vc-input button{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border:none;border-radius:50%;width:42px;height:42px;cursor:pointer;display:flex;align-items:center;justify-content:center;font-size:18px;transition:transform .1s}\n  .vc-input button:hover{transform:scale(1.05)}\n  .vc-input button:disabled{opacity:.5;cursor:not-allowed;transform:none}\n  .vc-typing{display:flex;gap:5px;padding:4px 0}\n  .vc-typing span{width:8px;height:8px;background:#667eea;border-radius:50%;animation:vc-bounce 1.4s infinite ease-in-out}\n  .vc-typing span:nth-child(2){animation-delay:.2s}\n  .vc-typing span:nth-child(3){animation-delay:.4s}\n  @keyframes vc-bounce{0%,80%,100%{transform:scale(0)}40%{transform:scale(1)}}\n  @keyframes vc-fade{from{opacity:0;transform:translateY(8px)}to{opacity:1;transform:translateY(0)}}\n  .vc-note{text-align:center;font-size:11px;color:#9ca3af;padding:8px 16px 12px;background:#fff}\n</style>\n<div class=\"vc-wrap\">\n  <div class=\"vc-hdr\">\n    <div class=\"vc-avatar\">&#129302;</div>\n    <div>\n      <h3>Vizuara Teaching Assistant</h3>\n      <p>Ask me anything about this notebook</p>\n    </div>\n  </div>\n  <div class=\"vc-msgs\" id=\"vcMsgs\">\n    <div class=\"vc-msg bot\">\n      <div class=\"vc-bbl\">&#128075; Hi! I've read through this entire notebook. Ask me about any concept, code block, or exercise &mdash; I'm here to help you learn!</div>\n    </div>\n  </div>\n  <div class=\"vc-chips\" id=\"vcChips\">\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Explain the main concept</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Help with the TODO exercise</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Summarize what I learned</span>\n  </div>\n  <div class=\"vc-input\">\n    <input type=\"text\" id=\"vcIn\" placeholder=\"Ask about concepts, code, exercises...\" />\n    <button id=\"vcSend\" onclick=\"vcSendMsg()\">&#10148;</button>\n  </div>\n  <div class=\"vc-note\">AI-generated &middot; Verify important information &middot; <a href=\"#\" onclick=\"vcClear();return false\" style=\"color:#667eea\">Clear chat</a></div>\n</div>\n<script>\n(function(){\n  var msgs=document.getElementById('vcMsgs'),inp=document.getElementById('vcIn'),\n      btn=document.getElementById('vcSend'),chips=document.getElementById('vcChips');\n\n  function esc(s){var d=document.createElement('div');d.textContent=s;return d.innerHTML}\n\n  function md(t){\n    return t\n      .replace(/```(\\w*)\\n([\\s\\S]*?)```/g,function(_,l,c){return '<pre><code>'+esc(c)+'</code></pre>'})\n      .replace(/`([^`]+)`/g,'<code>$1</code>')\n      .replace(/\\*\\*([^*]+)\\*\\*/g,'<strong>$1</strong>')\n      .replace(/\\*([^*]+)\\*/g,'<em>$1</em>')\n      .replace(/^#### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^## (.+)$/gm,'<h3>$1</h3>')\n      .replace(/^\\d+\\. (.+)$/gm,'<li>$1</li>')\n      .replace(/^- (.+)$/gm,'<li>$1</li>')\n      .replace(/\\n\\n/g,'<br><br>')\n      .replace(/\\n/g,'<br>');\n  }\n\n  function addMsg(text,isUser){\n    var m=document.createElement('div');m.className='vc-msg '+(isUser?'user':'bot');\n    var b=document.createElement('div');b.className='vc-bbl';\n    b.innerHTML=isUser?esc(text):md(text);\n    m.appendChild(b);msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function showTyping(){\n    var m=document.createElement('div');m.className='vc-msg bot';m.id='vcTyping';\n    m.innerHTML='<div class=\"vc-bbl\"><div class=\"vc-typing\"><span></span><span></span><span></span></div></div>';\n    msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function hideTyping(){var e=document.getElementById('vcTyping');if(e)e.remove()}\n\n  window.vcSendMsg=function(){\n    var q=inp.value.trim();if(!q)return;\n    inp.value='';chips.style.display='none';\n    addMsg(q,true);showTyping();btn.disabled=true;\n    google.colab.kernel.invokeFunction('notebook_chat',[q],{})\n      .then(function(r){\n        hideTyping();\n        var a=r.data['application/json'];\n        addMsg(typeof a==='string'?a:JSON.stringify(a),false);\n      })\n      .catch(function(){\n        hideTyping();\n        addMsg('Sorry, I encountered an error. Please check your internet connection and try again.',false);\n      })\n      .finally(function(){btn.disabled=false;inp.focus()});\n  };\n\n  window.vcAsk=function(q){inp.value=q;vcSendMsg()};\n  window.vcClear=function(){\n    msgs.innerHTML='<div class=\"vc-msg bot\"><div class=\"vc-bbl\">&#128075; Chat cleared. Ask me anything!</div></div>';\n    chips.style.display='flex';\n  };\n\n  inp.addEventListener('keypress',function(e){if(e.key==='Enter')vcSendMsg()});\n  inp.focus();\n})();\n</script>'''))"
   ],
   "id": "vizuara_chatbot"
  }
 ]
}