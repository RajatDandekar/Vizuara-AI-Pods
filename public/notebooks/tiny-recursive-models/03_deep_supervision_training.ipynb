{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Deep Supervision Training â€” Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"16tyhT-CfPx17iIUy9_IixJPaj2_P5b1I\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/03_00_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Deep Supervision Training: Teaching a Tiny Model to Reason\n",
    "\n",
    "*Part 3 of the Vizuara series on Tiny Recursive Models*\n",
    "*Estimated time: 40 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "In the previous notebook, we built the complete TRM architecture â€” RMSNorm, SwiGLU, RoPE, and the recursion loop. But an untrained model just produces random outputs.\n",
    "\n",
    "The key challenge: **how do you train a recursive model effectively?**\n",
    "\n",
    "The naive approach â€” run all recursions, check only the final answer â€” creates unstable gradients that must flow through dozens of steps. The TRM paper's solution is **deep supervision**: check the model's answer at multiple intermediate points during recursion and provide correction at each.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Implement the prediction loss (cross-entropy) and halting loss (ACT)\n",
    "- Build a deep supervision training loop\n",
    "- Train TRM on 4Ã—4 Sudoku puzzles\n",
    "- **Watch** the model learn to solve puzzles through recursive refinement\n",
    "- Visualize how prediction confidence sharpens across recursion steps"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_01_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_01_intuition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "### Why Deep Supervision?\n",
    "\n",
    "Imagine you are teaching someone to solve Sudoku. Two approaches:\n",
    "\n",
    "**Approach A (End-only supervision):** You let the student work for 30 minutes, then check only the final grid. If it is wrong, you say \"try again\" â€” but they have no idea which of their 30 minutes of work went wrong.\n",
    "\n",
    "**Approach B (Deep supervision):** Every 10 minutes, you check the student's progress. At minute 10, you notice a mistake in row 3 and correct it immediately. At minute 20, the student is on track. At minute 30, the final answer is correct.\n",
    "\n",
    "Approach B is better because:\n",
    "1. **Errors get caught early** â€” before they compound\n",
    "2. **Gradients are shorter** â€” the model only needs to backpropagate through a few steps, not all 18\n",
    "3. **Each checkpoint provides a learning signal** â€” more supervision = faster learning\n",
    "\n",
    "### The Halting Mechanism\n",
    "\n",
    "TRM also learns **when to stop thinking**. For easy puzzles, 2 recursion steps might be enough. For hard ones, you need all 18. The model outputs a \"halting score\" $\\hat{q}$ at each step, estimating whether it already has the correct answer. If $\\hat{q}$ is high, the model can stop recursing early â€” saving computation.\n",
    "\n",
    "### ðŸ¤” Think About This\n",
    "\n",
    "If a model checks its answer at 3 intermediate points (T=3) with 6 recursions between each check (n=6), how many total recursions happen? And how many gradient-carrying steps are there?\n",
    "\n",
    "Answer: 18 total recursions, but only 3 carry gradients (one per supervision step). The other 15 run in `torch.no_grad()` mode â€” they let the model reason freely without the computational overhead of gradient tracking."
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Math\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_02_math.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_02_math"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "### Prediction Loss\n",
    "\n",
    "The prediction loss is standard softmax cross-entropy:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{pred}} = -\\sum_{i} y_i^{\\text{true}} \\log(\\hat{y}_i)$$\n",
    "\n",
    "Computationally: for each cell in the grid, compare the model's predicted probability distribution over classes against the true label. If the model assigns high probability to the correct class, the loss is low.\n",
    "\n",
    "For example, if the true label is class 2 and $\\hat{y} = [0.1, 0.7, 0.2]$:\n",
    "$$\\mathcal{L}_{\\text{pred}} = -\\log(0.7) = 0.357$$\n",
    "\n",
    "### Halting Loss\n",
    "\n",
    "The halting loss is binary cross-entropy:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{halt}} = -[q \\log(\\hat{q}) + (1-q) \\log(1-\\hat{q})]$$\n",
    "\n",
    "Where $q = 1$ if the prediction matches the ground truth (model is correct), and $q = 0$ otherwise. The model outputs $\\hat{q}$ â€” its confidence that it has the right answer.\n",
    "\n",
    "Computationally: this teaches the model to be calibrated about its own correctness. If it has the right answer but $\\hat{q}$ is low (underconfident), the loss pushes $\\hat{q}$ up. If it has the wrong answer but $\\hat{q}$ is high (overconfident), the loss pushes it down.\n",
    "\n",
    "### Total Loss with Deep Supervision\n",
    "\n",
    "At each supervision step $t \\in \\{1, ..., T\\}$:\n",
    "\n",
    "$$\\mathcal{L}_t = \\mathcal{L}_{\\text{pred}}^{(t)} + \\mathcal{L}_{\\text{halt}}^{(t)}$$\n",
    "\n",
    "The total loss sums over all supervision steps:\n",
    "\n",
    "$$\\mathcal{L} = \\sum_{t=1}^{T} \\mathcal{L}_t$$\n",
    "\n",
    "### EMA (Exponential Moving Average)\n",
    "\n",
    "TRM uses EMA to stabilize training â€” maintaining a slow-moving copy of the model weights:\n",
    "\n",
    "$$\\theta_{\\text{EMA}} \\leftarrow \\alpha \\cdot \\theta_{\\text{EMA}} + (1 - \\alpha) \\cdot \\theta$$\n",
    "\n",
    "With $\\alpha = 0.999$. Computationally: after each gradient update, the EMA model weights move 0.1% toward the current model weights. This smooths out training noise, which is critical when training on small datasets."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Model Rebuild\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_03_model_rebuild.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_03_model_rebuild"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It â€” Component by Component\n",
    "\n",
    "### 4.1 Rebuilding the TRM (from Notebook 2)\n",
    "\n",
    "Let us quickly reconstruct the model from the previous notebook."
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
    "        return (x / rms) * self.weight\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        hidden_dim = hidden_dim or dim * 4\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n",
    "\n",
    "class MLPMixer(nn.Module):\n",
    "    def __init__(self, seq_len, dim):\n",
    "        super().__init__()\n",
    "        self.token_mix = nn.Linear(seq_len, seq_len, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.token_mix(x.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "class TRMLayer(nn.Module):\n",
    "    def __init__(self, dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(dim)\n",
    "        self.norm2 = RMSNorm(dim)\n",
    "        self.mixer = MLPMixer(seq_len, dim)\n",
    "        self.ffn = SwiGLU(dim, hidden_dim=dim * 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mixer(self.norm1(x))\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class TinyRecursiveModel(nn.Module):\n",
    "    def __init__(self, n_classes, grid_size, dim=64, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.grid_size = grid_size\n",
    "        self.n_classes = n_classes\n",
    "        seq_len = grid_size * grid_size\n",
    "\n",
    "        self.input_embed = nn.Linear(n_classes + 1, dim, bias=False)\n",
    "        self.y_init = nn.Parameter(torch.randn(1, 1, dim) * 0.02)\n",
    "        self.z_init = nn.Parameter(torch.randn(1, 1, dim) * 0.02)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TRMLayer(dim * 3, seq_len=seq_len) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.split_proj_y = nn.Linear(dim * 3, dim, bias=False)\n",
    "        self.split_proj_z = nn.Linear(dim * 3, dim, bias=False)\n",
    "        self.output_head = nn.Linear(dim, n_classes)\n",
    "        self.halt_head = nn.Linear(dim, 1)\n",
    "\n",
    "    def embed_input(self, x):\n",
    "        B = x.shape[0]\n",
    "        x_flat = x.reshape(B, -1)\n",
    "        x_onehot = F.one_hot(x_flat.long(), num_classes=self.n_classes + 1).float()\n",
    "        return self.input_embed(x_onehot)\n",
    "\n",
    "    def recurse(self, x_emb, y, z):\n",
    "        combined = torch.cat([x_emb, y, z], dim=-1)\n",
    "        for layer in self.layers:\n",
    "            combined = layer(combined)\n",
    "        y_new = self.split_proj_y(combined)\n",
    "        z_new = self.split_proj_z(combined)\n",
    "        return y_new, z_new\n",
    "\n",
    "    def forward_with_supervision(self, x, T=3, n=6):\n",
    "        \"\"\"\n",
    "        Forward pass with deep supervision.\n",
    "\n",
    "        Args:\n",
    "            x: input grid (batch, grid_size, grid_size)\n",
    "            T: number of supervision steps\n",
    "            n: recursions per supervision step\n",
    "\n",
    "        Returns:\n",
    "            List of (logits, halt_logits) at each supervision checkpoint\n",
    "        \"\"\"\n",
    "        B = x.shape[0]\n",
    "        seq_len = self.grid_size * self.grid_size\n",
    "        x_emb = self.embed_input(x)\n",
    "\n",
    "        y = self.y_init.expand(B, seq_len, -1)\n",
    "        z = self.z_init.expand(B, seq_len, -1)\n",
    "\n",
    "        checkpoints = []\n",
    "\n",
    "        for t in range(T):\n",
    "            # Run n-1 recursions WITHOUT gradients (free reasoning)\n",
    "            with torch.no_grad():\n",
    "                for _ in range(n - 1):\n",
    "                    y_detached = y.detach()\n",
    "                    z_detached = z.detach()\n",
    "                    y, z = self.recurse(x_emb, y_detached, z_detached)\n",
    "\n",
    "            # Run 1 recursion WITH gradients (learning step)\n",
    "            y, z = self.recurse(x_emb, y, z)\n",
    "\n",
    "            # Checkpoint: record predictions at this supervision step\n",
    "            logits = self.output_head(y)\n",
    "            halt_logits = self.halt_head(y).squeeze(-1)\n",
    "            checkpoints.append((logits, halt_logits, y.detach()))\n",
    "\n",
    "        return checkpoints\n",
    "\n",
    "print(\"Model architecture loaded successfully!\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Data\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_04_data.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_04_data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Generating Sudoku Training Data\n",
    "\n",
    "We need a dataset of 4Ã—4 Sudoku puzzles with their solutions."
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_4x4(grid, r, c, num):\n",
    "    \"\"\"Check if placing num at (r,c) is valid in a 4x4 Sudoku.\"\"\"\n",
    "    if num in grid[r, :]: return False\n",
    "    if num in grid[:, c]: return False\n",
    "    box_r, box_c = 2 * (r // 2), 2 * (c // 2)\n",
    "    if num in grid[box_r:box_r+2, box_c:box_c+2]: return False\n",
    "    return True\n",
    "\n",
    "def solve_4x4(grid):\n",
    "    \"\"\"Solve a 4x4 Sudoku via backtracking. Returns True if solvable.\"\"\"\n",
    "    for r in range(4):\n",
    "        for c in range(4):\n",
    "            if grid[r, c] == 0:\n",
    "                nums = list(range(1, 5))\n",
    "                np.random.shuffle(nums)\n",
    "                for num in nums:\n",
    "                    if is_valid_4x4(grid, r, c, num):\n",
    "                        grid[r, c] = num\n",
    "                        if solve_4x4(grid):\n",
    "                            return True\n",
    "                        grid[r, c] = 0\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def generate_sudoku_dataset(n_puzzles, n_remove=6, seed=42):\n",
    "    \"\"\"Generate n_puzzles 4x4 Sudoku puzzles with solutions.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    puzzles = []\n",
    "    solutions = []\n",
    "\n",
    "    for _ in range(n_puzzles):\n",
    "        # Generate a full valid grid\n",
    "        grid = np.zeros((4, 4), dtype=np.int64)\n",
    "        solve_4x4(grid)\n",
    "        solution = grid.copy()\n",
    "\n",
    "        # Remove some cells\n",
    "        indices = np.random.choice(16, size=n_remove, replace=False)\n",
    "        puzzle = solution.copy()\n",
    "        for idx in indices:\n",
    "            puzzle[idx // 4, idx % 4] = 0\n",
    "\n",
    "        puzzles.append(puzzle)\n",
    "        solutions.append(solution)\n",
    "\n",
    "    return np.array(puzzles), np.array(solutions)\n",
    "\n",
    "# Generate datasets\n",
    "train_puzzles, train_solutions = generate_sudoku_dataset(1000, n_remove=8, seed=42)\n",
    "test_puzzles, test_solutions = generate_sudoku_dataset(200, n_remove=8, seed=999)\n",
    "\n",
    "print(f\"Training set: {len(train_puzzles)} puzzles\")\n",
    "print(f\"Test set:     {len(test_puzzles)} puzzles\")\n",
    "print(f\"\\nExample puzzle:\")\n",
    "print(train_puzzles[0])\n",
    "print(f\"\\nSolution:\")\n",
    "print(train_solutions[0])\n",
    "print(f\"\\nEmpty cells per puzzle: {np.mean(np.sum(train_puzzles == 0, axis=(1,2))):.1f}\")"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_X = torch.tensor(train_puzzles, dtype=torch.long)\n",
    "train_Y = torch.tensor(train_solutions, dtype=torch.long)\n",
    "test_X = torch.tensor(test_puzzles, dtype=torch.long)\n",
    "test_Y = torch.tensor(test_solutions, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_Y)\n",
    "test_dataset = TensorDataset(test_X, test_Y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches:  {len(test_loader)}\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Todo Loss\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_05_todo_loss.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_05_todo_loss"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 The Loss Functions\n",
    "\n",
    "Now let us implement the prediction loss and halting loss.\n",
    "\n",
    "### TODO: Implement the Prediction Loss"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_loss(logits, targets, mask):\n",
    "    \"\"\"\n",
    "    Softmax cross-entropy loss on masked cells only.\n",
    "\n",
    "    Args:\n",
    "        logits: (batch, seq_len, n_classes) â€” raw predictions\n",
    "        targets: (batch, seq_len) â€” ground truth class indices (1-indexed)\n",
    "        mask: (batch, seq_len) â€” True for cells that were originally empty (need prediction)\n",
    "\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Convert targets from 1-indexed to 0-indexed (subtract 1, clamp min=0)\n",
    "    # Step 2: Reshape logits to (B*L, C) and targets to (B*L,)\n",
    "    # Step 3: Compute F.cross_entropy with reduction='none'\n",
    "    # Step 4: Apply the mask â€” only count loss for empty cells\n",
    "    # Step 5: Return the masked mean loss\n",
    "    # ==============================\n",
    "\n",
    "    # Convert targets from 1-indexed to 0-indexed for cross-entropy\n",
    "    targets_0idx = ???  # YOUR CODE HERE\n",
    "\n",
    "    # Reshape for cross-entropy\n",
    "    B, L, C = logits.shape\n",
    "    logits_flat = logits.reshape(-1, C)\n",
    "    targets_flat = targets_0idx.reshape(-1)\n",
    "    mask_flat = mask.reshape(-1)\n",
    "\n",
    "    # Compute per-element loss\n",
    "    loss = ???  # YOUR CODE HERE\n",
    "\n",
    "    # Only count loss for masked (empty) cells\n",
    "    if mask_flat.sum() > 0:\n",
    "        return (loss * mask_flat.float()).sum() / mask_flat.float().sum()\n",
    "    return loss.mean()"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Verification: test your prediction loss\n",
    "test_logits = torch.randn(2, 16, 4)\n",
    "test_targets = torch.randint(1, 5, (2, 16))\n",
    "test_mask = torch.ones(2, 16).bool()\n",
    "\n",
    "pred_l = prediction_loss(test_logits, test_targets, test_mask)\n",
    "expected_random = np.log(4)  # ~1.386 for random 4-class predictions\n",
    "assert 0.5 < pred_l.item() < 3.0, f\"âŒ Loss {pred_l.item():.3f} seems wrong for random predictions\"\n",
    "print(f\"âœ… Prediction loss (random): {pred_l.item():.3f} (expected ~{expected_random:.3f} for 4 classes)\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Losses\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_06_losses.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_06_losses"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the reference implementation:"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_loss(logits, targets, mask):\n",
    "    \"\"\"\n",
    "    Softmax cross-entropy loss on masked cells only.\n",
    "\n",
    "    Args:\n",
    "        logits: (batch, seq_len, n_classes) â€” raw predictions\n",
    "        targets: (batch, seq_len) â€” ground truth class indices (1-indexed)\n",
    "        mask: (batch, seq_len) â€” True for cells that were originally empty (need prediction)\n",
    "\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    # Convert targets from 1-indexed to 0-indexed for cross-entropy\n",
    "    targets_0idx = (targets - 1).clamp(min=0)  # classes 0..3\n",
    "\n",
    "    # Reshape for cross-entropy\n",
    "    B, L, C = logits.shape\n",
    "    logits_flat = logits.reshape(-1, C)     # (B*L, C)\n",
    "    targets_flat = targets_0idx.reshape(-1)  # (B*L,)\n",
    "    mask_flat = mask.reshape(-1)             # (B*L,)\n",
    "\n",
    "    # Compute per-element loss\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, reduction='none')  # (B*L,)\n",
    "\n",
    "    # Only count loss for masked (empty) cells\n",
    "    if mask_flat.sum() > 0:\n",
    "        return (loss * mask_flat.float()).sum() / mask_flat.float().sum()\n",
    "    return loss.mean()\n",
    "\n",
    "def halting_loss(halt_logits, predictions_correct, mask):\n",
    "    \"\"\"\n",
    "    Binary cross-entropy halting loss.\n",
    "\n",
    "    Args:\n",
    "        halt_logits: (batch, seq_len) â€” raw halting predictions\n",
    "        predictions_correct: (batch, seq_len) â€” 1.0 if prediction matches target, 0.0 otherwise\n",
    "        mask: (batch, seq_len) â€” True for cells that need prediction\n",
    "\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    halt_probs = torch.sigmoid(halt_logits)\n",
    "    # Clamp for numerical stability\n",
    "    halt_probs = halt_probs.clamp(1e-7, 1 - 1e-7)\n",
    "\n",
    "    bce = -(predictions_correct * torch.log(halt_probs) +\n",
    "            (1 - predictions_correct) * torch.log(1 - halt_probs))\n",
    "\n",
    "    mask_float = mask.float()\n",
    "    if mask_float.sum() > 0:\n",
    "        return (bce * mask_float).sum() / mask_float.sum()\n",
    "    return bce.mean()\n",
    "\n",
    "# Test the losses\n",
    "test_logits = torch.randn(2, 16, 4)\n",
    "test_targets = torch.randint(1, 5, (2, 16))\n",
    "test_mask = torch.randint(0, 2, (2, 16)).bool()\n",
    "\n",
    "pred_l = prediction_loss(test_logits, test_targets, test_mask)\n",
    "print(f\"Prediction loss (random): {pred_l.item():.3f}\")\n",
    "print(f\"Expected for 4 classes:   {np.log(4):.3f} (random baseline)\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualize: How cross-entropy loss decreases as confidence increases\n",
    "confidences = np.linspace(0.01, 0.99, 100)\n",
    "losses = -np.log(confidences)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(confidences, losses, linewidth=2.5, color='#e65100')\n",
    "plt.xlabel('Predicted Probability for Correct Class', fontsize=12)\n",
    "plt.ylabel('Cross-Entropy Loss', fontsize=12)\n",
    "plt.title('Loss Decreases as Model Becomes More Confident', fontsize=13, fontweight='bold')\n",
    "plt.axhline(y=-np.log(0.25), color='#999', linestyle='--', label=f'Random baseline (4 classes): {-np.log(0.25):.2f}')\n",
    "plt.axhline(y=-np.log(0.7), color='#2e7d32', linestyle='--', label=f'70% confidence: {-np.log(0.7):.2f}')\n",
    "plt.axhline(y=-np.log(0.95), color='#1565c0', linestyle='--', label=f'95% confidence: {-np.log(0.95):.2f}')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Ema\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_07_ema.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_07_ema"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 EMA (Exponential Moving Average)"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    \"\"\"\n",
    "    Exponential Moving Average of model parameters.\n",
    "    Maintains a smoothed copy of the weights for more stable evaluation.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        \"\"\"Update EMA weights: shadow = decay * shadow + (1 - decay) * current\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = self.decay * self.shadow[name] + (1 - self.decay) * param.data\n",
    "\n",
    "    def apply(self, model):\n",
    "        \"\"\"Replace model weights with EMA weights (for evaluation).\"\"\"\n",
    "        self.backup = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self, model):\n",
    "        \"\"\"Restore original model weights (after evaluation).\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]\n",
    "\n",
    "print(\"EMA helper class ready!\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Training Loop\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_08_training_loop.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_08_training_loop"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 The Deep Supervision Training Loop\n",
    "\n",
    "This is the core innovation. Instead of training on only the final output, we supervise at T intermediate checkpoints."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, T=3, n=6):\n",
    "    \"\"\"\n",
    "    Train for one epoch with deep supervision.\n",
    "\n",
    "    At each supervision step t:\n",
    "    1. Run n-1 recursions without gradients (free reasoning)\n",
    "    2. Run 1 recursion with gradients\n",
    "    3. Compute prediction + halting loss at this checkpoint\n",
    "    4. Accumulate loss across all T checkpoints\n",
    "    5. Backpropagate the total loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Mask: True where the original puzzle had empty cells\n",
    "        mask = (batch_x.reshape(batch_x.shape[0], -1) == 0)\n",
    "        targets = batch_y.reshape(batch_y.shape[0], -1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get checkpoints from deep supervision forward pass\n",
    "        checkpoints = model.forward_with_supervision(batch_x, T=T, n=n)\n",
    "\n",
    "        # Accumulate loss across all supervision steps\n",
    "        batch_loss = 0\n",
    "        for t, (logits, halt_logits, y_snapshot) in enumerate(checkpoints):\n",
    "            # Prediction loss\n",
    "            p_loss = prediction_loss(logits, targets, mask)\n",
    "\n",
    "            # Check which predictions are correct\n",
    "            preds = logits.argmax(dim=-1) + 1  # 1-indexed\n",
    "            correct = (preds == targets).float()\n",
    "\n",
    "            # Halting loss\n",
    "            h_loss = halting_loss(halt_logits, correct, mask)\n",
    "\n",
    "            batch_loss = batch_loss + p_loss + 0.1 * h_loss  # Weight halting loss lower\n",
    "\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track metrics from final checkpoint\n",
    "        final_logits = checkpoints[-1][0]\n",
    "        final_preds = final_logits.argmax(dim=-1) + 1\n",
    "        correct_mask = ((final_preds == targets) & mask).sum().item()\n",
    "        total_mask = mask.sum().item()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "        total_correct += correct_mask\n",
    "        total_cells += total_mask\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = total_correct / max(total_cells, 1) * 100\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader, T=3, n=6):\n",
    "    \"\"\"Evaluate model accuracy on test set.\"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_cells = 0\n",
    "    total_puzzles_perfect = 0\n",
    "    total_puzzles = 0\n",
    "\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        mask = (batch_x.reshape(batch_x.shape[0], -1) == 0)\n",
    "        targets = batch_y.reshape(batch_y.shape[0], -1)\n",
    "\n",
    "        checkpoints = model.forward_with_supervision(batch_x, T=T, n=n)\n",
    "        final_logits = checkpoints[-1][0]\n",
    "        final_preds = final_logits.argmax(dim=-1) + 1\n",
    "\n",
    "        correct = (final_preds == targets) & mask\n",
    "        total_correct += correct.sum().item()\n",
    "        total_cells += mask.sum().item()\n",
    "\n",
    "        # Check perfect puzzles (all masked cells correct)\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            puzzle_mask = mask[i]\n",
    "            if puzzle_mask.sum() > 0:\n",
    "                puzzle_correct = correct[i][puzzle_mask].all().item()\n",
    "                total_puzzles_perfect += puzzle_correct\n",
    "            total_puzzles += 1\n",
    "\n",
    "    cell_accuracy = total_correct / max(total_cells, 1) * 100\n",
    "    puzzle_accuracy = total_puzzles_perfect / max(total_puzzles, 1) * 100\n",
    "\n",
    "    return cell_accuracy, puzzle_accuracy\n",
    "\n",
    "print(\"Training functions ready!\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Todo Ema\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_09_todo_ema.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_09_todo_ema"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ðŸ”§ Your Turn\n",
    "\n",
    "### TODO: Implement the Training Loop with EMA"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_ema(model, train_loader, test_loader, n_epochs=30, lr=1e-3, T=3, n=4):\n",
    "    \"\"\"\n",
    "    Full training loop with EMA and deep supervision.\n",
    "\n",
    "    Returns training history for plotting.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Initialize the EMA helper (use decay=0.999)\n",
    "    # Step 2: After each epoch's training step, update the EMA\n",
    "    # Step 3: For evaluation, apply EMA weights, evaluate, then restore original weights\n",
    "    # ==============================\n",
    "\n",
    "    ema = ???  # YOUR CODE HERE: Initialize EMA\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'test_cell_acc': [], 'test_puzzle_acc': [],\n",
    "        'test_cell_acc_ema': [], 'test_puzzle_acc_ema': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, T=T, n=n)\n",
    "\n",
    "        # Update EMA\n",
    "        ???  # YOUR CODE HERE\n",
    "\n",
    "        # Evaluate without EMA\n",
    "        cell_acc, puzzle_acc = evaluate(model, test_loader, T=T, n=n)\n",
    "\n",
    "        # Evaluate with EMA\n",
    "        ???  # YOUR CODE HERE: apply EMA weights\n",
    "        cell_acc_ema, puzzle_acc_ema = evaluate(model, test_loader, T=T, n=n)\n",
    "        ???  # YOUR CODE HERE: restore original weights\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_cell_acc'].append(cell_acc)\n",
    "        history['test_puzzle_acc'].append(puzzle_acc)\n",
    "        history['test_cell_acc_ema'].append(cell_acc_ema)\n",
    "        history['test_puzzle_acc_ema'].append(puzzle_acc_ema)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Loss: {train_loss:.4f} | \"\n",
    "                  f\"Train Acc: {train_acc:.1f}% | \"\n",
    "                  f\"Test Cell: {cell_acc:.1f}% | Test Puzzle: {puzzle_acc:.1f}% | \"\n",
    "                  f\"EMA Puzzle: {puzzle_acc_ema:.1f}%\")\n",
    "\n",
    "    return history"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Verification: Run the training\n",
    "# (If your EMA implementation is correct, EMA accuracy should be >= non-EMA accuracy)\n",
    "\n",
    "model = TinyRecursiveModel(n_classes=4, grid_size=4, dim=48, n_layers=2).to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "print(f\"Training with T=3 supervision steps, n=4 recursions per step\\n\")\n",
    "\n",
    "history = train_with_ema(model, train_loader, test_loader, n_epochs=30, lr=1e-3, T=3, n=4)\n",
    "\n",
    "final_ema = history['test_puzzle_acc_ema'][-1]\n",
    "final_no_ema = history['test_puzzle_acc'][-1]\n",
    "print(f\"\\nFinal test puzzle accuracy (no EMA): {final_no_ema:.1f}%\")\n",
    "print(f\"Final test puzzle accuracy (EMA):    {final_ema:.1f}%\")\n",
    "if final_ema >= final_no_ema - 1:\n",
    "    print(\"âœ… EMA implementation looks correct!\")\n",
    "else:\n",
    "    print(\"âš ï¸ EMA accuracy is significantly lower â€” check your implementation\")"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Training\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_10_training.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_10_training"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and Results"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], linewidth=2, color='#e65100')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cell accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train', linewidth=2, color='#1565c0')\n",
    "axes[1].plot(history['test_cell_acc'], label='Test', linewidth=2, color='#2e7d32')\n",
    "axes[1].plot(history['test_cell_acc_ema'], label='Test (EMA)', linewidth=2, color='#2e7d32', linestyle='--')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Cell Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Per-Cell Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Puzzle accuracy\n",
    "axes[2].plot(history['test_puzzle_acc'], label='Test', linewidth=2, color='#6a1b9a')\n",
    "axes[2].plot(history['test_puzzle_acc_ema'], label='Test (EMA)', linewidth=2, color='#6a1b9a', linestyle='--')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Puzzle Accuracy (%)', fontsize=12)\n",
    "axes[2].set_title('Full Puzzle Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[2].legend(fontsize=10)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('TRM Training with Deep Supervision', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Recursion Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_11_recursion_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_11_recursion_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Visualize: Model solving a specific puzzle across recursion steps\n",
    "@torch.no_grad()\n",
    "def visualize_recursion_steps(model, puzzle, solution, T=3, n=4):\n",
    "    \"\"\"Show how the model's predictions evolve across recursion steps.\"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor(puzzle, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    x_emb = model.embed_input(x)\n",
    "    B = 1\n",
    "    seq_len = model.grid_size * model.grid_size\n",
    "\n",
    "    y = model.y_init.expand(B, seq_len, -1)\n",
    "    z = model.z_init.expand(B, seq_len, -1)\n",
    "\n",
    "    all_preds = []\n",
    "    all_confs = []\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            y, z = model.recurse(x_emb, y, z)\n",
    "            logits = model.output_head(y)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = probs.argmax(dim=-1) + 1\n",
    "            conf = probs.max(dim=-1).values\n",
    "            all_preds.append(preds[0].cpu().numpy().reshape(4, 4))\n",
    "            all_confs.append(conf[0].cpu().numpy().reshape(4, 4))\n",
    "\n",
    "    # Plot selected steps\n",
    "    n_show = min(6, len(all_preds))\n",
    "    indices = np.linspace(0, len(all_preds)-1, n_show, dtype=int)\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_show + 1, figsize=(4 * (n_show + 1), 4.5))\n",
    "\n",
    "    # Show original puzzle\n",
    "    ax = axes[0]\n",
    "    for r in range(4):\n",
    "        for c in range(4):\n",
    "            val = puzzle[r, c]\n",
    "            color = '#e3f2fd' if val > 0 else '#f5f5f5'\n",
    "            ax.add_patch(plt.Rectangle((c, 3-r), 1, 1, facecolor=color, edgecolor='gray', lw=2))\n",
    "            if val > 0:\n",
    "                ax.text(c+0.5, 3-r+0.5, str(val), ha='center', va='center',\n",
    "                       fontsize=18, fontweight='bold', color='#1565c0')\n",
    "            else:\n",
    "                ax.text(c+0.5, 3-r+0.5, '?', ha='center', va='center',\n",
    "                       fontsize=18, color='#bbb')\n",
    "    for i in range(0, 5, 2):\n",
    "        ax.axhline(y=i, color='black', linewidth=3)\n",
    "        ax.axvline(x=i, color='black', linewidth=3)\n",
    "    ax.set_xlim(0, 4); ax.set_ylim(0, 4)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('Puzzle', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Show predictions at each selected step\n",
    "    for plot_idx, step_idx in enumerate(indices):\n",
    "        ax = axes[plot_idx + 1]\n",
    "        pred = all_preds[step_idx]\n",
    "        conf = all_confs[step_idx]\n",
    "\n",
    "        for r in range(4):\n",
    "            for c in range(4):\n",
    "                if puzzle[r, c] > 0:\n",
    "                    color = '#e3f2fd'\n",
    "                    text_color = '#1565c0'\n",
    "                    val_str = str(puzzle[r, c])\n",
    "                elif pred[r, c] == solution[r, c]:\n",
    "                    # Correct prediction â€” intensity by confidence\n",
    "                    alpha = conf[r, c]\n",
    "                    color = (0.78 * alpha + 1 * (1-alpha),\n",
    "                             0.9 * alpha + 1 * (1-alpha),\n",
    "                             0.77 * alpha + 1 * (1-alpha))\n",
    "                    text_color = '#2e7d32'\n",
    "                    val_str = str(pred[r, c])\n",
    "                else:\n",
    "                    color = '#ffcdd2'\n",
    "                    text_color = '#c62828'\n",
    "                    val_str = str(pred[r, c])\n",
    "\n",
    "                ax.add_patch(plt.Rectangle((c, 3-r), 1, 1, facecolor=color, edgecolor='gray', lw=2))\n",
    "                ax.text(c+0.5, 3-r+0.65, val_str, ha='center', va='center',\n",
    "                       fontsize=16, fontweight='bold', color=text_color)\n",
    "                ax.text(c+0.5, 3-r+0.3, f'{conf[r,c]:.0%}', ha='center', va='center',\n",
    "                       fontsize=8, color='#888')\n",
    "\n",
    "        for i in range(0, 5, 2):\n",
    "            ax.axhline(y=i, color='black', linewidth=3)\n",
    "            ax.axvline(x=i, color='black', linewidth=3)\n",
    "        ax.set_xlim(0, 4); ax.set_ylim(0, 4)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(f'Step {step_idx+1}/{len(all_preds)}', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.suptitle('Recursive Refinement: Predictions Sharpen Over Steps',\n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Pick a few test puzzles to visualize\n",
    "for idx in [0, 5, 10]:\n",
    "    print(f\"\\n--- Test puzzle {idx} ---\")\n",
    "    visualize_recursion_steps(model, test_puzzles[idx], test_solutions[idx], T=3, n=4)"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Final\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_12_final.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_12_final"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ðŸŽ¯ Final Output â€” The Model Solves Sudoku!"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many test puzzles the model solves perfectly\n",
    "@torch.no_grad()\n",
    "def evaluate_detailed(model, puzzles, solutions, T=3, n=4):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(puzzles)):\n",
    "        x = torch.tensor(puzzles[i], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        checkpoints = model.forward_with_supervision(x, T=T, n=n)\n",
    "        logits = checkpoints[-1][0]\n",
    "        preds = (logits.argmax(dim=-1) + 1)[0].cpu().numpy().reshape(4, 4)\n",
    "\n",
    "        mask = puzzles[i] == 0\n",
    "        correct_cells = (preds[mask] == solutions[i][mask]).sum()\n",
    "        total_cells = mask.sum()\n",
    "        perfect = (preds[mask] == solutions[i][mask]).all()\n",
    "\n",
    "        results.append({\n",
    "            'puzzle': puzzles[i],\n",
    "            'solution': solutions[i],\n",
    "            'prediction': preds,\n",
    "            'mask': mask,\n",
    "            'correct_cells': correct_cells,\n",
    "            'total_cells': total_cells,\n",
    "            'perfect': perfect\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "results = evaluate_detailed(model, test_puzzles, test_solutions)\n",
    "\n",
    "n_perfect = sum(r['perfect'] for r in results)\n",
    "n_total = len(results)\n",
    "avg_cell_acc = np.mean([r['correct_cells'] / max(r['total_cells'], 1) for r in results]) * 100\n",
    "\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  FINAL RESULTS â€” TRM on 4Ã—4 Sudoku\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Test puzzles:        {n_total}\")\n",
    "print(f\"  Perfectly solved:    {n_perfect} ({100*n_perfect/n_total:.1f}%)\")\n",
    "print(f\"  Average cell acc:    {avg_cell_acc:.1f}%\")\n",
    "print(f\"  Model parameters:    {n_params:,}\")\n",
    "print(f\"{'='*50}\")"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Show a gallery of solved puzzles\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 9))\n",
    "\n",
    "# Pick 5 correct and 5 incorrect (or random) puzzles\n",
    "correct_indices = [i for i, r in enumerate(results) if r['perfect']][:5]\n",
    "wrong_indices = [i for i, r in enumerate(results) if not r['perfect']][:5]\n",
    "\n",
    "# Pad if needed\n",
    "while len(correct_indices) < 5:\n",
    "    correct_indices.append(correct_indices[-1] if correct_indices else 0)\n",
    "while len(wrong_indices) < 5:\n",
    "    wrong_indices.append(correct_indices[len(wrong_indices)] if len(correct_indices) > len(wrong_indices) else 0)\n",
    "\n",
    "for col, idx in enumerate(correct_indices):\n",
    "    r = results[idx]\n",
    "    ax = axes[0][col]\n",
    "    for row in range(4):\n",
    "        for c in range(4):\n",
    "            if r['puzzle'][row, c] > 0:\n",
    "                color = '#e3f2fd'\n",
    "                val = str(r['puzzle'][row, c])\n",
    "                fc = '#1565c0'\n",
    "            elif r['prediction'][row, c] == r['solution'][row, c]:\n",
    "                color = '#c8e6c9'\n",
    "                val = str(r['prediction'][row, c])\n",
    "                fc = '#2e7d32'\n",
    "            else:\n",
    "                color = '#ffcdd2'\n",
    "                val = str(r['prediction'][row, c])\n",
    "                fc = '#c62828'\n",
    "            ax.add_patch(plt.Rectangle((c, 3-row), 1, 1, facecolor=color, edgecolor='gray', lw=1.5))\n",
    "            ax.text(c+0.5, 3-row+0.5, val, ha='center', va='center', fontsize=14, fontweight='bold', color=fc)\n",
    "    for i in range(0, 5, 2):\n",
    "        ax.axhline(y=i, color='black', lw=2)\n",
    "        ax.axvline(x=i, color='black', lw=2)\n",
    "    ax.set_xlim(0,4); ax.set_ylim(0,4); ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "    acc = r['correct_cells'] / max(r['total_cells'], 1) * 100\n",
    "    ax.set_title(f'âœ… {acc:.0f}%', fontsize=12, fontweight='bold', color='#2e7d32')\n",
    "\n",
    "for col, idx in enumerate(wrong_indices):\n",
    "    r = results[idx]\n",
    "    ax = axes[1][col]\n",
    "    for row in range(4):\n",
    "        for c in range(4):\n",
    "            if r['puzzle'][row, c] > 0:\n",
    "                color = '#e3f2fd'; val = str(r['puzzle'][row, c]); fc = '#1565c0'\n",
    "            elif r['prediction'][row, c] == r['solution'][row, c]:\n",
    "                color = '#c8e6c9'; val = str(r['prediction'][row, c]); fc = '#2e7d32'\n",
    "            else:\n",
    "                color = '#ffcdd2'; val = str(r['prediction'][row, c]); fc = '#c62828'\n",
    "            ax.add_patch(plt.Rectangle((c, 3-row), 1, 1, facecolor=color, edgecolor='gray', lw=1.5))\n",
    "            ax.text(c+0.5, 3-row+0.5, val, ha='center', va='center', fontsize=14, fontweight='bold', color=fc)\n",
    "    for i in range(0, 5, 2):\n",
    "        ax.axhline(y=i, color='black', lw=2)\n",
    "        ax.axvline(x=i, color='black', lw=2)\n",
    "    ax.set_xlim(0,4); ax.set_ylim(0,4); ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "    acc = r['correct_cells'] / max(r['total_cells'], 1) * 100\n",
    "    status = 'âœ…' if r['perfect'] else 'âŒ'\n",
    "    ax.set_title(f'{status} {acc:.0f}%', fontsize=12, fontweight='bold',\n",
    "                 color='#2e7d32' if r['perfect'] else '#c62828')\n",
    "\n",
    "axes[0][0].set_ylabel('Correct', fontsize=14, fontweight='bold')\n",
    "axes[1][0].set_ylabel('Errors', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Legend\n",
    "fig.text(0.2, 0.02, 'ðŸ”µ Given  ', fontsize=11, color='#1565c0')\n",
    "fig.text(0.4, 0.02, 'ðŸŸ¢ Correctly predicted  ', fontsize=11, color='#2e7d32')\n",
    "fig.text(0.65, 0.02, 'ðŸ”´ Incorrect  ', fontsize=11, color='#c62828')\n",
    "\n",
    "plt.suptitle(f'ðŸŽ‰ TRM Sudoku Results: {n_perfect}/{n_total} Puzzles Solved Perfectly',\n",
    "             fontsize=15, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Congratulations! You have trained a Tiny Recursive Model to solve Sudoku!\")\n",
    "print(f\"   The model uses {n_params:,} parameters and recursive reasoning to solve puzzles\")\n",
    "print(f\"   that a single-pass model of the same size could never handle.\")"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_13_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_13_closing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reflection and Next Steps\n",
    "\n",
    "### ðŸ’¡ Key Takeaways\n",
    "\n",
    "1. **Deep supervision** provides learning signal at multiple intermediate points, preventing gradient instability in deep recursion chains\n",
    "2. **Halting loss** teaches the model to estimate its own confidence â€” enabling early stopping for easy examples\n",
    "3. **EMA** smooths training noise, critical for small datasets\n",
    "4. The combination of these techniques enables training a tiny model to solve structured reasoning tasks\n",
    "\n",
    "### ðŸ¤” Reflection Questions\n",
    "\n",
    "1. What would happen if we set T=1 (only one supervision step)? Would the model still learn effectively?\n",
    "2. Why does EMA help more on small datasets than large ones?\n",
    "3. The halting mechanism could save computation during inference. How would you implement early stopping at test time?\n",
    "\n",
    "### ðŸ† Optional Challenges\n",
    "\n",
    "1. **Increase difficulty:** Generate puzzles with 10-12 empty cells instead of 8. Does the model need more recursion steps?\n",
    "2. **Curriculum learning:** Start training with easy puzzles (4 empty cells) and gradually increase difficulty. Does this help?\n",
    "3. **Visualize the reasoning state z:** Run PCA on the z vectors across recursion steps. Do they form interpretable clusters?\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In the final notebook, we will run **ablation studies** â€” systematically removing components to understand what really matters: recursion depth vs model size, MLP vs attention, with/without z, with/without EMA."
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "chatbot"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸ’¬ AI Teaching Assistant â€” Click â–¶ to start\n",
    "#@markdown This AI chatbot reads your notebook and can answer questions about any concept, code, or exercise.\n",
    "\n",
    "import json as _json\n",
    "import requests as _requests\n",
    "from google.colab import output as _output\n",
    "from IPython.display import display, HTML as _HTML, Markdown as _Markdown\n",
    "\n",
    "# --- Read notebook content for context ---\n",
    "def _get_notebook_context():\n",
    "    try:\n",
    "        from google.colab import _message\n",
    "        nb = _message.blocking_request(\"get_ipynb\", request=\"\", timeout_sec=10)\n",
    "        cells = nb.get(\"ipynb\", {}).get(\"cells\", [])\n",
    "        parts = []\n",
    "        for cell in cells:\n",
    "            src = \"\".join(cell.get(\"source\", []))\n",
    "            tags = cell.get(\"metadata\", {}).get(\"tags\", [])\n",
    "            if \"chatbot\" in tags:\n",
    "                continue\n",
    "            if src.strip():\n",
    "                ct = cell.get(\"cell_type\", \"unknown\")\n",
    "                parts.append(f\"[{ct.upper()}]\\n{src}\")\n",
    "        return \"\\n\\n---\\n\\n\".join(parts)\n",
    "    except Exception:\n",
    "        return \"Notebook content unavailable.\"\n",
    "\n",
    "_NOTEBOOK_CONTEXT = _get_notebook_context()\n",
    "_CHAT_HISTORY = []\n",
    "_API_URL = \"https://course-creator-brown.vercel.app/api/chat\"\n",
    "\n",
    "def _notebook_chat(question):\n",
    "    global _CHAT_HISTORY\n",
    "    try:\n",
    "        resp = _requests.post(_API_URL, json={\n",
    "            'question': question,\n",
    "            'context': _NOTEBOOK_CONTEXT[:100000],\n",
    "            'history': _CHAT_HISTORY[-10:],\n",
    "        }, timeout=60)\n",
    "        data = resp.json()\n",
    "        answer = data.get('answer', 'Sorry, I could not generate a response.')\n",
    "        _CHAT_HISTORY.append({'role': 'user', 'content': question})\n",
    "        _CHAT_HISTORY.append({'role': 'assistant', 'content': answer})\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f'Error connecting to teaching assistant: {str(e)}'\n",
    "\n",
    "_output.register_callback('notebook_chat', _notebook_chat)\n",
    "\n",
    "def ask(question):\n",
    "    \"\"\"Ask the AI teaching assistant a question about this notebook.\"\"\"\n",
    "    answer = _notebook_chat(question)\n",
    "    display(_Markdown(answer))\n",
    "\n",
    "print(\"\\u2705 AI Teaching Assistant is ready!\")\n",
    "print(\"\\U0001f4a1 Use the chat below, or call ask(\\'your question\\') in any cell.\")\n",
    "\n",
    "# --- Display chat widget ---\n",
    "display(_HTML('''<style>\n  .vc-wrap{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;max-width:100%;border-radius:16px;overflow:hidden;box-shadow:0 4px 24px rgba(0,0,0,.12);background:#fff;border:1px solid #e5e7eb}\n  .vc-hdr{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:16px 20px;display:flex;align-items:center;gap:12px}\n  .vc-avatar{width:42px;height:42px;background:rgba(255,255,255,.2);border-radius:50%;display:flex;align-items:center;justify-content:center;font-size:22px}\n  .vc-hdr h3{font-size:16px;font-weight:600;margin:0}\n  .vc-hdr p{font-size:12px;opacity:.85;margin:2px 0 0}\n  .vc-msgs{height:420px;overflow-y:auto;padding:16px;background:#f8f9fb;display:flex;flex-direction:column;gap:10px}\n  .vc-msg{display:flex;flex-direction:column;animation:vc-fade .25s ease}\n  .vc-msg.user{align-items:flex-end}\n  .vc-msg.bot{align-items:flex-start}\n  .vc-bbl{max-width:85%;padding:10px 14px;border-radius:16px;font-size:14px;line-height:1.55;word-wrap:break-word}\n  .vc-msg.user .vc-bbl{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border-bottom-right-radius:4px}\n  .vc-msg.bot .vc-bbl{background:#fff;color:#1a1a2e;border:1px solid #e8e8e8;border-bottom-left-radius:4px}\n  .vc-bbl code{background:rgba(0,0,0,.07);padding:2px 6px;border-radius:4px;font-size:13px;font-family:'Fira Code',monospace}\n  .vc-bbl pre{background:#1e1e2e;color:#cdd6f4;padding:12px;border-radius:8px;overflow-x:auto;margin:8px 0;font-size:13px}\n  .vc-bbl pre code{background:none;padding:0;color:inherit}\n  .vc-bbl h3,.vc-bbl h4{margin:10px 0 4px;font-size:15px}\n  .vc-bbl ul,.vc-bbl ol{margin:4px 0;padding-left:20px}\n  .vc-bbl li{margin:2px 0}\n  .vc-chips{display:flex;flex-wrap:wrap;gap:8px;padding:0 16px 12px;background:#f8f9fb}\n  .vc-chip{background:#fff;border:1px solid #d1d5db;border-radius:20px;padding:6px 14px;font-size:12px;cursor:pointer;transition:all .15s;color:#4b5563}\n  .vc-chip:hover{border-color:#667eea;color:#667eea;background:#f0f0ff}\n  .vc-input{display:flex;padding:12px 16px;background:#fff;border-top:1px solid #eee;gap:8px}\n  .vc-input input{flex:1;padding:10px 16px;border:2px solid #e8e8e8;border-radius:24px;font-size:14px;outline:none;transition:border-color .2s}\n  .vc-input input:focus{border-color:#667eea}\n  .vc-input button{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border:none;border-radius:50%;width:42px;height:42px;cursor:pointer;display:flex;align-items:center;justify-content:center;font-size:18px;transition:transform .1s}\n  .vc-input button:hover{transform:scale(1.05)}\n  .vc-input button:disabled{opacity:.5;cursor:not-allowed;transform:none}\n  .vc-typing{display:flex;gap:5px;padding:4px 0}\n  .vc-typing span{width:8px;height:8px;background:#667eea;border-radius:50%;animation:vc-bounce 1.4s infinite ease-in-out}\n  .vc-typing span:nth-child(2){animation-delay:.2s}\n  .vc-typing span:nth-child(3){animation-delay:.4s}\n  @keyframes vc-bounce{0%,80%,100%{transform:scale(0)}40%{transform:scale(1)}}\n  @keyframes vc-fade{from{opacity:0;transform:translateY(8px)}to{opacity:1;transform:translateY(0)}}\n  .vc-note{text-align:center;font-size:11px;color:#9ca3af;padding:8px 16px 12px;background:#fff}\n</style>\n<div class=\"vc-wrap\">\n  <div class=\"vc-hdr\">\n    <div class=\"vc-avatar\">&#129302;</div>\n    <div>\n      <h3>Vizuara Teaching Assistant</h3>\n      <p>Ask me anything about this notebook</p>\n    </div>\n  </div>\n  <div class=\"vc-msgs\" id=\"vcMsgs\">\n    <div class=\"vc-msg bot\">\n      <div class=\"vc-bbl\">&#128075; Hi! I've read through this entire notebook. Ask me about any concept, code block, or exercise &mdash; I'm here to help you learn!</div>\n    </div>\n  </div>\n  <div class=\"vc-chips\" id=\"vcChips\">\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Explain the main concept</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Help with the TODO exercise</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Summarize what I learned</span>\n  </div>\n  <div class=\"vc-input\">\n    <input type=\"text\" id=\"vcIn\" placeholder=\"Ask about concepts, code, exercises...\" />\n    <button id=\"vcSend\" onclick=\"vcSendMsg()\">&#10148;</button>\n  </div>\n  <div class=\"vc-note\">AI-generated &middot; Verify important information &middot; <a href=\"#\" onclick=\"vcClear();return false\" style=\"color:#667eea\">Clear chat</a></div>\n</div>\n<script>\n(function(){\n  var msgs=document.getElementById('vcMsgs'),inp=document.getElementById('vcIn'),\n      btn=document.getElementById('vcSend'),chips=document.getElementById('vcChips');\n\n  function esc(s){var d=document.createElement('div');d.textContent=s;return d.innerHTML}\n\n  function md(t){\n    return t\n      .replace(/```(\\w*)\\n([\\s\\S]*?)```/g,function(_,l,c){return '<pre><code>'+esc(c)+'</code></pre>'})\n      .replace(/`([^`]+)`/g,'<code>$1</code>')\n      .replace(/\\*\\*([^*]+)\\*\\*/g,'<strong>$1</strong>')\n      .replace(/\\*([^*]+)\\*/g,'<em>$1</em>')\n      .replace(/^#### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^## (.+)$/gm,'<h3>$1</h3>')\n      .replace(/^\\d+\\. (.+)$/gm,'<li>$1</li>')\n      .replace(/^- (.+)$/gm,'<li>$1</li>')\n      .replace(/\\n\\n/g,'<br><br>')\n      .replace(/\\n/g,'<br>');\n  }\n\n  function addMsg(text,isUser){\n    var m=document.createElement('div');m.className='vc-msg '+(isUser?'user':'bot');\n    var b=document.createElement('div');b.className='vc-bbl';\n    b.innerHTML=isUser?esc(text):md(text);\n    m.appendChild(b);msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function showTyping(){\n    var m=document.createElement('div');m.className='vc-msg bot';m.id='vcTyping';\n    m.innerHTML='<div class=\"vc-bbl\"><div class=\"vc-typing\"><span></span><span></span><span></span></div></div>';\n    msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function hideTyping(){var e=document.getElementById('vcTyping');if(e)e.remove()}\n\n  window.vcSendMsg=function(){\n    var q=inp.value.trim();if(!q)return;\n    inp.value='';chips.style.display='none';\n    addMsg(q,true);showTyping();btn.disabled=true;\n    google.colab.kernel.invokeFunction('notebook_chat',[q],{})\n      .then(function(r){\n        hideTyping();\n        var a=r.data['application/json'];\n        addMsg(typeof a==='string'?a:JSON.stringify(a),false);\n      })\n      .catch(function(){\n        hideTyping();\n        addMsg('Sorry, I encountered an error. Please check your internet connection and try again.',false);\n      })\n      .finally(function(){btn.disabled=false;inp.focus()});\n  };\n\n  window.vcAsk=function(q){inp.value=q;vcSendMsg()};\n  window.vcClear=function(){\n    msgs.innerHTML='<div class=\"vc-msg bot\"><div class=\"vc-bbl\">&#128075; Chat cleared. Ask me anything!</div></div>';\n    chips.style.display='flex';\n  };\n\n  inp.addEventListener('keypress',function(e){if(e.key==='Enter')vcSendMsg()});\n  inp.focus();\n})();\n</script>'''))"
   ],
   "id": "vizuara_chatbot"
  }
 ]
}