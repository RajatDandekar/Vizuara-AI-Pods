{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "From NCSN to Diffusion Models -- The Unified View -- Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_00_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"17rFuCNZUUY1xHrMq1WTamV-JWh_IDZe8\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/04_00_intro.mp3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_01_setup_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Setup Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_01_setup_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_02_why_it_matters_intuition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Why It Matters Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_02_why_it_matters_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_03_math_equivalence",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Math Equivalence\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_03_math_equivalence.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_04_data_model_setup",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Data Model Setup\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_04_data_model_setup.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From NCSN to Diffusion Models -- The Unified View -- Vizuara\n",
    "\n",
    "## 1. Why Does This Matter?\n",
    "\n",
    "In the previous notebooks, we built Noise Conditioned Score Networks from scratch and used Annealed Langevin Dynamics to generate samples. But there is a bigger picture here.\n",
    "\n",
    "In 2020, Ho, Jain, and Abbeel published DDPM (Denoising Diffusion Probabilistic Models). At first glance, DDPM looks very different from NCSN. DDPM adds noise in discrete time steps and learns to reverse the process. NCSN uses multiple noise levels and predicts score functions.\n",
    "\n",
    "But here is the remarkable insight: **these are the same thing in disguise**. The score of the noisy distribution is directly proportional to the noise that was added. Learning to predict noise (DDPM) and learning to predict the score (NCSN) are equivalent tasks.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- See the mathematical equivalence between NCSN and DDPM objectives\n",
    "- Implement both perspectives on the same data\n",
    "- Understand how the Score SDE framework unifies them\n",
    "- Build intuition for why modern diffusion models are all score-based\n",
    "\n",
    "## 2. Building Intuition\n",
    "\n",
    "Imagine two people looking at the same mountain from different sides.\n",
    "\n",
    "**Person A (NCSN perspective):** \"I am going to learn the slope of the mountain at every point. If I know the slope everywhere, I can start from any random location and follow the slopes downhill to find the valleys where the treasure is.\"\n",
    "\n",
    "**Person B (DDPM perspective):** \"I am going to learn to undo erosion. Given any eroded version of the mountain, I can predict what it looked like one step before the erosion happened. By repeatedly undoing erosion, I can reconstruct the original mountain.\"\n",
    "\n",
    "Both are describing the same underlying process. The \"slope at a point\" (score) and \"the erosion that happened\" (noise) are directly related:\n",
    "\n",
    "$$\\text{score} = -\\frac{\\text{noise}}{\\text{noise level}}$$\n",
    "\n",
    "This connection is what Yang Song and colleagues formalized in 2021 using Stochastic Differential Equations (SDEs).\n",
    "\n",
    "## 3. The Mathematics\n",
    "\n",
    "### 3.1 The NCSN Objective (Score Prediction)\n",
    "\n",
    "$$\\mathcal{L}_{\\text{NCSN}} = \\mathbb{E}_\\sigma \\mathbb{E}_{x, \\epsilon} \\left[ \\sigma^2 \\left\\| s_\\theta(\\tilde{x}, \\sigma) + \\frac{\\epsilon}{\\sigma} \\right\\|^2 \\right]$$\n",
    "\n",
    "Target: predict the score $-\\epsilon / \\sigma$\n",
    "\n",
    "### 3.2 The DDPM Objective (Noise Prediction)\n",
    "\n",
    "$$\\mathcal{L}_{\\text{DDPM}} = \\mathbb{E}_{t, x, \\epsilon} \\left[ \\left\\| \\epsilon_\\theta(\\tilde{x}, t) - \\epsilon \\right\\|^2 \\right]$$\n",
    "\n",
    "Target: predict the noise $\\epsilon$\n",
    "\n",
    "### 3.3 The Equivalence\n",
    "\n",
    "If $s_\\theta(\\tilde{x}, \\sigma) = -\\epsilon_\\theta(\\tilde{x}, \\sigma) / \\sigma$, then:\n",
    "\n",
    "$$\\sigma^2 \\left\\| s_\\theta + \\frac{\\epsilon}{\\sigma} \\right\\|^2 = \\sigma^2 \\left\\| -\\frac{\\epsilon_\\theta}{\\sigma} + \\frac{\\epsilon}{\\sigma} \\right\\|^2 = \\left\\| \\epsilon_\\theta - \\epsilon \\right\\|^2$$\n",
    "\n",
    "**Worked example:** Let $\\epsilon = [0.5, -0.3]$, $\\sigma = 2.0$.\n",
    "\n",
    "NCSN target: $-\\epsilon / \\sigma = [-0.25, 0.15]$\n",
    "\n",
    "Suppose score network predicts $s = [-0.2, 0.12]$:\n",
    "- NCSN loss: $\\sigma^2 \\|[-0.2, 0.12] - [-0.25, 0.15]\\|^2 = 4 \\cdot ((0.05)^2 + (0.03)^2) = 4 \\cdot 0.0034 = 0.0136$\n",
    "\n",
    "Corresponding noise prediction: $\\epsilon_\\theta = -\\sigma \\cdot s = -2.0 \\cdot [-0.2, 0.12] = [0.4, -0.24]$:\n",
    "- DDPM loss: $\\|[0.4, -0.24] - [0.5, -0.3]\\|^2 = (-0.1)^2 + (0.06)^2 = 0.01 + 0.0036 = 0.0136$\n",
    "\n",
    "The losses are identical. This is exactly what we want.\n",
    "\n",
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 Setup: Data and NCSN from Previous Notebooks"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data(n=5000):\n",
    "    mix = torch.rand(n, 1)\n",
    "    centers = torch.tensor([[-3.0, 0.0], [3.0, 0.0]])\n",
    "    idx = (mix > 0.5).long().squeeze()\n",
    "    return centers[idx] + 0.5 * torch.randn(n, 2)\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "    \"\"\"NCSN: predicts score s(x, sigma).\"\"\"\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )\n",
    "    def forward(self, x, sigma):\n",
    "        if sigma.dim() == 1:\n",
    "            sigma = sigma.unsqueeze(1)\n",
    "        return self.net(torch.cat([x, sigma], dim=1))\n",
    "\n",
    "class NoiseNet(nn.Module):\n",
    "    \"\"\"DDPM-style: predicts noise epsilon(x, sigma).\"\"\"\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )\n",
    "    def forward(self, x, sigma):\n",
    "        if sigma.dim() == 1:\n",
    "            sigma = sigma.unsqueeze(1)\n",
    "        return self.net(torch.cat([x, sigma], dim=1))\n",
    "\n",
    "data = generate_data(5000)\n",
    "L = 10\n",
    "sigma_1, sigma_L = 10.0, 0.01\n",
    "sigmas = torch.tensor([sigma_1 * (sigma_L / sigma_1) ** (i / (L-1)) for i in range(L)])\n",
    "print(\"Data and models ready.\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_05_train_side_by_side_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Train Side By Side Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_05_train_side_by_side_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Both Networks Side by Side"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_06_train_side_by_side_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Train Side By Side Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_06_train_side_by_side_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NCSN (score prediction)\n",
    "score_model = ScoreNet(128)\n",
    "score_opt = torch.optim.Adam(score_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train NoiseNet (noise prediction, DDPM-style)\n",
    "noise_model = NoiseNet(128)\n",
    "noise_opt = torch.optim.Adam(noise_model.parameters(), lr=1e-3)\n",
    "\n",
    "score_losses = []\n",
    "noise_losses = []\n",
    "\n",
    "for epoch in range(3000):\n",
    "    idx = torch.randint(0, L, (data.shape[0],))\n",
    "    sigma = sigmas[idx].unsqueeze(1)\n",
    "    epsilon = torch.randn_like(data)\n",
    "    noisy_data = data + sigma * epsilon\n",
    "\n",
    "    # --- NCSN loss ---\n",
    "    score_target = -epsilon / sigma\n",
    "    score_pred = score_model(noisy_data, sigma.squeeze(1))\n",
    "    loss_score = (sigma**2 * (score_pred - score_target)**2).mean()\n",
    "\n",
    "    score_opt.zero_grad()\n",
    "    loss_score.backward()\n",
    "    score_opt.step()\n",
    "    score_losses.append(loss_score.item())\n",
    "\n",
    "    # --- DDPM loss ---\n",
    "    noise_pred = noise_model(noisy_data, sigma.squeeze(1))\n",
    "    loss_noise = ((noise_pred - epsilon)**2).mean()\n",
    "\n",
    "    noise_opt.zero_grad()\n",
    "    loss_noise.backward()\n",
    "    noise_opt.step()\n",
    "    noise_losses.append(loss_noise.item())\n",
    "\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Score loss={loss_score.item():.4f}, Noise loss={loss_noise.item():.4f}\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_07_plot_training_curves",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Plot Training Curves\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_07_plot_training_curves.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].semilogy(score_losses, alpha=0.3, color='blue')\n",
    "axes[0].set_title('NCSN (Score Prediction) Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].semilogy(noise_losses, alpha=0.3, color='red')\n",
    "axes[1].set_title('DDPM-style (Noise Prediction) Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_08_verify_equivalence_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Verify Equivalence Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_08_verify_equivalence_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Verify the Equivalence Numerically"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_09_verify_equivalence_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Verify Equivalence Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_09_verify_equivalence_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_10_verify_equivalence_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Verify Equivalence Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_10_verify_equivalence_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that score = -noise_pred / sigma\n",
    "test_points = torch.randn(100, 2) * 3\n",
    "test_sigma_val = 1.0\n",
    "test_sigma = torch.full((100,), test_sigma_val)\n",
    "\n",
    "with torch.no_grad():\n",
    "    score_output = score_model(test_points, test_sigma)\n",
    "    noise_output = noise_model(test_points, test_sigma)\n",
    "\n",
    "# If equivalence holds: score should approximately equal -noise / sigma\n",
    "derived_score = -noise_output / test_sigma_val\n",
    "\n",
    "# They won't be exactly equal (different random seeds, different networks)\n",
    "# but they should be correlated and similar in magnitude\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(score_output[:, 0].numpy(), derived_score[:, 0].numpy(), s=10, alpha=0.5)\n",
    "axes[0].plot([-5, 5], [-5, 5], 'r--', label='Perfect agreement')\n",
    "axes[0].set_title('Score (x1 component): Direct vs Derived from Noise')\n",
    "axes[0].set_xlabel('NCSN score prediction')\n",
    "axes[0].set_ylabel('-NoiseNet / sigma')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].scatter(score_output[:, 1].numpy(), derived_score[:, 1].numpy(), s=10, alpha=0.5)\n",
    "axes[1].plot([-5, 5], [-5, 5], 'r--', label='Perfect agreement')\n",
    "axes[1].set_title('Score (x2 component): Direct vs Derived from Noise')\n",
    "axes[1].set_xlabel('NCSN score prediction')\n",
    "axes[1].set_ylabel('-NoiseNet / sigma')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Both models learn the same underlying function, just parameterized differently.\")\n",
    "print(\"The correlation shows the mathematical equivalence in action.\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_11_todo1_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_11_todo1_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** The scatter plots should show a clear positive correlation along the diagonal line.\n",
    "\n",
    "## 5. Your Turn\n",
    "\n",
    "### TODO 1: Sample from the Noise-Prediction Model"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_12_todo1_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_12_todo1_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ddpm_style(noise_model, sigmas, n_steps_per_level=100,\n",
    "                       eps=0.00005, dim=2):\n",
    "    \"\"\"\n",
    "    Generate samples using the noise-prediction model with ALD.\n",
    "\n",
    "    The key insight: we can convert noise predictions to scores on-the-fly.\n",
    "    score = -noise_pred / sigma\n",
    "\n",
    "    Then use the standard ALD update:\n",
    "    x_{t+1} = x_t + alpha * score + sqrt(2*alpha) * z\n",
    "\n",
    "    Args:\n",
    "        noise_model: trained NoiseNet\n",
    "        sigmas: noise levels (large to small)\n",
    "        n_steps_per_level: steps per noise level\n",
    "        eps: base step size\n",
    "        dim: data dimensionality\n",
    "\n",
    "    Returns:\n",
    "        Final sample tensor\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Hint: it is almost identical to annealed_langevin_dynamics\n",
    "    # but replace model(x, sigma) with -noise_model(x, sigma) / sigma\n",
    "    pass"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_13_todo2_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_13_todo2_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Compare Samples from Both Models"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_14_todo2_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_14_todo2_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(score_model, noise_model, sigmas, data, n_samples=200):\n",
    "    \"\"\"\n",
    "    Generate samples from both models and compare them.\n",
    "\n",
    "    For each model:\n",
    "        1. Generate n_samples using ALD\n",
    "        2. Plot the generated samples\n",
    "        3. Compute histogram overlap with true data\n",
    "\n",
    "    Display side by side.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_15_putting_it_together_transition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Putting It Together Transition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_15_putting_it_together_transition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_16_generate_samples_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Generate Samples Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_16_generate_samples_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from both models\n",
    "def ald_sample(model, sigmas, n_steps=100, eps=5e-5, is_noise_model=False):\n",
    "    \"\"\"Unified sampling function for both score and noise models.\"\"\"\n",
    "    x = torch.randn(1, 2) * sigmas[0].item()\n",
    "    sigma_L = sigmas[-1].item()\n",
    "\n",
    "    for sigma_val in sigmas.numpy():\n",
    "        alpha = eps * (sigma_val / sigma_L) ** 2\n",
    "        for _ in range(n_steps):\n",
    "            sigma_t = torch.full((1,), sigma_val)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x, sigma_t)\n",
    "                if is_noise_model:\n",
    "                    score = -pred / sigma_val\n",
    "                else:\n",
    "                    score = pred\n",
    "            x = x + alpha * score + (2 * alpha) ** 0.5 * torch.randn_like(x)\n",
    "    return x.detach()\n",
    "\n",
    "# Generate from both\n",
    "score_samples = []\n",
    "noise_samples = []\n",
    "for i in range(300):\n",
    "    score_samples.append(ald_sample(score_model, sigmas, is_noise_model=False).numpy())\n",
    "    noise_samples.append(ald_sample(noise_model, sigmas, is_noise_model=True).numpy())\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Generated {i+1}/300 from each model\")\n",
    "\n",
    "score_samples = np.concatenate(score_samples)\n",
    "noise_samples = np.concatenate(noise_samples)"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_17_comparison_plot_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Comparison Plot Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_17_comparison_plot_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_18_comparison_plot_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Comparison Plot Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_18_comparison_plot_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(data[:500, 0].numpy(), data[:500, 1].numpy(), s=3, alpha=0.3, c='gray')\n",
    "axes[0].set_title('True Data', fontsize=13)\n",
    "\n",
    "axes[1].scatter(score_samples[:, 0], score_samples[:, 1], s=3, alpha=0.3, c='blue')\n",
    "axes[1].set_title('NCSN (Score) Samples', fontsize=13)\n",
    "\n",
    "axes[2].scatter(noise_samples[:, 0], noise_samples[:, 1], s=3, alpha=0.3, c='red')\n",
    "axes[2].set_title('DDPM-style (Noise) Samples', fontsize=13)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(-7, 7)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Same Task, Different Parameterizations', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Both models produce similar results, confirming the mathematical equivalence!\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_19_unified_view_transition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Unified View Transition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_19_unified_view_transition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_20_score_sde_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Score Sde Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_20_score_sde_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bigger picture: Score SDE framework\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"THE UNIFIED VIEW: Score SDEs\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"NCSN (2019): Discrete noise levels, score prediction\")\n",
    "print(\"  - Train: s_theta(x, sigma) to predict score\")\n",
    "print(\"  - Sample: Annealed Langevin Dynamics\")\n",
    "print()\n",
    "print(\"DDPM (2020): Discrete time steps, noise prediction\")\n",
    "print(\"  - Train: epsilon_theta(x, t) to predict noise\")\n",
    "print(\"  - Sample: Reverse denoising steps\")\n",
    "print()\n",
    "print(\"Score SDE (2021): Continuous time, unified framework\")\n",
    "print(\"  - Forward: dx = f(x,t)dt + g(t)dw  (adds noise)\")\n",
    "print(\"  - Reverse: dx = [f - g^2 * score]dt + g * dw_rev\")\n",
    "print(\"  - Key: the reverse process depends ONLY on the score\")\n",
    "print()\n",
    "print(\"This means ANY generative model that learns to denoise\")\n",
    "print(\"is implicitly learning the score function.\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_21_timeline_viz_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Timeline Viz Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_21_timeline_viz_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the connection\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Timeline\n",
    "years = [2005, 2011, 2019, 2020, 2021]\n",
    "labels = ['Score\\nMatching', 'Denoising\\nScore Matching', 'NCSN', 'DDPM', 'Score SDE\\n(Unified)']\n",
    "colors = ['#4a90d9', '#4a90d9', '#2ecc71', '#e74c3c', '#9b59b6']\n",
    "\n",
    "ax.scatter(years, [1]*len(years), s=300, c=colors, zorder=5, edgecolors='black')\n",
    "\n",
    "for yr, label, c in zip(years, labels, colors):\n",
    "    ax.annotate(label, (yr, 1), textcoords=\"offset points\",\n",
    "                xytext=(0, 30), ha='center', fontsize=11, fontweight='bold',\n",
    "                color=c)\n",
    "    ax.annotate(str(yr), (yr, 1), textcoords=\"offset points\",\n",
    "                xytext=(0, -25), ha='center', fontsize=10)\n",
    "\n",
    "# Arrows\n",
    "ax.annotate('', xy=(2011, 1), xytext=(2005, 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=2))\n",
    "ax.annotate('', xy=(2019, 1), xytext=(2011, 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=2))\n",
    "ax.annotate('', xy=(2021, 1), xytext=(2019, 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='#2ecc71', lw=2.5))\n",
    "ax.annotate('', xy=(2021, 1), xytext=(2020, 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='#e74c3c', lw=2.5))\n",
    "\n",
    "ax.set_xlim(2003, 2023)\n",
    "ax.set_ylim(0.5, 1.8)\n",
    "ax.set_title('Evolution of Score-Based and Diffusion Models', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_22_final_output_transition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Final Output Transition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_22_final_output_transition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_23_final_summary_viz_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Final Summary Viz Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_23_final_summary_viz_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_24_final_summary_viz_text",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Final Summary Viz Text\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_24_final_summary_viz_text.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary: the equivalence in one visualization\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Top-left: NCSN score field\n",
    "x_grid = np.linspace(-7, 7, 20)\n",
    "y_grid = np.linspace(-4, 4, 15)\n",
    "X, Y = np.meshgrid(x_grid, y_grid)\n",
    "pts = torch.tensor(np.stack([X.ravel(), Y.ravel()], axis=1), dtype=torch.float32)\n",
    "sigma_test = torch.full((pts.shape[0],), 1.0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    score_field = score_model(pts, sigma_test).numpy()\n",
    "    noise_field = noise_model(pts, sigma_test).numpy()\n",
    "\n",
    "norms = np.sqrt(score_field[:, 0]**2 + score_field[:, 1]**2).reshape(15, 20)\n",
    "max_n = np.percentile(norms, 95) + 1e-6\n",
    "\n",
    "axes[0, 0].quiver(X, Y, score_field[:, 0].reshape(15,20)/max_n,\n",
    "                   score_field[:, 1].reshape(15,20)/max_n, color='blue', alpha=0.7)\n",
    "axes[0, 0].set_title('NCSN: Score Field at sigma=1.0', fontsize=12)\n",
    "axes[0, 0].scatter(data[:200, 0].numpy(), data[:200, 1].numpy(), s=2, c='red', alpha=0.3)\n",
    "\n",
    "derived = -noise_field / 1.0\n",
    "axes[0, 1].quiver(X, Y, derived[:, 0].reshape(15,20)/max_n,\n",
    "                   derived[:, 1].reshape(15,20)/max_n, color='red', alpha=0.7)\n",
    "axes[0, 1].set_title('DDPM: -Noise/sigma at sigma=1.0', fontsize=12)\n",
    "axes[0, 1].scatter(data[:200, 0].numpy(), data[:200, 1].numpy(), s=2, c='blue', alpha=0.3)\n",
    "\n",
    "# Bottom: samples\n",
    "axes[1, 0].scatter(score_samples[:, 0], score_samples[:, 1], s=5, c='blue', alpha=0.3)\n",
    "axes[1, 0].set_title('Samples from Score Model', fontsize=12)\n",
    "\n",
    "axes[1, 1].scatter(noise_samples[:, 0], noise_samples[:, 1], s=5, c='red', alpha=0.3)\n",
    "axes[1, 1].set_title('Samples from Noise Model', fontsize=12)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.set_xlim(-7, 7)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "plt.suptitle('The NCSN-DDPM Equivalence: Same Function, Different Names',\n",
    "             fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBoth fields point in the same direction.\")\n",
    "print(\"Both sample sets match the true distribution.\")\n",
    "print(\"Score prediction and noise prediction are two views of the same coin.\")\n",
    "print(\"\\nThis insight led to the unified Score SDE framework (2021),\")\n",
    "print(\"which underpins ALL modern diffusion models -- DALL-E, Stable Diffusion,\")\n",
    "print(\"Imagen, and more.\")"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_04_25_reflection_next_steps",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Reflection Next Steps\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_25_reflection_next_steps.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "**What we learned:**\n",
    "1. NCSN predicts the score: $s_\\theta(\\tilde{x}, \\sigma) \\approx -\\epsilon / \\sigma$\n",
    "2. DDPM predicts the noise: $\\epsilon_\\theta(\\tilde{x}, t) \\approx \\epsilon$\n",
    "3. These are mathematically equivalent: $s = -\\epsilon_\\theta / \\sigma$\n",
    "4. The Score SDE framework (2021) unified both perspectives using continuous-time SDEs\n",
    "\n",
    "**Reflection questions:**\n",
    "- If both approaches are equivalent, why did researchers develop both independently?\n",
    "- What advantages might the SDE formulation have over discrete noise levels?\n",
    "- Modern models like Stable Diffusion use the noise-prediction parameterization. Can you think of a practical reason why?\n",
    "\n",
    "**Congratulations!** You now understand the complete NCSN pipeline and its connection to the broader landscape of diffusion models. The score function -- this simple compass pointing toward data -- turned out to be one of the most important ideas in modern generative AI.\n",
    "\n",
    "**Further reading:**\n",
    "- Song & Ermon, \"Generative Modeling by Estimating Gradients of the Data Distribution\" (NeurIPS 2019)\n",
    "- Ho et al., \"Denoising Diffusion Probabilistic Models\" (NeurIPS 2020)\n",
    "- Song et al., \"Score-Based Generative Modeling through SDEs\" (ICLR 2021)"
   ],
   "id": "cell_20"
  }
 ]
}