{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Annealed Langevin Dynamics -- Generating Samples from NCSN -- Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_00_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1_yOuaRupWcvvBB5tNnjVrtDllXqg6x4Q\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/03_00_intro.mp3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_06_retrain_ncsn_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Retrain Ncsn Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_06_retrain_ncsn_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_02_intro_concept",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Intro Concept\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_02_intro_concept.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_03_intuition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_03_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_04_math_langevin",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Math Langevin\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_04_math_langevin.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_05_math_annealed_langevin",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Math Annealed Langevin\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_05_math_annealed_langevin.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annealed Langevin Dynamics -- Generating Samples from NCSN -- Vizuara\n",
    "\n",
    "## 1. Why Does This Matter?\n",
    "\n",
    "We have trained a Noise Conditioned Score Network that can estimate the score function at any noise level. But a score network by itself does not generate images or data. We need a **sampling procedure** that uses these score estimates to create new samples from scratch.\n",
    "\n",
    "**Annealed Langevin Dynamics** is that procedure. It starts from pure random noise and progressively refines it into a clean data sample by following the score at decreasing noise levels.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand standard Langevin dynamics and why it fails alone\n",
    "- Implement Annealed Langevin Dynamics step by step\n",
    "- Generate new samples from a trained NCSN\n",
    "- Visualize the sampling trajectory from noise to data\n",
    "\n",
    "## 2. Building Intuition\n",
    "\n",
    "Think of sculpting a statue from a rough block of marble.\n",
    "\n",
    "**Phase 1 -- Large chisel (high noise level):** You rough out the general shape. You are not worried about details -- you just want to establish the big forms. Is it a person? An animal? The large chisel removes big chunks quickly.\n",
    "\n",
    "**Phase 2 -- Medium chisel (medium noise level):** Now you refine. The arms take shape, the torso gets proportions. The medium chisel carves more precisely.\n",
    "\n",
    "**Phase 3 -- Fine sandpaper (low noise level):** The final details emerge. Facial features, finger lines, texture. The sandpaper barely changes the overall shape but makes it look real.\n",
    "\n",
    "This is exactly what Annealed Langevin Dynamics does. At each noise level, the score function tells you which direction to \"carve\" the sample. Large noise levels give coarse directions. Small noise levels give precise directions.\n",
    "\n",
    "## 3. The Mathematics\n",
    "\n",
    "### 3.1 Standard Langevin Dynamics\n",
    "\n",
    "The basic Langevin update at a fixed noise level:\n",
    "\n",
    "$$x_{t+1} = x_t + \\alpha \\, s_\\theta(x_t) + \\sqrt{2\\alpha} \\, z_t$$\n",
    "\n",
    "where $z_t \\sim \\mathcal{N}(0, I)$ and $\\alpha$ is the step size.\n",
    "\n",
    "**Worked example:** $x_t = [2.0, 1.0]$, $s_\\theta = [-0.5, 0.3]$, $\\alpha = 0.1$, $z_t = [0.2, -0.1]$.\n",
    "\n",
    "$$x_{t+1} = [2.0, 1.0] + 0.1 \\cdot [-0.5, 0.3] + \\sqrt{0.2} \\cdot [0.2, -0.1]$$\n",
    "$$= [2.0, 1.0] + [-0.05, 0.03] + 0.4472 \\cdot [0.2, -0.1]$$\n",
    "$$= [2.0, 1.0] + [-0.05, 0.03] + [0.0894, -0.0447]$$\n",
    "$$= [2.0394, 0.9853]$$\n",
    "\n",
    "The sample moved slightly in the direction of the score, plus some random jitter.\n",
    "\n",
    "### 3.2 Annealed Langevin Dynamics\n",
    "\n",
    "For NCSN, we run Langevin dynamics at each noise level in sequence:\n",
    "\n",
    "$$x_{t+1} = x_t + \\alpha_i \\, s_\\theta(x_t, \\sigma_i) + \\sqrt{2\\alpha_i} \\, z_t$$\n",
    "\n",
    "with step size adapted to the noise level:\n",
    "\n",
    "$$\\alpha_i = \\epsilon \\cdot \\frac{\\sigma_i^2}{\\sigma_L^2}$$\n",
    "\n",
    "**Worked example:** $\\epsilon = 0.00005$, $\\sigma_i = 2.0$, $\\sigma_L = 0.01$.\n",
    "\n",
    "$$\\alpha_i = 0.00005 \\times \\frac{4.0}{0.0001} = 0.00005 \\times 40000 = 2.0$$\n",
    "\n",
    "At $\\sigma_i = 0.01$ (smallest):\n",
    "\n",
    "$$\\alpha_i = 0.00005 \\times \\frac{0.0001}{0.0001} = 0.00005$$\n",
    "\n",
    "Large noise level means large steps (explore broadly). Small noise level means tiny steps (refine carefully).\n",
    "\n",
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 First, Let's Retrain Our NCSN"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Data ---\n",
    "def generate_data(n=5000):\n",
    "    mix = torch.rand(n, 1)\n",
    "    centers = torch.tensor([[-3.0, 0.0], [3.0, 0.0]])\n",
    "    idx = (mix > 0.5).long().squeeze()\n",
    "    return centers[idx] + 0.5 * torch.randn(n, 2)\n",
    "\n",
    "# --- Model ---\n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )\n",
    "    def forward(self, x, sigma):\n",
    "        if sigma.dim() == 1:\n",
    "            sigma = sigma.unsqueeze(1)\n",
    "        return self.net(torch.cat([x, sigma], dim=1))\n",
    "\n",
    "# --- Noise schedule ---\n",
    "L = 10\n",
    "sigma_1, sigma_L = 10.0, 0.01\n",
    "sigmas = torch.tensor([sigma_1 * (sigma_L / sigma_1) ** (i / (L-1)) for i in range(L)])\n",
    "\n",
    "# --- Training ---\n",
    "model = ScoreNet(128)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data = generate_data(5000)\n",
    "\n",
    "for epoch in range(3000):\n",
    "    idx = torch.randint(0, L, (data.shape[0],))\n",
    "    sigma = sigmas[idx].unsqueeze(1)\n",
    "    noise = torch.randn_like(data)\n",
    "    noisy_data = data + sigma * noise\n",
    "    target = -noise / sigma\n",
    "    pred = model(noisy_data, sigma.squeeze(1))\n",
    "    loss = (sigma**2 * (pred - target)**2).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Training complete. Final loss: {loss.item():.4f}\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_07_standard_langevin_func",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Standard Langevin Func\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_07_standard_langevin_func.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Implement Standard Langevin Dynamics (Single Noise Level)"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin_dynamics(score_net, sigma, n_steps=200, eps=0.01, dim=2,\n",
    "                       x_init=None, track=True):\n",
    "    \"\"\"Standard Langevin dynamics at a single noise level.\"\"\"\n",
    "    if x_init is None:\n",
    "        x = torch.randn(1, dim) * 5  # Start far from data\n",
    "    else:\n",
    "        x = x_init.clone()\n",
    "\n",
    "    trajectory = [x.detach().numpy().copy()] if track else None\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        sigma_t = torch.full((1,), sigma)\n",
    "        with torch.no_grad():\n",
    "            score = score_net(x, sigma_t)\n",
    "        noise = torch.randn_like(x)\n",
    "        x = x + eps * score + (2 * eps) ** 0.5 * noise\n",
    "\n",
    "        if track:\n",
    "            trajectory.append(x.detach().numpy().copy())\n",
    "\n",
    "    if track:\n",
    "        trajectory = np.concatenate(trajectory, axis=0)\n",
    "    return x.detach(), trajectory"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_08_run_standard_langevin",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Run Standard Langevin\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_08_run_standard_langevin.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_09_standard_langevin_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Standard Langevin Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_09_standard_langevin_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_16_full_ald_viz_output",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Full Ald Viz Output\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_16_full_ald_viz_output.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Langevin at a single small sigma -- it fails!\n",
    "x_start = torch.tensor([[5.0, 4.0]])\n",
    "sample, traj = langevin_dynamics(model, sigma=sigmas[-1].item(), n_steps=500,\n",
    "                                  eps=0.001, x_init=x_start)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:, 0].numpy(), data[:, 1].numpy(), s=1, alpha=0.1, c='blue', label='Data')\n",
    "plt.plot(traj[:, 0], traj[:, 1], 'r-', alpha=0.5, linewidth=0.5)\n",
    "plt.scatter(traj[0, 0], traj[0, 1], c='green', s=100, zorder=5, marker='*', label='Start')\n",
    "plt.scatter(traj[-1, 0], traj[-1, 1], c='red', s=100, zorder=5, marker='*', label='End')\n",
    "plt.title('Standard Langevin (smallest sigma only) -- Gets Stuck!')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Start: {traj[0]}\")\n",
    "print(f\"End:   {traj[-1]}\")\n",
    "print(\"The sample likely got stuck far from the data -- the score is unreliable there!\")"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_10_annealed_langevin_func",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Annealed Langevin Func\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_10_annealed_langevin_func.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** You should see the trajectory wandering aimlessly, never reaching the data clusters. This demonstrates why we need annealing.\n",
    "\n",
    "### 4.3 Implement Annealed Langevin Dynamics"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealed_langevin_dynamics(score_net, sigmas, n_steps_per_level=100,\n",
    "                                eps=0.00005, dim=2, x_init=None, track=True):\n",
    "    \"\"\"\n",
    "    Annealed Langevin Dynamics: run Langevin at each noise level in sequence.\n",
    "\n",
    "    Args:\n",
    "        score_net: trained NCSN\n",
    "        sigmas: noise levels from large to small (tensor or numpy array)\n",
    "        n_steps_per_level: Langevin steps per noise level\n",
    "        eps: base step size\n",
    "        dim: data dimensionality\n",
    "        x_init: initial point (default: random noise)\n",
    "        track: whether to record trajectory\n",
    "\n",
    "    Returns:\n",
    "        final sample, trajectory (if track=True)\n",
    "    \"\"\"\n",
    "    if isinstance(sigmas, torch.Tensor):\n",
    "        sigmas_np = sigmas.numpy()\n",
    "    else:\n",
    "        sigmas_np = sigmas\n",
    "\n",
    "    sigma_L = sigmas_np[-1]\n",
    "\n",
    "    if x_init is None:\n",
    "        x = torch.randn(1, dim) * sigmas_np[0]\n",
    "    else:\n",
    "        x = x_init.clone()\n",
    "\n",
    "    trajectory = []\n",
    "    level_boundaries = []\n",
    "\n",
    "    for i, sigma in enumerate(sigmas_np):\n",
    "        alpha = eps * (sigma / sigma_L) ** 2\n",
    "\n",
    "        for t in range(n_steps_per_level):\n",
    "            sigma_t = torch.full((1,), sigma)\n",
    "            with torch.no_grad():\n",
    "                score = score_net(x, sigma_t)\n",
    "            noise = torch.randn_like(x)\n",
    "            x = x + alpha * score + (2 * alpha) ** 0.5 * noise\n",
    "\n",
    "            if track:\n",
    "                trajectory.append(x.detach().numpy().copy())\n",
    "\n",
    "        level_boundaries.append(len(trajectory))\n",
    "\n",
    "    if track:\n",
    "        trajectory = np.concatenate(trajectory, axis=0)\n",
    "    return x.detach(), trajectory, level_boundaries"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_11_todo1_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_11_todo1_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn\n",
    "\n",
    "### TODO 1: Visualize the Annealed Langevin Trajectory"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_12_todo1_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_12_todo1_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ald_trajectory(data, trajectory, level_boundaries, sigmas):\n",
    "    \"\"\"\n",
    "    Create a visualization of the annealed Langevin dynamics trajectory.\n",
    "\n",
    "    Args:\n",
    "        data: original training data tensor\n",
    "        trajectory: (N, 2) array of sample positions over time\n",
    "        level_boundaries: list of indices where noise level changes\n",
    "        sigmas: noise levels used\n",
    "\n",
    "    Requirements:\n",
    "        - Plot the true data as faint background points\n",
    "        - Color the trajectory segments by noise level (e.g., red->orange->blue)\n",
    "        - Mark the start point with a green star\n",
    "        - Mark the end point with a red star\n",
    "        - Add a legend showing which color corresponds to which sigma\n",
    "\n",
    "    Hints:\n",
    "        - Use different colors for each noise level segment\n",
    "        - matplotlib colormaps like 'coolwarm' or manual color lists work well\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# sample, traj, bounds = annealed_langevin_dynamics(model, sigmas)\n",
    "# visualize_ald_trajectory(data, traj, bounds, sigmas)"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_13_todo2_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_13_todo2_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Experiment with Step Size and Number of Steps"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_14_todo2_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_14_todo2_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ald_parameter_study(model, sigmas, data):\n",
    "    \"\"\"\n",
    "    Study how eps and n_steps_per_level affect sample quality.\n",
    "\n",
    "    Try the following combinations:\n",
    "        eps = [0.0001, 0.00005, 0.00001]\n",
    "        n_steps = [50, 100, 200]\n",
    "\n",
    "    For each combination:\n",
    "        1. Generate 100 samples using annealed_langevin_dynamics\n",
    "        2. Plot the generated samples alongside the true data\n",
    "        3. Compute a simple quality metric (e.g., mean distance to nearest true data point)\n",
    "\n",
    "    What do you observe?\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_15_full_ald_viz_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Full Ald Viz Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_15_full_ald_viz_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single sample and visualize the full journey\n",
    "x_start = torch.tensor([[7.0, 5.0]])\n",
    "sample, traj, bounds = annealed_langevin_dynamics(\n",
    "    model, sigmas, n_steps_per_level=100, eps=5e-5, x_init=x_start\n",
    ")\n",
    "\n",
    "# Color-coded trajectory\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.scatter(data[:, 0].numpy(), data[:, 1].numpy(), s=2, alpha=0.1, c='gray', label='Data')\n",
    "\n",
    "colors = plt.cm.coolwarm(np.linspace(0, 1, L))\n",
    "prev = 0\n",
    "for i, boundary in enumerate(bounds):\n",
    "    seg = traj[prev:boundary]\n",
    "    ax.plot(seg[:, 0], seg[:, 1], '-', color=colors[i], alpha=0.6, linewidth=1.0,\n",
    "            label=f'sigma={sigmas[i]:.3f}')\n",
    "    prev = boundary\n",
    "\n",
    "ax.scatter(traj[0, 0], traj[0, 1], c='lime', s=200, zorder=5,\n",
    "           marker='*', edgecolors='black', label='Start')\n",
    "ax.scatter(traj[-1, 0], traj[-1, 1], c='red', s=200, zorder=5,\n",
    "           marker='*', edgecolors='black', label='End')\n",
    "ax.set_title('Annealed Langevin Dynamics Trajectory', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Start: {traj[0]}\")\n",
    "print(f\"End:   {traj[-1]}\")\n",
    "print(\"The sample should end up near one of the data clusters!\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_17_generate_many_samples",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Generate Many Samples\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_17_generate_many_samples.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate many samples to evaluate quality\n",
    "n_samples = 500\n",
    "generated = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    sample, _, _ = annealed_langevin_dynamics(\n",
    "        model, sigmas, n_steps_per_level=100, eps=5e-5, track=False\n",
    "    )\n",
    "    generated.append(sample.numpy())\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Generated {i+1}/{n_samples} samples\")\n",
    "\n",
    "generated = np.concatenate(generated, axis=0)\n",
    "print(f\"Generated {len(generated)} samples\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_18_compare_distributions_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Compare Distributions Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_18_compare_distributions_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_19_compare_distributions_output",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Compare Distributions Output\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_19_compare_distributions_output.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare generated vs true distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Panel 1: True data\n",
    "axes[0].scatter(data[:, 0].numpy(), data[:, 1].numpy(), s=2, alpha=0.3, c='blue')\n",
    "axes[0].set_title('True Data', fontsize=13)\n",
    "axes[0].set_xlim(-7, 7)\n",
    "axes[0].set_ylim(-4, 4)\n",
    "\n",
    "# Panel 2: Generated samples\n",
    "axes[1].scatter(generated[:, 0], generated[:, 1], s=2, alpha=0.3, c='red')\n",
    "axes[1].set_title('Generated Samples (NCSN + ALD)', fontsize=13)\n",
    "axes[1].set_xlim(-7, 7)\n",
    "axes[1].set_ylim(-4, 4)\n",
    "\n",
    "# Panel 3: Overlay\n",
    "axes[2].scatter(data[:500, 0].numpy(), data[:500, 1].numpy(), s=3, alpha=0.3,\n",
    "                c='blue', label='True')\n",
    "axes[2].scatter(generated[:, 0], generated[:, 1], s=3, alpha=0.3,\n",
    "                c='red', label='Generated')\n",
    "axes[2].set_title('Overlay: True vs Generated', fontsize=13)\n",
    "axes[2].set_xlim(-7, 7)\n",
    "axes[2].set_ylim(-4, 4)\n",
    "axes[2].legend()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('NCSN Sampling Results', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_20_marginal_histograms_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Marginal Histograms Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_20_marginal_histograms_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_21_marginal_histograms_output",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Marginal Histograms Output\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_21_marginal_histograms_output.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative evaluation: compare histograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# X1 marginal\n",
    "axes[0].hist(data[:, 0].numpy(), bins=50, density=True, alpha=0.5, color='blue', label='True')\n",
    "axes[0].hist(generated[:, 0], bins=50, density=True, alpha=0.5, color='red', label='Generated')\n",
    "axes[0].set_title('Marginal Distribution: x1')\n",
    "axes[0].legend()\n",
    "\n",
    "# X2 marginal\n",
    "axes[1].hist(data[:, 1].numpy(), bins=50, density=True, alpha=0.5, color='blue', label='True')\n",
    "axes[1].hist(generated[:, 1], bins=50, density=True, alpha=0.5, color='red', label='Generated')\n",
    "axes[1].set_title('Marginal Distribution: x2')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The marginal distributions should match closely. This is exactly what we want!\")"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_22_final_showcase_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Final Showcase Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_22_final_showcase_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_23_final_showcase_output",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Final Showcase Output\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_23_final_showcase_output.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final showcase: side-by-side comparison with trajectory examples\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Left: multiple trajectories\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(data[:, 0].numpy(), data[:, 1].numpy(), s=1, alpha=0.05, c='gray')\n",
    "for trial in range(5):\n",
    "    x_init = torch.randn(1, 2) * sigmas[0].item()\n",
    "    _, traj, bounds = annealed_langevin_dynamics(\n",
    "        model, sigmas, n_steps_per_level=100, eps=5e-5, x_init=x_init\n",
    "    )\n",
    "    ax1.plot(traj[:, 0], traj[:, 1], '-', alpha=0.4, linewidth=0.8)\n",
    "    ax1.scatter(traj[0, 0], traj[0, 1], c='green', s=60, zorder=5, marker='*')\n",
    "    ax1.scatter(traj[-1, 0], traj[-1, 1], c='red', s=60, zorder=5, marker='*')\n",
    "ax1.set_title('5 Sampling Trajectories', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: generated distribution\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(data[:500, 0].numpy(), data[:500, 1].numpy(), s=5, alpha=0.3,\n",
    "            c='blue', label='True data')\n",
    "ax2.scatter(generated[:, 0], generated[:, 1], s=5, alpha=0.3,\n",
    "            c='red', label='Generated')\n",
    "ax2.set_title('500 Generated Samples', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('x1')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-6, 6)\n",
    "\n",
    "plt.suptitle('Annealed Langevin Dynamics: From Noise to Data', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNCSN + Annealed Langevin Dynamics successfully generates samples\")\n",
    "print(\"that match the true data distribution!\")"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_24_reflection_next_steps",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Narration: Reflection Next Steps\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_24_reflection_next_steps.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "**What we learned:**\n",
    "1. Standard Langevin dynamics fails when starting from low-density regions\n",
    "2. Annealed Langevin Dynamics runs Langevin at decreasing noise levels\n",
    "3. The step size $\\alpha_i \\propto \\sigma_i^2$ adapts to each noise level\n",
    "4. Large noise levels capture global structure; small noise levels refine details\n",
    "\n",
    "**Reflection questions:**\n",
    "- What happens if you skip the high-noise levels and start directly at small sigma?\n",
    "- How does the number of steps per noise level affect sample quality?\n",
    "- Could you use a continuous noise schedule instead of discrete levels?\n",
    "\n",
    "**Next notebook:** We will explore the connection between NCSN and diffusion models (DDPM), and see how both approaches were unified through stochastic differential equations."
   ],
   "id": "cell_20"
  }
 ]
}