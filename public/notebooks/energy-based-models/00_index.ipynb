{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Energy Based Models -- Course Index"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Based Models and the Score Function -- Learning Path\n",
    "\n",
    "## Welcome to the Vizuara Course on Energy-Based Models\n",
    "\n",
    "This series of notebooks takes you on a guided journey from the foundations of energy-based modeling to the score function -- the key idea that powers modern diffusion models.\n",
    "\n",
    "### Prerequisites\n",
    "- Basic PyTorch (tensors, autograd, nn.Module)\n",
    "- Familiarity with probability distributions (Gaussian, sampling)\n",
    "- Calculus (gradients, derivatives)\n",
    "\n",
    "### Notebook Series\n",
    "\n",
    "**Notebook 1: Energy Functions and the Boltzmann Distribution**\n",
    "- What is an energy function?\n",
    "- How does the Boltzmann distribution convert energy to probability?\n",
    "- Why is the partition function intractable?\n",
    "- Hands-on: implement and visualize energy landscapes\n",
    "\n",
    "**Notebook 2: The Score Function and Langevin Dynamics**\n",
    "- The score function as a compass toward high probability\n",
    "- How the score bypasses the partition function\n",
    "- Langevin dynamics: sampling with score + noise\n",
    "- Hands-on: implement Langevin sampling from known distributions\n",
    "\n",
    "**Notebook 3: Score Matching and Denoising Score Matching**\n",
    "- Learning the score from data (Hyvarinen 2005)\n",
    "- Denoising Score Matching: a faster alternative (Vincent 2010)\n",
    "- Connection to DDPM and noise prediction\n",
    "- Hands-on: train a score network and generate 2D samples\n",
    "\n",
    "**Notebook 4: Full Pipeline -- Multi-Scale Score Matching**\n",
    "- Why multiple noise scales matter\n",
    "- Noise-conditioned score networks\n",
    "- Annealed Langevin dynamics\n",
    "- Hands-on: generate complex multi-modal distributions\n",
    "- Bridge to modern diffusion models (DDPM, Score SDE)\n",
    "\n",
    "### How to Use These Notebooks\n",
    "1. Open each notebook in Google Colab (Runtime > Change runtime type > GPU)\n",
    "2. Run each cell sequentially\n",
    "3. Complete the TODO sections before looking at solutions\n",
    "4. Use the reflection questions to deepen your understanding\n",
    "\n",
    "### Estimated Time\n",
    "- Notebook 1: 45 minutes\n",
    "- Notebook 2: 60 minutes\n",
    "- Notebook 3: 75 minutes\n",
    "- Notebook 4: 90 minutes\n",
    "- Total: ~4.5 hours\n",
    "\n",
    "### References\n",
    "- Hyvarinen (2005): Estimation of Non-Normalized Statistical Models by Score Matching\n",
    "- Vincent (2010): A Connection Between Score Matching and Denoising Autoencoders\n",
    "- Song & Ermon (2019): Generative Modeling by Estimating Gradients of the Data Distribution\n",
    "- Ho et al. (2020): Denoising Diffusion Probabilistic Models"
   ],
   "id": "cell_1"
  }
 ]
}