{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Score Matching and Denoising Score Matching -- Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_00_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1_yOuaRupWcvvBB5tNnjVrtDllXqg6x4Q\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/03_00_intro.mp3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_02_why_it_matters",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_02_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_03_intuition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_03_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_04_math_overview",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Math Overview\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_04_math_overview.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Matching and Denoising Score Matching -- Vizuara\n",
    "\n",
    "## 1. Why Does This Matter?\n",
    "\n",
    "So far we have seen that the score function is a powerful tool for sampling from distributions. But there was a catch: we assumed we KNEW the score function. In practice, we do not know the true data distribution, so we cannot compute the true score.\n",
    "\n",
    "This notebook introduces two landmark techniques that solve this problem:\n",
    "1. **Score Matching** (Hyvarinen, 2005) -- learn the score from data without knowing the true distribution\n",
    "2. **Denoising Score Matching** (Vincent, 2010) -- a computationally efficient alternative that connects directly to diffusion models\n",
    "\n",
    "**By the end of this notebook, you will:**\n",
    "- Implement the tractable score matching loss\n",
    "- Train a neural network to estimate the score function\n",
    "- Implement denoising score matching\n",
    "- Generate samples from a learned score using Langevin dynamics\n",
    "- Understand the deep connection to modern diffusion models\n",
    "\n",
    "## 2. Building Intuition\n",
    "\n",
    "### Why Can't We Just Use MSE Against the True Score?\n",
    "\n",
    "The obvious approach is to train a neural network $s_\\theta(x)$ by minimizing:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2} \\mathbb{E}_{p(x)} \\left[\\|s_\\theta(x) - \\nabla_x \\log p(x)\\|^2\\right]$$\n",
    "\n",
    "But this requires the TRUE score $\\nabla_x \\log p(x)$, which we do not have.\n",
    "\n",
    "### Hyvarinen's Insight\n",
    "\n",
    "Hyvarinen showed in 2005 that through integration by parts, this loss can be rewritten into a form that only requires the model and the data -- no true score needed. This is truly amazing.\n",
    "\n",
    "### The Denoising Trick (Vincent, 2010)\n",
    "\n",
    "Even Hyvarinen's formulation requires computing the Jacobian trace, which is expensive. Vincent's insight was simpler: add noise to data, then the score of the NOISY distribution is known analytically. Train the network to match this known target.\n",
    "\n",
    "Think of it like invisible magnets on a table: you flick a ball away from a magnet and train a neural network to predict the direction back to the magnet.\n",
    "\n",
    "## 3. The Mathematics\n",
    "\n",
    "### Tractable Score Matching (Hyvarinen 2005)\n",
    "\n",
    "$$J(\\theta) = \\mathbb{E}_{p(x)} \\left[\\text{tr}(\\nabla_x s_\\theta(x)) + \\frac{1}{2}\\|s_\\theta(x)\\|^2\\right]$$\n",
    "\n",
    "**Term 1** (Jacobian trace): forces score arrows to converge inward at data points. Computationally, we compute the diagonal of the Jacobian matrix and sum the entries.\n",
    "\n",
    "**Term 2** (score magnitude): penalizes large scores, making high-density points stationary. Computationally, this is just the squared L2 norm of the score vector.\n",
    "\n",
    "### Denoising Score Matching (Vincent 2010)\n",
    "\n",
    "$$J_{DSM}(\\theta) = \\mathbb{E}_{p(x)\\, q(\\tilde{x}|x)} \\left[\\left\\|s_\\theta(\\tilde{x}) + \\frac{\\tilde{x} - x}{\\sigma^2}\\right\\|^2\\right]$$\n",
    "\n",
    "Computationally: add Gaussian noise to each data point, then train the network to predict the direction from the noisy point back to the clean point, scaled by $1/\\sigma^2$.\n",
    "\n",
    "**Numerical example:** Clean point $x = 2$, noise $\\epsilon = 0.6$, $\\sigma = 0.5$. Noisy point $\\tilde{x} = 2.3$. Target score: $-(2.3 - 2)/0.25 = -1.2$.\n",
    "\n",
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 The Score Network"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_05_score_network_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Code Walkthrough: Score Network Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_05_score_network_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ScoreNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network that estimates the score function s_theta(x).\n",
    "\n",
    "    Takes a 2D point as input, outputs a 2D score vector.\n",
    "    Simple MLP with SiLU activations.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=2, hidden=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_06_training_data_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Training Data Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_06_training_data_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training Data: Mixture of Gaussians"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_07_training_data_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß What to Look For: Training Data Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_07_training_data_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mixture_of_gaussians(n, centers=None, std=0.3):\n",
    "    \"\"\"Generate samples from a mixture of Gaussians.\"\"\"\n",
    "    if centers is None:\n",
    "        centers = [[-2.0, 0.0], [2.0, 0.0]]\n",
    "    centers = torch.tensor(centers)\n",
    "    n_components = len(centers)\n",
    "\n",
    "    # Random component assignment\n",
    "    idx = torch.randint(0, n_components, (n,))\n",
    "    samples = torch.randn(n, 2) * std + centers[idx]\n",
    "    return samples\n",
    "\n",
    "# Generate and visualize training data\n",
    "data = sample_mixture_of_gaussians(2000)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:, 0].numpy(), data[:, 1].numpy(), s=5, alpha=0.3, c='steelblue')\n",
    "plt.title('Training Data: Mixture of Two Gaussians', fontsize=14)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_08_sm_loss_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Code Walkthrough: Sm Loss Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_08_sm_loss_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tractable Score Matching Loss"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_matching_loss(model, x):\n",
    "    \"\"\"\n",
    "    Compute the tractable score matching loss (Hyvarinen 2005).\n",
    "\n",
    "    L = E[ tr(Jacobian of s_theta) + 0.5 * ||s_theta||^2 ]\n",
    "\n",
    "    This requires computing the diagonal of the Jacobian of s_theta(x),\n",
    "    which needs one backward pass per dimension.\n",
    "    \"\"\"\n",
    "    x = x.clone().requires_grad_(True)\n",
    "    score = model(x)\n",
    "\n",
    "    # Term 2: score magnitude (easy)\n",
    "    score_sq = 0.5 * (score ** 2).sum(dim=-1)\n",
    "\n",
    "    # Term 1: trace of Jacobian (harder -- need autograd)\n",
    "    trace = torch.zeros(x.shape[0], device=x.device)\n",
    "    for i in range(x.shape[1]):\n",
    "        # Gradient of the i-th component of score w.r.t. x\n",
    "        grad_i = torch.autograd.grad(\n",
    "            score[:, i].sum(), x,\n",
    "            create_graph=True, retain_graph=True\n",
    "        )[0][:, i]  # Only the diagonal element\n",
    "        trace += grad_i\n",
    "\n",
    "    loss = (trace + score_sq).mean()\n",
    "    return loss"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_09_sm_loss_explanation",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Sm Loss Explanation\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_09_sm_loss_explanation.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us understand this code. We compute two terms: the squared magnitude of the predicted score (simple), and the trace of its Jacobian (requires `autograd` to differentiate each component of the score with respect to the corresponding input dimension). The sum gives us the tractable loss."
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_10_sm_loss_test",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Code Walkthrough: Sm Loss Test\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_10_sm_loss_test.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test: does the loss compute without errors?\n",
    "model = ScoreNetwork(dim=2, hidden=64)\n",
    "test_x = torch.randn(32, 2)\n",
    "test_loss = score_matching_loss(model, test_x)\n",
    "print(f\"Score matching loss (random model): {test_loss.item():.4f}\")\n",
    "print(\"Loss computed successfully!\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_11_training_sm",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Code Walkthrough: Training Sm\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_11_training_sm.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Training with Score Matching"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sm = ScoreNetwork(dim=2, hidden=128)\n",
    "optimizer = torch.optim.Adam(model_sm.parameters(), lr=1e-3)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(500):\n",
    "    x = sample_mixture_of_gaussians(256)\n",
    "    loss = score_matching_loss(model_sm, x)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1:4d} | Loss: {loss.item():.4f}\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_12_sm_loss_plot",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß What to Look For: Sm Loss Plot\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_12_sm_loss_plot.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization checkpoint: training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, 'b-', alpha=0.5, linewidth=0.5)\n",
    "plt.plot(np.convolve(losses, np.ones(20)/20, mode='valid'), 'r-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score Matching Loss')\n",
    "plt.title('Training Loss (Score Matching)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_13_sm_field_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß What to Look For: Sm Field Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_13_sm_field_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned score field\n",
    "n_grid = 20\n",
    "g = torch.linspace(-4, 4, n_grid)\n",
    "G1, G2 = torch.meshgrid(g, g, indexing='ij')\n",
    "grid_pts = torch.stack([G1.flatten(), G2.flatten()], dim=-1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores = model_sm(grid_pts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Data as background\n",
    "data_vis = sample_mixture_of_gaussians(1000)\n",
    "ax.scatter(data_vis[:, 0], data_vis[:, 1], s=5, alpha=0.2, c='gray')\n",
    "\n",
    "# Score field\n",
    "ax.quiver(G1.numpy(), G2.numpy(),\n",
    "          scores[:, 0].reshape(n_grid, n_grid).numpy(),\n",
    "          scores[:, 1].reshape(n_grid, n_grid).numpy(),\n",
    "          color='darkblue', scale=60, width=0.004)\n",
    "\n",
    "ax.set_title('Learned Score Field (Score Matching)', fontsize=14)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Arrows should point toward the two data clusters.\")"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_14_dsm_intro_todo",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Before You Start: Dsm Intro Todo\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_14_dsm_intro_todo.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn -- Denoising Score Matching\n",
    "\n",
    "The tractable score matching loss works but is slow because of the Jacobian computation. Denoising Score Matching is much faster."
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsm_loss(model, x, sigma=0.5):\n",
    "    \"\"\"\n",
    "    TODO: Implement the Denoising Score Matching loss.\n",
    "\n",
    "    Steps:\n",
    "    1. Add Gaussian noise to x: x_noisy = x + sigma * epsilon\n",
    "    2. Compute the target score: target = -(x_noisy - x) / sigma^2\n",
    "       (which simplifies to: target = -epsilon / sigma)\n",
    "    3. Predict the score at x_noisy using the model\n",
    "    4. Return the MSE between predicted and target scores\n",
    "\n",
    "    Args:\n",
    "        model: Score network\n",
    "        x: Clean data points (batch_size, dim)\n",
    "        sigma: Noise level\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss value\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Sample noise\n",
    "    epsilon = ???  # torch.randn_like(x)\n",
    "\n",
    "    # Step 2: Create noisy data\n",
    "    x_noisy = ???  # x + sigma * epsilon\n",
    "\n",
    "    # Step 3: Compute target score\n",
    "    target = ???  # -epsilon / sigma  (or equivalently -(x_noisy - x) / sigma**2)\n",
    "\n",
    "    # Step 4: Predict score and compute MSE\n",
    "    pred = ???  # model(x_noisy)\n",
    "    loss = ???  # MSE between pred and target\n",
    "    # ==============================\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Test (uncomment after implementing):\n",
    "# model_test = ScoreNetwork(dim=2, hidden=64)\n",
    "# x_test = torch.randn(32, 2)\n",
    "# l = dsm_loss(model_test, x_test, sigma=0.5)\n",
    "# print(f\"DSM loss: {l.item():.4f}\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_15_dsm_verification",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Code Walkthrough: Dsm Verification\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_15_dsm_verification.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: compare DSM against known solution\n",
    "def dsm_loss_solution(model, x, sigma=0.5):\n",
    "    epsilon = torch.randn_like(x)\n",
    "    x_noisy = x + sigma * epsilon\n",
    "    target = -epsilon / sigma\n",
    "    pred = model(x_noisy)\n",
    "    loss = ((pred - target) ** 2).sum(dim=-1).mean()\n",
    "    return loss\n",
    "\n",
    "model_verify = ScoreNetwork(dim=2, hidden=64)\n",
    "x_verify = torch.randn(64, 2)\n",
    "loss_val = dsm_loss_solution(model_verify, x_verify)\n",
    "print(f\"DSM loss (verification): {loss_val.item():.4f}\")\n",
    "print(\"If your implementation gives a similar value, it is correct!\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_16_train_dsm_todo",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Before You Start: Train Dsm Todo\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_16_train_dsm_todo.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Your Turn -- Train with DSM and Compare"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dsm(n_epochs=2000, sigma=0.5, lr=1e-3):\n",
    "    \"\"\"\n",
    "    TODO: Train a score network using DSM.\n",
    "\n",
    "    Follow the same pattern as the score matching training above,\n",
    "    but use dsm_loss_solution() instead of score_matching_loss().\n",
    "\n",
    "    Return the trained model and loss history.\n",
    "    \"\"\"\n",
    "    model = ScoreNetwork(dim=2, hidden=128)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        x = sample_mixture_of_gaussians(256)\n",
    "\n",
    "        # ============ TODO ============\n",
    "        # Compute DSM loss, backprop, update\n",
    "        # ==============================\n",
    "\n",
    "        loss = dsm_loss_solution(model, x, sigma)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f\"Epoch {epoch+1:4d} | DSM Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "model_dsm, dsm_losses = train_dsm(n_epochs=2000, sigma=0.5)"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_17_dsm_sm_comparison_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß What to Look For: Dsm Sm Comparison Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_17_dsm_sm_comparison_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: compare score fields\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "data_bg = sample_mixture_of_gaussians(500)\n",
    "n_g = 20\n",
    "g = torch.linspace(-4, 4, n_g)\n",
    "G1, G2 = torch.meshgrid(g, g, indexing='ij')\n",
    "gp = torch.stack([G1.flatten(), G2.flatten()], dim=-1)\n",
    "\n",
    "for ax, model, title in zip(axes, [model_sm, model_dsm],\n",
    "                              ['Score Matching', 'Denoising Score Matching']):\n",
    "    with torch.no_grad():\n",
    "        s = model(gp)\n",
    "    ax.scatter(data_bg[:, 0], data_bg[:, 1], s=5, alpha=0.2, c='gray')\n",
    "    ax.quiver(G1.numpy(), G2.numpy(),\n",
    "              s[:, 0].reshape(n_g, n_g).numpy(),\n",
    "              s[:, 1].reshape(n_g, n_g).numpy(),\n",
    "              color='darkblue', scale=60, width=0.004)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.suptitle('Comparison: Score Matching vs DSM', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Both methods learn similar score fields, but DSM is MUCH faster to train!\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_18_langevin_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Langevin Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_18_langevin_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together -- Sample with Langevin Dynamics"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_19_langevin_sampling_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß What to Look For: Langevin Sampling Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_19_langevin_sampling_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin_sample(model, n_samples=500, n_steps=1000, step_size=0.01, dim=2):\n",
    "    \"\"\"Sample using Langevin dynamics from a learned score network.\"\"\"\n",
    "    x = torch.randn(n_samples, dim) * 3  # Start from noise\n",
    "    trajectories = [x[:5].clone()]\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        with torch.no_grad():\n",
    "            score = model(x)\n",
    "        noise = torch.randn_like(x)\n",
    "        x = x + step_size * score + (2 * step_size) ** 0.5 * noise\n",
    "\n",
    "        if t % 50 == 0:\n",
    "            trajectories.append(x[:5].clone())\n",
    "\n",
    "    return x, trajectories\n",
    "\n",
    "# Sample from the DSM-trained model\n",
    "samples_dsm, trajs = langevin_sample(model_dsm, n_samples=1000, n_steps=1500)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# True data\n",
    "true_data = sample_mixture_of_gaussians(1000)\n",
    "axes[0].scatter(true_data[:, 0], true_data[:, 1], s=5, alpha=0.3, c='steelblue')\n",
    "axes[0].set_title('True Data', fontsize=14)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlim(-5, 5)\n",
    "axes[0].set_ylim(-4, 4)\n",
    "\n",
    "# Trajectories\n",
    "for i in range(5):\n",
    "    tx = [t[i, 0].item() for t in trajs]\n",
    "    ty = [t[i, 1].item() for t in trajs]\n",
    "    axes[1].plot(tx, ty, '-', alpha=0.5, linewidth=1)\n",
    "    axes[1].plot(tx[0], ty[0], 'go', markersize=5)\n",
    "    axes[1].plot(tx[-1], ty[-1], 'rs', markersize=5)\n",
    "axes[1].set_title('Langevin Trajectories', fontsize=14)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlim(-5, 5)\n",
    "axes[1].set_ylim(-4, 4)\n",
    "\n",
    "# Generated samples\n",
    "axes[2].scatter(samples_dsm[:, 0].numpy(), samples_dsm[:, 1].numpy(),\n",
    "                s=5, alpha=0.3, c='coral')\n",
    "axes[2].set_title('Generated Samples (DSM)', fontsize=14)\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].set_xlim(-5, 5)\n",
    "axes[2].set_ylim(-4, 4)\n",
    "\n",
    "plt.suptitle('Full Pipeline: Train Score (DSM) + Sample (Langevin)', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"The generated samples match the true data distribution! Not bad right?\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_20_diffusion_connection",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Diffusion Connection\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_20_diffusion_connection.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results -- Connection to Diffusion Models"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DSM loss is equivalent to predicting the added noise\n",
    "# This is EXACTLY what DDPM does!\n",
    "\n",
    "# Let us verify this connection numerically\n",
    "x_clean = sample_mixture_of_gaussians(100)\n",
    "sigma = 0.5\n",
    "epsilon = torch.randn_like(x_clean)\n",
    "x_noisy = x_clean + sigma * epsilon\n",
    "\n",
    "# DSM target: -(x_noisy - x_clean) / sigma^2\n",
    "dsm_target = -(x_noisy - x_clean) / sigma**2\n",
    "\n",
    "# Noise prediction target (DDPM style): epsilon\n",
    "noise_target = epsilon\n",
    "\n",
    "# These are related by: dsm_target = -noise_target / sigma\n",
    "reconstructed = -noise_target / sigma\n",
    "print(f\"DSM target and -epsilon/sigma match: {torch.allclose(dsm_target, reconstructed)}\")\n",
    "print(f\"\\nThis confirms: learning the score function is the SAME as\")\n",
    "print(f\"learning to predict the noise -- the foundation of DDPM!\")"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_21_final_output_viz",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß What to Look For: Final Output Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_21_final_output_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grand finale: 4-panel summary of the entire pipeline\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Panel 1: True data\n",
    "true_data = sample_mixture_of_gaussians(2000)\n",
    "axes[0, 0].scatter(true_data[:, 0], true_data[:, 1], s=3, alpha=0.3, c='steelblue')\n",
    "axes[0, 0].set_title('1. True Data Distribution', fontsize=13)\n",
    "\n",
    "# Panel 2: Learned score field\n",
    "n_g = 25\n",
    "g = torch.linspace(-4, 4, n_g)\n",
    "G1, G2 = torch.meshgrid(g, g, indexing='ij')\n",
    "gp = torch.stack([G1.flatten(), G2.flatten()], dim=-1)\n",
    "with torch.no_grad():\n",
    "    sc = model_dsm(gp)\n",
    "axes[0, 1].quiver(G1.numpy(), G2.numpy(),\n",
    "                   sc[:, 0].reshape(n_g, n_g).numpy(),\n",
    "                   sc[:, 1].reshape(n_g, n_g).numpy(),\n",
    "                   color='darkblue', scale=80, width=0.003)\n",
    "axes[0, 1].set_title('2. Learned Score Field (DSM)', fontsize=13)\n",
    "\n",
    "# Panel 3: Sampling trajectories\n",
    "samples_final, trajs_final = langevin_sample(model_dsm, n_samples=500, n_steps=1000)\n",
    "for i in range(8):\n",
    "    tx = [t[min(i, len(t)-1), 0].item() for t in trajs_final]\n",
    "    ty = [t[min(i, len(t)-1), 1].item() for t in trajs_final]\n",
    "    axes[1, 0].plot(tx, ty, '-', alpha=0.4, linewidth=1)\n",
    "axes[1, 0].set_title('3. Langevin Sampling Trajectories', fontsize=13)\n",
    "\n",
    "# Panel 4: Generated vs true overlay\n",
    "axes[1, 1].scatter(true_data[:, 0], true_data[:, 1], s=3, alpha=0.15, c='steelblue', label='True')\n",
    "axes[1, 1].scatter(samples_final[:, 0].numpy(), samples_final[:, 1].numpy(),\n",
    "                    s=3, alpha=0.3, c='coral', label='Generated')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].set_title('4. Generated vs True Data', fontsize=13)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "plt.suptitle('Score-Based Generative Modeling: Complete Pipeline', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"1. We trained a neural network to estimate the score function using DSM\")\n",
    "print(\"2. DSM only requires adding noise and learning to undo it\")\n",
    "print(\"3. We sampled new data using Langevin dynamics with the learned score\")\n",
    "print(\"4. This is the foundation of modern diffusion models!\")"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_22_reflection",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title üéß Wrap-Up: Reflection\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_22_reflection.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "### Think About These Questions:\n",
    "1. The DSM loss uses a single noise level $\\sigma$. What happens if $\\sigma$ is too small? Too large? (Hint: think about the bias-variance tradeoff)\n",
    "2. How does this connect to DDPM, which uses MANY noise levels? What advantage does multi-scale noise provide?\n",
    "3. The Jacobian trace in the tractable score matching loss scales as $O(D)$ per sample. For a 256x256 image ($D = 196608$), how many times slower is this compared to DSM?\n",
    "4. Can you think of distributions where Langevin dynamics would struggle, even with a perfect score function?\n",
    "\n",
    "### What's Next\n",
    "The next notebook brings everything together: we will apply the full pipeline (DSM + Langevin) to a more complex dataset and explore what happens when we use multiple noise scales -- the bridge to modern diffusion models."
   ],
   "id": "cell_25"
  }
 ]
}