{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Vision Encoders: CNNs & Vision Transformers -- Learning Path"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Encoders: CNNs & Vision Transformers -- Vizuara\n",
    "\n",
    "**A hands-on learning path from convolutions to self-attention.**\n",
    "\n",
    "This series of notebooks takes you from the fundamental convolution operation to building a complete Vision Transformer, all from scratch in PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "### Notebook 1: Convolutions from Scratch\n",
    "- Implement the 2D convolution operation manually\n",
    "- Understand learnable filters, ReLU, and max pooling\n",
    "- Build and train a complete CNN on CIFAR-10\n",
    "- Visualize learned filters and feature maps\n",
    "- **Estimated time:** 45-60 minutes\n",
    "\n",
    "### Notebook 2: Vision Transformers from Scratch\n",
    "- Implement patch embedding from scratch\n",
    "- Build the self-attention mechanism step by step\n",
    "- Assemble a complete Vision Transformer\n",
    "- Train on CIFAR-10 and visualize attention maps\n",
    "- **Estimated time:** 60-75 minutes\n",
    "\n",
    "### Notebook 3: CNN vs. ViT -- A Hands-On Comparison\n",
    "- Train both architectures under identical conditions\n",
    "- Compare accuracy, speed, and parameter efficiency\n",
    "- Run a data efficiency experiment\n",
    "- Discover when to use each architecture\n",
    "- **Estimated time:** 45-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- Basic Python and PyTorch familiarity\n",
    "- Understanding of neural network fundamentals (forward pass, backpropagation)\n",
    "- A Google Colab account with GPU access (T4 is sufficient)\n",
    "\n",
    "## How to Use\n",
    "1. Open each notebook in Google Colab\n",
    "2. Connect to a GPU runtime (Runtime -> Change runtime type -> GPU)\n",
    "3. Run cells sequentially from top to bottom\n",
    "4. Complete the TODO exercises for deeper understanding\n",
    "\n",
    "Each notebook is self-contained -- you can work through them in order or jump to any individual notebook."
   ]
  }
 ]
}