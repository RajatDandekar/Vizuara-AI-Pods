{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Building a Complete Context Engine â€” Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"11gcJ8_8aATzq7q6k1ExNgH2pUCTE2at1\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/00_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Building a Complete Context Engine: The Four Strategies in Action\n",
    "\n",
    "*Part 4 of the Vizuara series on Context Engineering for LLMs*\n",
    "*Estimated time: 35 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "chatbot"
    ]
   },
   "source": [
    "# ðŸ¤– AI Teaching Assistant\n",
    "\n",
    "Need help with this notebook? Open the **AI Teaching Assistant** â€” it has already read this entire notebook and can help with concepts, code, and exercises.\n",
    "\n",
    "**[ðŸ‘‰ Open AI Teaching Assistant](https://course-creator-brown.vercel.app/courses/context-engineering-for-llms/practice/4/assistant)**\n",
    "\n",
    "*Tip: Open it in a separate tab and work through this notebook side-by-side.*\n"
   ],
   "id": "vizuara_chatbot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Welcome to Part 4: Building a Complete Context Engine!\")\n",
    "print(\"No API keys needed â€” everything runs locally.\\n\")\n",
    "print(\"Libraries loaded: json, numpy, matplotlib, pathlib, sklearn (later)\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_01_why_it_matters"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "Modern LLMs have context windows of 128K, 200K, even 1M tokens. That sounds like a lot â€” until you realize that a real-world agent might need to juggle:\n",
    "\n",
    "- A **system prompt** (2K tokens)\n",
    "- **Conversation history** (50K tokens after an hour of coding)\n",
    "- **Retrieved documents** (30K tokens from a codebase search)\n",
    "- **Tool results** (20K tokens of grep output)\n",
    "- **Persistent memory** (project conventions, user preferences)\n",
    "\n",
    "That is already more than 100K tokens, and we have not even left room for the model to *think* and *respond* (which needs 30-50K tokens of output budget).\n",
    "\n",
    "**Context engineering** is the discipline of managing this finite resource intelligently. Lance Martin (LangChain) and Anthropic codified four canonical strategies:\n",
    "\n",
    "| Strategy | Core Idea | Analogy |\n",
    "|----------|-----------|---------|\n",
    "| **Write** | Persist important info outside the window | Saving phone numbers in contacts instead of memorizing |\n",
    "| **Select** | Retrieve just-in-time, not everything upfront | Looking up one book from the library vs carrying all books |\n",
    "| **Compress** | Summarize and compact, don't truncate blindly | Meeting notes instead of full transcript |\n",
    "| **Isolate** | Split context across sub-agents | Delegating research to team members who report back summaries |\n",
    "\n",
    "In this notebook, you will build each strategy as a standalone class, combine them into a full `ContextEngine`, and measure exactly how much each strategy saves."
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Overflow Simulation\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_overflow_simulation.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_overflow_simulation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see the problem concretely: what happens without context engineering?\n",
    "\n",
    "# Simulate a realistic agent context\n",
    "system_prompt = \"You are a senior software engineer helping with a Python web application.\" * 10\n",
    "conversation_history = [\n",
    "    f\"Turn {i}: {'User asks about feature implementation.' if i % 2 == 0 else 'Assistant provides detailed code with explanations, examples, and best practices.'}\" * (3 if i % 2 == 1 else 1)\n",
    "    for i in range(80)\n",
    "]\n",
    "tool_results = [\n",
    "    f\"grep result {i}: \" + \"def function_name(param1, param2, param3):\\n    \" * 20 + f\"# match {i}\"\n",
    "    for i in range(15)\n",
    "]\n",
    "project_memory = [\n",
    "    \"Convention: use snake_case for Python functions\",\n",
    "    \"Build command: pytest tests/ -v --cov\",\n",
    "    \"Database: PostgreSQL 15, schema in migrations/\",\n",
    "    \"Style: Black formatter, 88 char line length\",\n",
    "    \"Deploy: docker-compose up --build\",\n",
    "]\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    \"\"\"Rough token estimate: ~4 characters per token.\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "total_system = estimate_tokens(system_prompt)\n",
    "total_history = sum(estimate_tokens(msg) for msg in conversation_history)\n",
    "total_tools = sum(estimate_tokens(r) for r in tool_results)\n",
    "total_memory = sum(estimate_tokens(m) for m in project_memory)\n",
    "total_all = total_system + total_history + total_tools + total_memory\n",
    "\n",
    "context_limit = 128000\n",
    "output_reserved = 35000\n",
    "available = context_limit - output_reserved\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  THE CONTEXT BUDGET PROBLEM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  Context window:        {context_limit:>8,} tokens\")\n",
    "print(f\"  Reserved for output:   {output_reserved:>8,} tokens\")\n",
    "print(f\"  Available for input:   {available:>8,} tokens\")\n",
    "print(f\"\\n  System prompt:         {total_system:>8,} tokens\")\n",
    "print(f\"  Conversation history:  {total_history:>8,} tokens\")\n",
    "print(f\"  Tool results:          {total_tools:>8,} tokens\")\n",
    "print(f\"  Project memory:        {total_memory:>8,} tokens\")\n",
    "print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"  TOTAL needed:          {total_all:>8,} tokens\")\n",
    "print(f\"\\n  Over budget by:        {max(0, total_all - available):>8,} tokens\")\n",
    "print(f\"  Utilization:           {total_all / available * 100:>7.1f}%\")\n",
    "\n",
    "if total_all > available:\n",
    "    print(\"\\n  âš ï¸  We are OVER BUDGET. Without context engineering,\")\n",
    "    print(\"     we would have to truncate â€” losing important information.\")\n",
    "else:\n",
    "    print(\"\\n  We fit, but barely. As the session grows, we will overflow.\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Building Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_building_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_building_intuition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "### The Four Strategies as Everyday Actions\n",
    "\n",
    "Before we write any code, let us build a mental model for each strategy using everyday analogies.\n",
    "\n",
    "**Strategy 1 â€” Write (Persist Outside the Window)**\n",
    "\n",
    "Imagine you are studying for an exam. You cannot memorize every single fact from a 500-page textbook. Instead, you write flashcards. The knowledge lives *outside your head* (outside the context window) but is available whenever you need it.\n",
    "\n",
    "Real-world example: Claude Code's `CLAUDE.md` file. Instead of re-explaining project conventions every message, the agent writes them to a persistent file and reads them back when needed.\n",
    "\n",
    "**Strategy 2 â€” Select (Retrieve Just-in-Time)**\n",
    "\n",
    "You are in a library with 10,000 books. You do not carry all of them to your desk. You check the catalog, find the 3 books relevant to your current research question, and fetch only those.\n",
    "\n",
    "Real-world example: Cursor's `@`-references let users manually select which files to include. Claude Code's `glob`/`grep` tools let the agent discover context lazily.\n",
    "\n",
    "**Strategy 3 â€” Compress (Summarize and Compact)**\n",
    "\n",
    "After a 2-hour meeting, you do not transcribe every word. You write bullet-point notes capturing the key decisions, action items, and unresolved questions. The 50-page transcript becomes 1 page of notes.\n",
    "\n",
    "Real-world example: Claude Code's auto-compact triggers at 95% capacity â€” it summarizes conversation history, clears verbose tool outputs, and keeps only the conclusions.\n",
    "\n",
    "**Strategy 4 â€” Isolate (Sub-Agent Architectures)**\n",
    "\n",
    "You are a project manager. Instead of personally reading every document, you assign each team member a specific task: \"Alice, summarize the backend architecture. Bob, review the test coverage. Carol, check the deployment config.\" Each person works with a clean, focused context and reports back a concise summary.\n",
    "\n",
    "Real-world example: Anthropic's multi-agent researcher splits research across sub-agents, each with its own context window, and collects condensed results."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Reflection\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_reflection.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_reflection"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” Think About This\n",
    "\n",
    "Before building anything, predict:\n",
    "\n",
    "1. Which strategy do you think saves the **most** tokens? Why?\n",
    "2. Which strategy is **cheapest** to implement (no ML, no embeddings)?\n",
    "3. Could you use *only one* strategy and still have a good system? Or do you need all four?\n",
    "\n",
    "Write down your predictions. We will revisit them at the end."
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Intuition Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/05_intuition_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_05_intuition_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick intuition builder: how much does each strategy typically save?\n",
    "\n",
    "strategies = ['Write\\n(Persist)', 'Select\\n(Retrieve)', 'Compress\\n(Summarize)', 'Isolate\\n(Sub-agents)']\n",
    "typical_savings_pct = [15, 40, 50, 30]  # rough estimates from production systems\n",
    "typical_effort = [1, 3, 2, 4]  # implementation complexity (1=easy, 4=hard)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "colors = ['#4CAF50', '#2196F3', '#FF9800', '#9C27B0']\n",
    "\n",
    "# Token savings\n",
    "bars1 = axes[0].bar(strategies, typical_savings_pct, color=colors,\n",
    "                     edgecolor='white', linewidth=2, width=0.6)\n",
    "for bar, val in zip(bars1, typical_savings_pct):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                 f'{val}%', ha='center', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Typical Token Savings (%)', fontsize=12)\n",
    "axes[0].set_title('Token Savings by Strategy', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylim(0, 65)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Implementation effort\n",
    "bars2 = axes[1].bar(strategies, typical_effort, color=colors,\n",
    "                     edgecolor='white', linewidth=2, width=0.6)\n",
    "effort_labels = ['Easy', 'Medium', 'Medium', 'Hard']\n",
    "for bar, val, lbl in zip(bars2, typical_effort, effort_labels):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 lbl, ha='center', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Implementation Complexity', fontsize=12)\n",
    "axes[1].set_title('Effort to Implement', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylim(0, 5.5)\n",
    "axes[1].set_yticks([1, 2, 3, 4])\n",
    "axes[1].set_yticklabels(['Easy', 'Medium', 'Hard', 'Very Hard'])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('The Four Context Engineering Strategies â€” Overview',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Each strategy targets a different part of the context budget.\")\n",
    "print(\"The real power comes from combining all four.\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Mathematics\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/06_mathematics.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_06_mathematics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "### 3.1 The Context Budget Equation\n",
    "\n",
    "A context window of $C$ tokens must accommodate:\n",
    "\n",
    "$$C = T_{\\text{system}} + T_{\\text{memory}} + T_{\\text{history}} + T_{\\text{retrieved}} + T_{\\text{query}} + T_{\\text{output}}$$\n",
    "\n",
    "We control the input side. The output budget $T_{\\text{output}}$ is reserved (typically 25-35% of $C$). Our job is to fit everything else into the remaining budget:\n",
    "\n",
    "$$T_{\\text{available}} = C - T_{\\text{output}}$$\n",
    "\n",
    "### 3.2 Strategy Formulas\n",
    "\n",
    "**Write (Persist):** Instead of repeating $n$ facts of average size $s$ tokens every turn, we write them once and load on demand. Savings per turn:\n",
    "\n",
    "$$\\Delta_{\\text{write}} = n \\cdot s \\cdot (1 - \\frac{1}{k})$$\n",
    "\n",
    "where $k$ is the number of turns between re-reads. If you write a fact and read it every 10 turns instead of repeating it every turn, you save 90%.\n",
    "\n",
    "**Select (Retrieve):** From a corpus of $N$ documents of average size $d$ tokens, we retrieve only $k \\ll N$:\n",
    "\n",
    "$$\\Delta_{\\text{select}} = (N - k) \\cdot d$$\n",
    "\n",
    "**Compress (Summarize):** A conversation of $H$ tokens compresses to $H \\cdot r$ tokens, where $r$ is the compression ratio (typically 0.1â€“0.3):\n",
    "\n",
    "$$\\Delta_{\\text{compress}} = H \\cdot (1 - r)$$\n",
    "\n",
    "**Isolate (Sub-agents):** Instead of one agent with context $C$, we have $n$ sub-agents each with context $C/n$, returning summaries of $s$ tokens:\n",
    "\n",
    "$$T_{\\text{lead}} = T_{\\text{system}} + T_{\\text{query}} + n \\cdot s$$"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Math Computation\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/07_math_computation.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_07_math_computation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute exact savings for our scenario\n",
    "\n",
    "C = 128000\n",
    "T_output = 35000\n",
    "T_available = C - T_output\n",
    "\n",
    "# Current usage (from above)\n",
    "T_system = total_system\n",
    "T_history = total_history\n",
    "T_tools = total_tools\n",
    "T_memory_tokens = total_memory\n",
    "T_query = 100  # user's current question\n",
    "\n",
    "T_total = T_system + T_history + T_tools + T_memory_tokens + T_query\n",
    "\n",
    "# Strategy savings (theoretical)\n",
    "# Write: memory facts don't need to be repeated in history\n",
    "write_savings = T_memory_tokens * 0  # already small; real savings come from not repeating in history\n",
    "# But more importantly, without Write, those facts bloat every conversation turn\n",
    "# Assume 20 turns where conventions were restated = ~200 tokens each\n",
    "write_savings = 20 * 50  # 20 repetitions of ~50 tokens each\n",
    "\n",
    "# Select: retrieve 5 of 15 tool results instead of all 15\n",
    "select_k = 5\n",
    "select_savings = sum(estimate_tokens(r) for r in tool_results[select_k:])\n",
    "\n",
    "# Compress: compress history to 30% of original\n",
    "compress_ratio = 0.3\n",
    "compress_savings = int(T_history * (1 - compress_ratio))\n",
    "\n",
    "# Isolate: each sub-agent gets focused context, returns 500-token summary\n",
    "# instead of dumping everything into one window\n",
    "isolate_sub_summaries = 3 * 500  # 3 sub-agents, 500 tokens each\n",
    "isolate_savings = max(0, T_tools - isolate_sub_summaries)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  THEORETICAL TOKEN SAVINGS PER STRATEGY\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"\\n  Original total:     {T_total:>8,} tokens\")\n",
    "print(f\"  Available budget:   {T_available:>8,} tokens\")\n",
    "print(f\"\\n  Write savings:      {write_savings:>8,} tokens  (avoid repeating facts)\")\n",
    "print(f\"  Select savings:     {select_savings:>8,} tokens  (fetch {select_k} of {len(tool_results)} results)\")\n",
    "print(f\"  Compress savings:   {compress_savings:>8,} tokens  (compress history to {compress_ratio:.0%})\")\n",
    "print(f\"  Isolate savings:    {isolate_savings:>8,} tokens  (sub-agent summaries)\")\n",
    "print(f\"\\n  Combined savings:   {write_savings + select_savings + compress_savings + isolate_savings:>8,} tokens\")\n",
    "\n",
    "after_all = T_total - (write_savings + select_savings + compress_savings + isolate_savings)\n",
    "print(f\"  After all 4:        {after_all:>8,} tokens\")\n",
    "print(f\"  Fits in budget?     {'Yes' if after_all <= T_available else 'No'}\")"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Strategy1 Write Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/08_strategy1_write_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_08_strategy1_write_intro"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It â€” The Four Strategies\n",
    "\n",
    "### 4.1 Strategy 1: Write (MemoryStore)\n",
    "\n",
    "The simplest strategy â€” and often the most overlooked. Persist important facts to a JSON file so they survive across sessions and do not need to be repeated in every message."
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryStore:\n",
    "    \"\"\"\n",
    "    Strategy 1: Write â€” Persist facts outside the context window.\n",
    "\n",
    "    Like saving phone numbers in your contacts instead of memorizing them.\n",
    "    Claude Code uses CLAUDE.md for exactly this purpose.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, memory_path=None):\n",
    "        if memory_path is None:\n",
    "            # Use a temp file for Colab\n",
    "            self.memory_path = Path(tempfile.mkdtemp()) / \"memory.json\"\n",
    "        else:\n",
    "            self.memory_path = Path(memory_path)\n",
    "        self._ensure_file()\n",
    "\n",
    "    def _ensure_file(self):\n",
    "        \"\"\"Create memory file if it does not exist.\"\"\"\n",
    "        if not self.memory_path.exists():\n",
    "            self.memory_path.write_text(json.dumps({\"facts\": {}, \"metadata\": {\"created\": \"session_start\", \"version\": 1}}, indent=2))\n",
    "\n",
    "    def save(self, key, value, category=\"general\"):\n",
    "        \"\"\"\n",
    "        Save a fact to persistent memory.\n",
    "\n",
    "        Args:\n",
    "            key: identifier for the fact (e.g., \"build_command\")\n",
    "            value: the fact itself (e.g., \"npm run build\")\n",
    "            category: grouping (e.g., \"project\", \"user_preference\")\n",
    "        \"\"\"\n",
    "        data = json.loads(self.memory_path.read_text())\n",
    "        data[\"facts\"][key] = {\n",
    "            \"value\": value,\n",
    "            \"category\": category,\n",
    "            \"access_count\": 0\n",
    "        }\n",
    "        self.memory_path.write_text(json.dumps(data, indent=2))\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load all memories from persistent storage.\"\"\"\n",
    "        data = json.loads(self.memory_path.read_text())\n",
    "        # Track access counts\n",
    "        for key in data[\"facts\"]:\n",
    "            data[\"facts\"][key][\"access_count\"] += 1\n",
    "        self.memory_path.write_text(json.dumps(data, indent=2))\n",
    "        return data[\"facts\"]\n",
    "\n",
    "    def search(self, query, top_k=5):\n",
    "        \"\"\"\n",
    "        Find relevant memories using keyword matching.\n",
    "        Simple but effective â€” no embeddings needed.\n",
    "        \"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        facts = self.load()\n",
    "\n",
    "        scored = []\n",
    "        for key, entry in facts.items():\n",
    "            # Score based on word overlap with key and value\n",
    "            text_words = set((key + \" \" + entry[\"value\"]).lower().split())\n",
    "            overlap = len(query_words & text_words)\n",
    "            if overlap > 0:\n",
    "                scored.append((key, entry[\"value\"], overlap))\n",
    "\n",
    "        scored.sort(key=lambda x: x[2], reverse=True)\n",
    "        return scored[:top_k]\n",
    "\n",
    "    def get_token_cost(self):\n",
    "        \"\"\"How many tokens does our memory store cost to include?\"\"\"\n",
    "        facts = json.loads(self.memory_path.read_text())[\"facts\"]\n",
    "        text = \"\\n\".join(f\"{k}: {v['value']}\" for k, v in facts.items())\n",
    "        return estimate_tokens(text)\n",
    "\n",
    "    def format_for_context(self):\n",
    "        \"\"\"Format memories as a context block.\"\"\"\n",
    "        facts = json.loads(self.memory_path.read_text())[\"facts\"]\n",
    "        if not facts:\n",
    "            return \"\"\n",
    "        lines = []\n",
    "        for key, entry in facts.items():\n",
    "            lines.append(f\"- {key}: {entry['value']}\")\n",
    "        return \"<memory>\\n\" + \"\\n\".join(lines) + \"\\n</memory>\""
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Write Demo\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/09_write_demo.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_09_write_demo"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Using the MemoryStore\n",
    "\n",
    "memory = MemoryStore()\n",
    "\n",
    "# Save project conventions (like Claude Code's CLAUDE.md)\n",
    "memory.save(\"build_command\", \"pytest tests/ -v --cov\", category=\"project\")\n",
    "memory.save(\"formatter\", \"Black, 88 char line length\", category=\"project\")\n",
    "memory.save(\"database\", \"PostgreSQL 15, migrations in alembic/\", category=\"project\")\n",
    "memory.save(\"deploy_command\", \"docker-compose up --build\", category=\"project\")\n",
    "memory.save(\"naming_convention\", \"snake_case for Python, camelCase for JS\", category=\"style\")\n",
    "memory.save(\"test_framework\", \"pytest with conftest.py fixtures\", category=\"project\")\n",
    "memory.save(\"api_style\", \"REST with FastAPI, OpenAPI docs at /docs\", category=\"project\")\n",
    "memory.save(\"error_handling\", \"Use custom exceptions in app/errors.py\", category=\"project\")\n",
    "\n",
    "print(\"Saved 8 project facts to persistent memory.\\n\")\n",
    "\n",
    "# Search for relevant memories\n",
    "print(\"Search: 'how to run tests'\")\n",
    "results = memory.search(\"how to run tests\")\n",
    "for key, value, score in results:\n",
    "    print(f\"  [{score}] {key}: {value}\")\n",
    "\n",
    "print(\"\\nSearch: 'database schema'\")\n",
    "results = memory.search(\"database schema\")\n",
    "for key, value, score in results:\n",
    "    print(f\"  [{score}] {key}: {value}\")\n",
    "\n",
    "print(f\"\\nToken cost of including all memories: {memory.get_token_cost()} tokens\")\n",
    "print(f\"\\nFormatted context block:\")\n",
    "print(memory.format_for_context())"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Write Matters\n",
    "\n",
    "The savings from Write are not just about the memory file itself (which is small). The real savings come from **not repeating** these facts in conversation. Without a persistent memory, a user might say \"remember, we use Black formatter\" three times in a session â€” each time adding tokens to the history. With Write, the fact is stored once and loaded on demand."
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the savings: repetition vs persistence\n",
    "\n",
    "# Without Write: user repeats conventions in conversation\n",
    "repeated_facts = [\n",
    "    \"Remember, we use Black formatter with 88 char lines\",\n",
    "    \"The test command is pytest tests/ -v --cov\",\n",
    "    \"Our database is PostgreSQL 15\",\n",
    "    \"We deploy with docker-compose up --build\",\n",
    "    \"Use snake_case for Python function names\",\n",
    "]\n",
    "\n",
    "# Simulate 5 repetitions over a conversation\n",
    "repetitions = 5\n",
    "tokens_without_write = sum(estimate_tokens(f) for f in repeated_facts) * repetitions\n",
    "tokens_with_write = memory.get_token_cost()  # loaded once from file\n",
    "\n",
    "print(f\"Without Write (facts repeated {repetitions}x): {tokens_without_write:,} tokens\")\n",
    "print(f\"With Write (loaded once from file):           {tokens_with_write:,} tokens\")\n",
    "print(f\"Savings:                                      {tokens_without_write - tokens_with_write:,} tokens ({(1 - tokens_with_write/tokens_without_write)*100:.0f}%)\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Strategy2 Select\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/10_strategy2_select.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_10_strategy2_select"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Strategy 2: Select (DocumentSelector)\n",
    "\n",
    "Do not load everything upfront. Maintain a lightweight index and fetch full content only when the agent actually needs it."
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSelector:\n",
    "    \"\"\"\n",
    "    Strategy 2: Select â€” Retrieve just-in-time, not everything upfront.\n",
    "\n",
    "    Like checking the library catalog instead of carrying all books.\n",
    "    Cursor uses @-references; Claude Code uses glob/grep for lazy discovery.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.index = {}  # doc_id -> metadata (small)\n",
    "        self.store = {}  # doc_id -> full content (large, loaded lazily)\n",
    "\n",
    "    def register(self, doc_id, summary, content, tags=None):\n",
    "        \"\"\"\n",
    "        Register a document. Stores metadata in the index (cheap)\n",
    "        and full content in the store (expensive, loaded only on demand).\n",
    "        \"\"\"\n",
    "        self.index[doc_id] = {\n",
    "            \"summary\": summary,\n",
    "            \"tags\": tags or [],\n",
    "            \"token_count\": estimate_tokens(content),\n",
    "        }\n",
    "        self.store[doc_id] = content\n",
    "\n",
    "    def select(self, query, top_k=5):\n",
    "        \"\"\"\n",
    "        Select the most relevant document IDs WITHOUT loading full content.\n",
    "        Uses keyword matching against summaries and tags.\n",
    "        Returns list of (doc_id, relevance_score, metadata).\n",
    "        \"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        scored = []\n",
    "\n",
    "        for doc_id, meta in self.index.items():\n",
    "            text = (meta[\"summary\"] + \" \" + \" \".join(meta[\"tags\"])).lower()\n",
    "            text_words = set(text.split())\n",
    "            overlap = len(query_words & text_words)\n",
    "            if overlap > 0:\n",
    "                scored.append((doc_id, overlap, meta))\n",
    "\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scored[:top_k]\n",
    "\n",
    "    def fetch(self, doc_id):\n",
    "        \"\"\"\n",
    "        Fetch the full content of a document (just-in-time loading).\n",
    "        This is the expensive operation â€” only call when truly needed.\n",
    "        \"\"\"\n",
    "        if doc_id in self.store:\n",
    "            return self.store[doc_id]\n",
    "        return None\n",
    "\n",
    "    def eager_load_cost(self):\n",
    "        \"\"\"Token cost of loading ALL documents (the naive approach).\"\"\"\n",
    "        return sum(estimate_tokens(content) for content in self.store.values())\n",
    "\n",
    "    def lazy_load_cost(self, selected_ids):\n",
    "        \"\"\"Token cost of loading only selected documents.\"\"\"\n",
    "        return sum(estimate_tokens(self.store[doc_id])\n",
    "                   for doc_id in selected_ids if doc_id in self.store)\n",
    "\n",
    "    def index_cost(self):\n",
    "        \"\"\"Token cost of the lightweight index (always loaded).\"\"\"\n",
    "        text = \"\\n\".join(f\"{did}: {m['summary']}\"\n",
    "                         for did, m in self.index.items())\n",
    "        return estimate_tokens(text)"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Select Demo\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/11_select_demo.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_11_select_demo"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Simulate a codebase with 20 files\n",
    "\n",
    "selector = DocumentSelector()\n",
    "\n",
    "# Register simulated codebase files\n",
    "files = [\n",
    "    (\"auth/login.py\", \"User authentication and login flow with JWT tokens\",\n",
    "     \"import jwt\\nfrom fastapi import APIRouter\\n\\nrouter = APIRouter()\\n\\n\" + \"def login(username, password):\\n    # Validate credentials against database\\n    user = db.query(User).filter_by(username=username).first()\\n    if not user or not verify_password(password, user.hashed_password):\\n        raise HTTPException(status_code=401)\\n    token = jwt.encode({'sub': user.id}, SECRET_KEY)\\n    return {'access_token': token}\\n\" * 5,\n",
    "     [\"auth\", \"login\", \"jwt\", \"security\"]),\n",
    "\n",
    "    (\"auth/permissions.py\", \"Role-based access control and permission decorators\",\n",
    "     \"from functools import wraps\\n\\ndef require_role(role):\\n    def decorator(func):\\n        @wraps(func)\\n        def wrapper(*args, **kwargs):\\n            if current_user.role != role:\\n                raise PermissionError\\n            return func(*args, **kwargs)\\n        return wrapper\\n    return decorator\\n\" * 4,\n",
    "     [\"auth\", \"permissions\", \"rbac\", \"decorator\"]),\n",
    "\n",
    "    (\"models/user.py\", \"SQLAlchemy User model with profile fields\",\n",
    "     \"from sqlalchemy import Column, Integer, String, DateTime\\nfrom app.database import Base\\n\\nclass User(Base):\\n    __tablename__ = 'users'\\n    id = Column(Integer, primary_key=True)\\n    username = Column(String(50), unique=True)\\n    email = Column(String(120), unique=True)\\n    hashed_password = Column(String(256))\\n    role = Column(String(20), default='user')\\n    created_at = Column(DateTime)\\n\" * 3,\n",
    "     [\"model\", \"user\", \"database\", \"sqlalchemy\"]),\n",
    "\n",
    "    (\"models/product.py\", \"Product catalog model with pricing and inventory\",\n",
    "     \"class Product(Base):\\n    __tablename__ = 'products'\\n    id = Column(Integer, primary_key=True)\\n    name = Column(String(200))\\n    description = Column(Text)\\n    price = Column(Numeric(10, 2))\\n    inventory_count = Column(Integer, default=0)\\n    category_id = Column(Integer, ForeignKey('categories.id'))\\n\" * 4,\n",
    "     [\"model\", \"product\", \"pricing\", \"inventory\"]),\n",
    "\n",
    "    (\"api/routes.py\", \"Main API router with all endpoint registrations\",\n",
    "     \"from fastapi import FastAPI\\napp = FastAPI(title='MyApp')\\n\\napp.include_router(auth_router, prefix='/auth')\\napp.include_router(product_router, prefix='/products')\\napp.include_router(order_router, prefix='/orders')\\napp.include_router(user_router, prefix='/users')\\n\" * 3,\n",
    "     [\"api\", \"routes\", \"fastapi\", \"endpoints\"]),\n",
    "\n",
    "    (\"api/products.py\", \"Product CRUD endpoints with search and filtering\",\n",
    "     \"from fastapi import APIRouter, Query\\n\\nrouter = APIRouter()\\n\\n@router.get('/')\\ndef list_products(category: str = None, min_price: float = None):\\n    query = db.query(Product)\\n    if category: query = query.filter_by(category=category)\\n    if min_price: query = query.filter(Product.price >= min_price)\\n    return query.all()\\n\\n@router.post('/')\\ndef create_product(product: ProductCreate):\\n    db_product = Product(**product.dict())\\n    db.add(db_product)\\n    db.commit()\\n    return db_product\\n\" * 3,\n",
    "     [\"api\", \"products\", \"crud\", \"search\", \"filtering\"]),\n",
    "\n",
    "    (\"tests/test_auth.py\", \"Authentication unit tests\",\n",
    "     \"import pytest\\nfrom app.auth.login import login\\n\\ndef test_valid_login():\\n    result = login('admin', 'password123')\\n    assert 'access_token' in result\\n\\ndef test_invalid_password():\\n    with pytest.raises(HTTPException):\\n        login('admin', 'wrong_password')\\n\" * 4,\n",
    "     [\"test\", \"auth\", \"pytest\", \"login\"]),\n",
    "\n",
    "    (\"tests/test_products.py\", \"Product endpoint integration tests\",\n",
    "     \"import pytest\\nfrom fastapi.testclient import TestClient\\n\\ndef test_list_products(client):\\n    response = client.get('/products/')\\n    assert response.status_code == 200\\n    assert isinstance(response.json(), list)\\n\\ndef test_create_product(client, admin_token):\\n    response = client.post('/products/', json={'name': 'Widget', 'price': 9.99})\\n    assert response.status_code == 201\\n\" * 3,\n",
    "     [\"test\", \"products\", \"integration\", \"fastapi\"]),\n",
    "\n",
    "    (\"config/settings.py\", \"Application configuration with environment variables\",\n",
    "     \"from pydantic import BaseSettings\\n\\nclass Settings(BaseSettings):\\n    DATABASE_URL: str = 'postgresql://localhost/myapp'\\n    SECRET_KEY: str = 'change-me'\\n    DEBUG: bool = False\\n    CORS_ORIGINS: list = ['http://localhost:3000']\\n    class Config:\\n        env_file = '.env'\\n\\nsettings = Settings()\\n\" * 2,\n",
    "     [\"config\", \"settings\", \"environment\", \"pydantic\"]),\n",
    "\n",
    "    (\"config/database.py\", \"Database connection and session management\",\n",
    "     \"from sqlalchemy import create_engine\\nfrom sqlalchemy.orm import sessionmaker\\n\\nengine = create_engine(settings.DATABASE_URL)\\nSessionLocal = sessionmaker(bind=engine)\\n\\ndef get_db():\\n    db = SessionLocal()\\n    try:\\n        yield db\\n    finally:\\n        db.close()\\n\" * 3,\n",
    "     [\"database\", \"connection\", \"sqlalchemy\", \"session\"]),\n",
    "\n",
    "    (\"middleware/cors.py\", \"CORS middleware configuration\",\n",
    "     \"from fastapi.middleware.cors import CORSMiddleware\\n\\ndef setup_cors(app):\\n    app.add_middleware(CORSMiddleware, allow_origins=settings.CORS_ORIGINS)\\n\" * 2,\n",
    "     [\"middleware\", \"cors\", \"security\"]),\n",
    "\n",
    "    (\"middleware/logging.py\", \"Request logging middleware with timing\",\n",
    "     \"import time\\nimport logging\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass LoggingMiddleware:\\n    async def __call__(self, request, call_next):\\n        start = time.time()\\n        response = await call_next(request)\\n        duration = time.time() - start\\n        logger.info(f'{request.method} {request.url} {response.status_code} {duration:.3f}s')\\n        return response\\n\" * 3,\n",
    "     [\"middleware\", \"logging\", \"timing\", \"request\"]),\n",
    "\n",
    "    (\"utils/email.py\", \"Email sending utility with templates\",\n",
    "     \"import smtplib\\nfrom email.mime.text import MIMEText\\n\\ndef send_email(to, subject, body):\\n    msg = MIMEText(body)\\n    msg['Subject'] = subject\\n    msg['To'] = to\\n    with smtplib.SMTP(settings.SMTP_HOST) as server:\\n        server.send_message(msg)\\n\" * 3,\n",
    "     [\"email\", \"utility\", \"smtp\", \"notification\"]),\n",
    "\n",
    "    (\"utils/pagination.py\", \"Pagination helper for list endpoints\",\n",
    "     \"def paginate(query, page=1, per_page=20):\\n    total = query.count()\\n    items = query.offset((page-1)*per_page).limit(per_page).all()\\n    return {'items': items, 'total': total, 'page': page, 'pages': (total+per_page-1)//per_page}\\n\" * 2,\n",
    "     [\"pagination\", \"utility\", \"list\", \"query\"]),\n",
    "\n",
    "    (\"migrations/001_initial.py\", \"Initial database migration creating core tables\",\n",
    "     \"def upgrade():\\n    op.create_table('users', sa.Column('id', sa.Integer, primary_key=True), sa.Column('username', sa.String(50)))\\n    op.create_table('products', sa.Column('id', sa.Integer, primary_key=True), sa.Column('name', sa.String(200)))\\n\" * 4,\n",
    "     [\"migration\", \"database\", \"schema\", \"alembic\"]),\n",
    "]\n",
    "\n",
    "for filepath, summary, content, tags in files:\n",
    "    selector.register(filepath, summary, content, tags)\n",
    "\n",
    "print(f\"Registered {len(files)} files in the document index.\\n\")\n",
    "print(f\"Index cost (always in context):  {selector.index_cost():>6,} tokens\")\n",
    "print(f\"Eager load (all files):          {selector.eager_load_cost():>6,} tokens\")\n",
    "print(f\"Ratio:                           {selector.index_cost() / selector.eager_load_cost() * 100:.1f}% of full load\")"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate a query: \"fix the login authentication bug\"\n",
    "\n",
    "query = \"fix the login authentication bug\"\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "# Step 1: Select relevant documents (cheap â€” only uses index)\n",
    "selected = selector.select(query, top_k=3)\n",
    "print(\"Step 1 â€” Select (from index only):\")\n",
    "for doc_id, score, meta in selected:\n",
    "    print(f\"  [{score}] {doc_id}: {meta['summary']} ({meta['token_count']} tokens)\")\n",
    "\n",
    "# Step 2: Fetch full content (expensive â€” only for selected docs)\n",
    "selected_ids = [doc_id for doc_id, _, _ in selected]\n",
    "print(f\"\\nStep 2 â€” Fetch (just-in-time):\")\n",
    "for doc_id in selected_ids:\n",
    "    content = selector.fetch(doc_id)\n",
    "    print(f\"  Loaded {doc_id}: {estimate_tokens(content)} tokens\")\n",
    "\n",
    "# Compare costs\n",
    "eager_cost = selector.eager_load_cost()\n",
    "lazy_cost = selector.lazy_load_cost(selected_ids) + selector.index_cost()\n",
    "savings = eager_cost - lazy_cost\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  Eager loading (all {len(files)} files): {eager_cost:>6,} tokens\")\n",
    "print(f\"  Lazy loading ({len(selected_ids)} files + index): {lazy_cost:>6,} tokens\")\n",
    "print(f\"  Savings:                        {savings:>6,} tokens ({savings/eager_cost*100:.0f}%)\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Strategy3 Compress\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/12_strategy3_compress.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_12_strategy3_compress"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Strategy 3: Compress (ContextCompressor)\n",
    "\n",
    "When approaching the context limit, compress intelligently. Keep high-signal information (architectural decisions, unresolved bugs), discard redundancy."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextCompressor:\n",
    "    \"\"\"\n",
    "    Strategy 3: Compress â€” Summarize and compact, don't truncate blindly.\n",
    "\n",
    "    Like writing meeting notes instead of keeping the full transcript.\n",
    "    Claude Code auto-compacts at 95% capacity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compress_history(self, messages, budget_tokens):\n",
    "        \"\"\"\n",
    "        Truncate from oldest, keeping the most recent messages\n",
    "        that fit within the token budget.\n",
    "\n",
    "        This is the simplest compression: just drop old messages.\n",
    "        \"\"\"\n",
    "        compressed = []\n",
    "        tokens_used = 0\n",
    "\n",
    "        for msg in reversed(messages):\n",
    "            msg_tokens = estimate_tokens(msg)\n",
    "            if tokens_used + msg_tokens > budget_tokens:\n",
    "                break\n",
    "            compressed.insert(0, msg)\n",
    "            tokens_used += msg_tokens\n",
    "\n",
    "        return compressed, tokens_used\n",
    "\n",
    "    def clear_tool_results(self, messages, max_result_tokens=100):\n",
    "        \"\"\"\n",
    "        Strip verbose tool outputs but keep conclusions.\n",
    "        Simulates Claude Code's behavior of clearing tool output\n",
    "        after processing.\n",
    "\n",
    "        Before: \"grep found 500 lines of code: [500 lines]...\"\n",
    "        After:  \"grep found 500 lines of code: [truncated, 500 lines matched]\"\n",
    "        \"\"\"\n",
    "        cleaned = []\n",
    "        tokens_saved = 0\n",
    "\n",
    "        for msg in messages:\n",
    "            if msg.startswith(\"TOOL_RESULT:\"):\n",
    "                # Keep first line (the summary) and truncate the rest\n",
    "                lines = msg.split(\"\\n\")\n",
    "                summary_line = lines[0]\n",
    "                original_tokens = estimate_tokens(msg)\n",
    "\n",
    "                if original_tokens > max_result_tokens:\n",
    "                    n_lines = len(lines) - 1\n",
    "                    truncated = f\"{summary_line}\\n[truncated: {n_lines} lines, {original_tokens} tokens of output]\"\n",
    "                    cleaned.append(truncated)\n",
    "                    tokens_saved += original_tokens - estimate_tokens(truncated)\n",
    "                else:\n",
    "                    cleaned.append(msg)\n",
    "            else:\n",
    "                cleaned.append(msg)\n",
    "\n",
    "        return cleaned, tokens_saved\n",
    "\n",
    "    def format_compressed(self, messages):\n",
    "        \"\"\"Format compressed messages as a context block.\"\"\"\n",
    "        return \"<history>\\n\" + \"\\n\".join(messages) + \"\\n</history>\""
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Compress a realistic conversation history\n",
    "\n",
    "# Simulate a 40-turn conversation with tool results\n",
    "conversation = []\n",
    "for i in range(40):\n",
    "    if i % 2 == 0:\n",
    "        conversation.append(f\"USER: How do I implement feature {i//2 + 1}?\")\n",
    "    elif i % 5 == 1:\n",
    "        # Every 5th assistant turn includes a verbose tool result\n",
    "        tool_output = f\"TOOL_RESULT: grep search for 'feature_{i//2}':\\n\" + \\\n",
    "            \"\\n\".join([f\"  src/module_{j}.py:L{j*10}: def feature_{i//2}_handler(request):\" +\n",
    "                      f\"    # Implementation of feature {i//2} with detailed logic and error handling\"\n",
    "                      for j in range(30)])\n",
    "        conversation.append(tool_output)\n",
    "    else:\n",
    "        conversation.append(f\"ASSISTANT: Here is how to implement feature {i//2 + 1}. \" +\n",
    "                          \"First, create the handler function. Then add the route. \" +\n",
    "                          \"Finally, write tests to verify the behavior. \" +\n",
    "                          \"Make sure to handle edge cases like invalid input and rate limiting.\")\n",
    "\n",
    "compressor = ContextCompressor()\n",
    "\n",
    "# Measure original\n",
    "original_tokens = sum(estimate_tokens(msg) for msg in conversation)\n",
    "print(f\"Original conversation: {len(conversation)} messages, {original_tokens:,} tokens\\n\")\n",
    "\n",
    "# Strategy A: Simple truncation (keep newest)\n",
    "budget = original_tokens // 3\n",
    "compressed_a, tokens_a = compressor.compress_history(conversation, budget)\n",
    "print(f\"Strategy A â€” Truncate from oldest:\")\n",
    "print(f\"  Budget: {budget:,} tokens\")\n",
    "print(f\"  Kept {len(compressed_a)} of {len(conversation)} messages ({tokens_a:,} tokens)\")\n",
    "print(f\"  Savings: {original_tokens - tokens_a:,} tokens ({(1 - tokens_a/original_tokens)*100:.0f}%)\\n\")\n",
    "\n",
    "# Strategy B: Clear tool results\n",
    "cleaned_b, saved_b = compressor.clear_tool_results(conversation)\n",
    "tokens_b = sum(estimate_tokens(msg) for msg in cleaned_b)\n",
    "print(f\"Strategy B â€” Clear tool results:\")\n",
    "print(f\"  Cleaned {len(cleaned_b)} messages ({tokens_b:,} tokens)\")\n",
    "print(f\"  Savings: {saved_b:,} tokens ({saved_b/original_tokens*100:.0f}%)\\n\")\n",
    "\n",
    "# Strategy C: Both combined\n",
    "cleaned_c, saved_c = compressor.clear_tool_results(conversation)\n",
    "compressed_c, tokens_c = compressor.compress_history(cleaned_c, budget)\n",
    "print(f\"Strategy C â€” Clear tools + truncate:\")\n",
    "print(f\"  Kept {len(compressed_c)} messages ({tokens_c:,} tokens)\")\n",
    "print(f\"  Total savings: {original_tokens - tokens_c:,} tokens ({(1 - tokens_c/original_tokens)*100:.0f}%)\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Compression Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/13_compression_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_13_compression_viz"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Visualization Checkpoint 1: Compression Comparison"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the three compression strategies\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "strategies_comp = ['Original', 'Truncate\\n(oldest)', 'Clear\\ntools', 'Both\\ncombined']\n",
    "token_counts = [original_tokens, tokens_a, tokens_b, tokens_c]\n",
    "colors_comp = ['#E53935', '#FFA726', '#42A5F5', '#66BB6A']\n",
    "\n",
    "# Bar chart of token counts\n",
    "axes[0].bar(strategies_comp, token_counts, color=colors_comp,\n",
    "            edgecolor='white', linewidth=2)\n",
    "for i, (s, t) in enumerate(zip(strategies_comp, token_counts)):\n",
    "    axes[0].text(i, t + 50, f'{t:,}', ha='center', fontsize=10, fontweight='bold')\n",
    "axes[0].set_ylabel('Tokens', fontsize=12)\n",
    "axes[0].set_title('Token Count by Strategy', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Savings percentages\n",
    "savings_pcts = [0, (1-tokens_a/original_tokens)*100,\n",
    "                (1-tokens_b/original_tokens)*100,\n",
    "                (1-tokens_c/original_tokens)*100]\n",
    "axes[1].bar(strategies_comp, savings_pcts, color=colors_comp,\n",
    "            edgecolor='white', linewidth=2)\n",
    "for i, pct in enumerate(savings_pcts):\n",
    "    axes[1].text(i, pct + 1, f'{pct:.0f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "axes[1].set_ylabel('Savings (%)', fontsize=12)\n",
    "axes[1].set_title('Token Savings', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Messages retained\n",
    "msg_counts = [len(conversation), len(compressed_a), len(cleaned_b), len(compressed_c)]\n",
    "axes[2].bar(strategies_comp, msg_counts, color=colors_comp,\n",
    "            edgecolor='white', linewidth=2)\n",
    "for i, mc in enumerate(msg_counts):\n",
    "    axes[2].text(i, mc + 0.5, str(mc), ha='center', fontsize=10, fontweight='bold')\n",
    "axes[2].set_ylabel('Messages', fontsize=12)\n",
    "axes[2].set_title('Messages Retained', fontsize=13, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Compression Strategy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Todo1\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/14_todo1.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_14_todo1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ðŸ”§ Your Turn â€” TODO Sections\n",
    "\n",
    "### TODO 1: Implement `summarize_history` using TF-IDF\n",
    "\n",
    "The `compress_history` method above is crude â€” it just drops old messages. A smarter approach extracts the **most important sentences** across the entire history using TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "\n",
    "TF-IDF scores each sentence by how \"distinctive\" its words are. Sentences with rare, topic-specific words score higher than sentences with common words like \"the\" or \"is\"."
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def summarize_history(messages, max_sentences=5):\n",
    "    \"\"\"\n",
    "    Extract the most important sentences from conversation history\n",
    "    using TF-IDF scoring.\n",
    "\n",
    "    How it works:\n",
    "    1. Split all messages into individual sentences\n",
    "    2. Compute TF-IDF vectors for each sentence\n",
    "    3. Score each sentence by the sum of its TF-IDF values\n",
    "       (sentences with rare, distinctive words score higher)\n",
    "    4. Return the top-k highest-scoring sentences\n",
    "\n",
    "    Args:\n",
    "        messages: list of conversation messages (strings)\n",
    "        max_sentences: number of sentences to keep\n",
    "\n",
    "    Returns:\n",
    "        list of the most important sentences (in original order)\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Split all messages into sentences\n",
    "    #   - Join all messages, then split on '. ' or '.\\n' or '?' or '!'\n",
    "    #   - Filter out empty strings and very short sentences (< 10 chars)\n",
    "    #\n",
    "    # Step 2: Compute TF-IDF\n",
    "    #   - Create a TfidfVectorizer()\n",
    "    #   - Fit and transform the sentences\n",
    "    #   - For each sentence, compute its score as the sum of its TF-IDF values\n",
    "    #     (hint: use .toarray() and .sum(axis=1))\n",
    "    #\n",
    "    # Step 3: Select top sentences\n",
    "    #   - Get indices of top max_sentences by score\n",
    "    #   - Sort those indices to preserve original order\n",
    "    #   - Return the corresponding sentences\n",
    "    #\n",
    "    # YOUR CODE BELOW:\n",
    "    # ==============================\n",
    "\n",
    "    pass  # Replace with your implementation\n",
    "\n",
    "\n",
    "# âœ… Verification: Run this to test your implementation\n",
    "test_messages = [\n",
    "    \"The authentication system uses JWT tokens with RS256 signing.\",\n",
    "    \"I went to the store today. It was nice weather outside.\",\n",
    "    \"Critical bug: the refresh token rotation is broken in production.\",\n",
    "    \"The user model has fields for username, email, and hashed_password.\",\n",
    "    \"Maybe we should consider updating the dependencies. That would be good.\",\n",
    "    \"The database migration 003 adds a foreign key constraint on orders.user_id.\",\n",
    "    \"Everything looks fine to me. Nothing special going on here.\",\n",
    "    \"PostgreSQL connection pooling is configured with max_connections=20.\",\n",
    "    \"The API rate limiter uses a sliding window algorithm with Redis backend.\",\n",
    "    \"I think the weather will be good tomorrow. Should we go for a walk?\",\n",
    "]\n",
    "\n",
    "result = summarize_history(test_messages, max_sentences=4)\n",
    "\n",
    "if result is not None:\n",
    "    print(\"Your extracted summary:\")\n",
    "    for i, sentence in enumerate(result):\n",
    "        print(f\"  {i+1}. {sentence}\")\n",
    "\n",
    "    # Check that it picked technical sentences over filler\n",
    "    technical_keywords = ['JWT', 'token', 'database', 'PostgreSQL', 'API', 'migration', 'bug']\n",
    "    technical_count = sum(1 for s in result\n",
    "                         if any(kw.lower() in s.lower() for kw in technical_keywords))\n",
    "    print(f\"\\nTechnical sentences selected: {technical_count}/{len(result)}\")\n",
    "    if technical_count >= 3:\n",
    "        print(\"Excellent! Your TF-IDF correctly prioritizes technical content.\")\n",
    "    else:\n",
    "        print(\"Hmm, try adjusting â€” TF-IDF should favor rare, specific words.\")\n",
    "else:\n",
    "    print(\"TODO not yet implemented. Complete the function above!\")"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Todo1 Solution\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/15_todo1_solution.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_15_todo1_solution"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the reference solution (collapse this cell after attempting the TODO):"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference solution for summarize_history\n",
    "\n",
    "def summarize_history_solution(messages, max_sentences=5):\n",
    "    \"\"\"Reference solution: TF-IDF extractive summarization.\"\"\"\n",
    "    # Step 1: Split into sentences\n",
    "    all_text = \" \".join(messages)\n",
    "    raw_sentences = re.split(r'(?<=[.!?])\\s+', all_text)\n",
    "    sentences = [s.strip() for s in raw_sentences if len(s.strip()) >= 10]\n",
    "\n",
    "    if len(sentences) <= max_sentences:\n",
    "        return sentences\n",
    "\n",
    "    # Step 2: TF-IDF scoring\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    scores = tfidf_matrix.toarray().sum(axis=1)\n",
    "\n",
    "    # Step 3: Select top sentences in original order\n",
    "    top_indices = np.argsort(scores)[::-1][:max_sentences]\n",
    "    top_indices_sorted = sorted(top_indices)\n",
    "\n",
    "    return [sentences[i] for i in top_indices_sorted]\n",
    "\n",
    "\n",
    "# Verify the reference solution\n",
    "result_ref = summarize_history_solution(test_messages, max_sentences=4)\n",
    "print(\"Reference solution output:\")\n",
    "for i, sentence in enumerate(result_ref):\n",
    "    print(f\"  {i+1}. {sentence}\")\n",
    "\n",
    "original_tokens_test = sum(estimate_tokens(m) for m in test_messages)\n",
    "summary_tokens_test = sum(estimate_tokens(s) for s in result_ref)\n",
    "print(f\"\\nOriginal: {original_tokens_test} tokens -> Summary: {summary_tokens_test} tokens\")\n",
    "print(f\"Compression ratio: {summary_tokens_test/original_tokens_test:.1%}\")"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Strategy4 Isolate\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/16_strategy4_isolate.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_16_strategy4_isolate"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Strategy 4: Isolate (SubAgentManager)\n",
    "\n",
    "Split context across multiple agents with clean, focused windows. Each sub-agent dives deep into one area and returns a condensed summary."
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubAgentManager:\n",
    "    \"\"\"\n",
    "    Strategy 4: Isolate â€” Sub-agent architectures with separate context windows.\n",
    "\n",
    "    Like delegating research to team members who report back summaries.\n",
    "    Anthropic's multi-agent researcher outperformed single-agent on SWE-bench.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_summary_tokens=500):\n",
    "        self.max_summary_tokens = max_summary_tokens\n",
    "        self.sub_agents = []\n",
    "        self.results = []\n",
    "\n",
    "    def dispatch(self, task, context, agent_id=None):\n",
    "        \"\"\"\n",
    "        Give a sub-agent a focused task with limited context.\n",
    "        In production, this would call an LLM. Here we simulate.\n",
    "\n",
    "        Args:\n",
    "            task: what the sub-agent should do\n",
    "            context: the focused context for this sub-agent\n",
    "            agent_id: optional identifier\n",
    "\n",
    "        Returns:\n",
    "            dict with agent metadata\n",
    "        \"\"\"\n",
    "        agent_id = agent_id or f\"agent_{len(self.sub_agents)}\"\n",
    "        context_tokens = estimate_tokens(context)\n",
    "\n",
    "        agent_info = {\n",
    "            \"agent_id\": agent_id,\n",
    "            \"task\": task,\n",
    "            \"context_tokens\": context_tokens,\n",
    "            \"status\": \"dispatched\"\n",
    "        }\n",
    "        self.sub_agents.append(agent_info)\n",
    "        return agent_info\n",
    "\n",
    "    def simulate_execution(self, context):\n",
    "        \"\"\"\n",
    "        Simulate a sub-agent processing its context and producing a summary.\n",
    "        In production, this calls an LLM. Here we use extractive summarization.\n",
    "        \"\"\"\n",
    "        # Extract key lines (simulating what an LLM would summarize)\n",
    "        lines = context.split(\"\\n\")\n",
    "        # Keep lines with code-like patterns (def, class, import, return)\n",
    "        key_patterns = ['def ', 'class ', 'import ', 'return ', '@', 'raise ',\n",
    "                        'Column(', 'router.', 'assert ']\n",
    "        key_lines = [l.strip() for l in lines\n",
    "                     if any(p in l for p in key_patterns) and len(l.strip()) > 5]\n",
    "\n",
    "        # Deduplicate and limit\n",
    "        seen = set()\n",
    "        unique_lines = []\n",
    "        for line in key_lines:\n",
    "            if line not in seen:\n",
    "                seen.add(line)\n",
    "                unique_lines.append(line)\n",
    "\n",
    "        # Truncate to fit summary budget\n",
    "        summary_lines = []\n",
    "        tokens = 0\n",
    "        for line in unique_lines:\n",
    "            line_tokens = estimate_tokens(line)\n",
    "            if tokens + line_tokens > self.max_summary_tokens:\n",
    "                break\n",
    "            summary_lines.append(line)\n",
    "            tokens += line_tokens\n",
    "\n",
    "        return \"\\n\".join(summary_lines) if summary_lines else \"No key findings.\"\n",
    "\n",
    "    def collect_results(self):\n",
    "        \"\"\"\n",
    "        Gather condensed results from all sub-agents.\n",
    "        Each result is a short summary â€” much smaller than the original context.\n",
    "        \"\"\"\n",
    "        collected = []\n",
    "        for agent in self.sub_agents:\n",
    "            collected.append({\n",
    "                \"agent_id\": agent[\"agent_id\"],\n",
    "                \"task\": agent[\"task\"],\n",
    "                \"context_tokens\": agent[\"context_tokens\"],\n",
    "                \"status\": \"completed\"\n",
    "            })\n",
    "        return collected\n",
    "\n",
    "    def format_for_lead_agent(self, summaries):\n",
    "        \"\"\"\n",
    "        Format sub-agent summaries for the lead agent's context.\n",
    "        The lead agent sees compact summaries, not raw documents.\n",
    "        \"\"\"\n",
    "        blocks = []\n",
    "        for agent_id, summary in summaries:\n",
    "            blocks.append(f\"<sub_agent id='{agent_id}'>\\n{summary}\\n</sub_agent>\")\n",
    "        return \"\\n\\n\".join(blocks)"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Split a research task across 3 sub-agents\n",
    "\n",
    "manager = SubAgentManager(max_summary_tokens=300)\n",
    "\n",
    "# The lead agent needs to answer: \"How does authentication work in this codebase?\"\n",
    "# Instead of loading all 15 files, we dispatch 3 focused sub-agents.\n",
    "\n",
    "tasks = [\n",
    "    (\"auth_specialist\", \"Analyze authentication flow and security mechanisms\",\n",
    "     [\"auth/login.py\", \"auth/permissions.py\"]),\n",
    "    (\"data_specialist\", \"Analyze user data model and database schema\",\n",
    "     [\"models/user.py\", \"config/database.py\", \"migrations/001_initial.py\"]),\n",
    "    (\"test_specialist\", \"Review test coverage for authentication\",\n",
    "     [\"tests/test_auth.py\"]),\n",
    "]\n",
    "\n",
    "print(\"Dispatching sub-agents:\\n\")\n",
    "total_sub_context = 0\n",
    "summaries = []\n",
    "\n",
    "for agent_id, task, file_ids in tasks:\n",
    "    # Each sub-agent gets ONLY its relevant files\n",
    "    context_parts = [selector.fetch(fid) for fid in file_ids if selector.fetch(fid)]\n",
    "    sub_context = \"\\n\\n\".join(context_parts)\n",
    "    sub_tokens = estimate_tokens(sub_context)\n",
    "    total_sub_context += sub_tokens\n",
    "\n",
    "    manager.dispatch(task, sub_context, agent_id)\n",
    "\n",
    "    # Simulate execution\n",
    "    summary = manager.simulate_execution(sub_context)\n",
    "    summary_tokens = estimate_tokens(summary)\n",
    "    summaries.append((agent_id, summary))\n",
    "\n",
    "    print(f\"  {agent_id}:\")\n",
    "    print(f\"    Task: {task}\")\n",
    "    print(f\"    Files: {file_ids}\")\n",
    "    print(f\"    Context: {sub_tokens:,} tokens\")\n",
    "    print(f\"    Summary: {summary_tokens} tokens\")\n",
    "    print(f\"    Compression: {summary_tokens/sub_tokens*100:.0f}%\\n\")\n",
    "\n",
    "# What the lead agent actually sees\n",
    "lead_context = manager.format_for_lead_agent(summaries)\n",
    "lead_tokens = estimate_tokens(lead_context)\n",
    "\n",
    "# Compare with the naive approach (loading all files)\n",
    "naive_tokens = selector.eager_load_cost()\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(f\"  Naive (load all files):    {naive_tokens:>6,} tokens\")\n",
    "print(f\"  Isolation (3 summaries):   {lead_tokens:>6,} tokens\")\n",
    "print(f\"  Savings:                   {naive_tokens - lead_tokens:>6,} tokens ({(1 - lead_tokens/naive_tokens)*100:.0f}%)\")\n",
    "print(\"=\" * 55)"
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Todo2\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/17_todo2.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_17_todo2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Implement `dispatch_to_subagents`\n",
    "\n",
    "Now it is your turn. Implement a function that takes a set of tasks and documents, automatically splits them across sub-agents with isolated contexts, and collects their condensed results."
   ],
   "id": "cell_31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_to_subagents(tasks, documents, max_summary_tokens=300):\n",
    "    \"\"\"\n",
    "    Split research across N sub-agents, each with isolated context.\n",
    "\n",
    "    Args:\n",
    "        tasks: list of dicts, each with:\n",
    "            - 'name': sub-agent identifier\n",
    "            - 'description': what this agent should investigate\n",
    "            - 'doc_ids': list of document IDs this agent should see\n",
    "        documents: dict mapping doc_id -> full content string\n",
    "        max_summary_tokens: max tokens per sub-agent summary\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'summaries': list of (agent_name, summary_text) tuples\n",
    "            - 'total_input_tokens': total tokens fed to all sub-agents\n",
    "            - 'total_output_tokens': total tokens in all summaries\n",
    "            - 'compression_ratio': output/input ratio\n",
    "            - 'per_agent': list of dicts with per-agent stats\n",
    "\n",
    "    How to implement:\n",
    "    1. For each task, gather the documents specified by doc_ids\n",
    "    2. Concatenate those documents as the sub-agent's context\n",
    "    3. Generate an extractive summary (keep lines matching code patterns)\n",
    "    4. Truncate summary to max_summary_tokens\n",
    "    5. Collect all summaries and compute statistics\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # For each task:\n",
    "    #   1. Gather documents: join documents[doc_id] for each doc_id in task['doc_ids']\n",
    "    #   2. Count tokens in the gathered context\n",
    "    #   3. Generate extractive summary:\n",
    "    #      - Split context into lines\n",
    "    #      - Keep lines containing: 'def ', 'class ', 'import ', 'return ',\n",
    "    #        '@', 'raise ', 'Column(', 'assert '\n",
    "    #      - Deduplicate\n",
    "    #      - Truncate to max_summary_tokens\n",
    "    #   4. Store (task['name'], summary) in summaries list\n",
    "    #   5. Track per-agent stats: name, input_tokens, output_tokens\n",
    "    #\n",
    "    # After all tasks:\n",
    "    #   - Compute total_input_tokens, total_output_tokens, compression_ratio\n",
    "    #   - Return the results dict\n",
    "    #\n",
    "    # YOUR CODE BELOW:\n",
    "    # ==============================\n",
    "\n",
    "    pass  # Replace with your implementation\n",
    "\n",
    "\n",
    "# âœ… Verification\n",
    "test_tasks = [\n",
    "    {'name': 'auth_agent', 'description': 'Analyze auth',\n",
    "     'doc_ids': ['auth/login.py', 'auth/permissions.py']},\n",
    "    {'name': 'model_agent', 'description': 'Analyze models',\n",
    "     'doc_ids': ['models/user.py', 'models/product.py']},\n",
    "]\n",
    "\n",
    "test_docs = {fid: selector.fetch(fid) for fid in\n",
    "             ['auth/login.py', 'auth/permissions.py', 'models/user.py', 'models/product.py']}\n",
    "\n",
    "result = dispatch_to_subagents(test_tasks, test_docs)\n",
    "\n",
    "if result is not None:\n",
    "    print(\"Your sub-agent dispatch results:\")\n",
    "    print(f\"  Total input tokens:  {result['total_input_tokens']:,}\")\n",
    "    print(f\"  Total output tokens: {result['total_output_tokens']:,}\")\n",
    "    print(f\"  Compression ratio:   {result['compression_ratio']:.1%}\")\n",
    "    print(f\"\\n  Per-agent breakdown:\")\n",
    "    for agent in result['per_agent']:\n",
    "        print(f\"    {agent['name']}: {agent['input_tokens']} -> {agent['output_tokens']} tokens\")\n",
    "    print(f\"\\n  Summaries:\")\n",
    "    for name, summary in result['summaries']:\n",
    "        print(f\"    [{name}]: {summary[:80]}...\")\n",
    "else:\n",
    "    print(\"TODO not yet implemented. Complete the function above!\")"
   ],
   "id": "cell_32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Todo2 Solution\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/18_todo2_solution.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_18_todo2_solution"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the reference solution:"
   ],
   "id": "cell_33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference solution for dispatch_to_subagents\n",
    "\n",
    "def dispatch_to_subagents_solution(tasks, documents, max_summary_tokens=300):\n",
    "    \"\"\"Reference solution: dispatch tasks to isolated sub-agents.\"\"\"\n",
    "    summaries = []\n",
    "    per_agent = []\n",
    "    total_input = 0\n",
    "    total_output = 0\n",
    "\n",
    "    key_patterns = ['def ', 'class ', 'import ', 'return ', '@', 'raise ',\n",
    "                    'Column(', 'assert ']\n",
    "\n",
    "    for task in tasks:\n",
    "        # Step 1: Gather documents\n",
    "        context_parts = [documents[did] for did in task['doc_ids'] if did in documents]\n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        input_tokens = estimate_tokens(context)\n",
    "        total_input += input_tokens\n",
    "\n",
    "        # Step 2: Extractive summary\n",
    "        lines = context.split(\"\\n\")\n",
    "        key_lines = [l.strip() for l in lines\n",
    "                     if any(p in l for p in key_patterns) and len(l.strip()) > 5]\n",
    "\n",
    "        # Deduplicate\n",
    "        seen = set()\n",
    "        unique = []\n",
    "        for line in key_lines:\n",
    "            if line not in seen:\n",
    "                seen.add(line)\n",
    "                unique.append(line)\n",
    "\n",
    "        # Truncate to budget\n",
    "        summary_lines = []\n",
    "        tokens = 0\n",
    "        for line in unique:\n",
    "            lt = estimate_tokens(line)\n",
    "            if tokens + lt > max_summary_tokens:\n",
    "                break\n",
    "            summary_lines.append(line)\n",
    "            tokens += lt\n",
    "\n",
    "        summary = \"\\n\".join(summary_lines) if summary_lines else \"No key findings.\"\n",
    "        output_tokens = estimate_tokens(summary)\n",
    "        total_output += output_tokens\n",
    "\n",
    "        summaries.append((task['name'], summary))\n",
    "        per_agent.append({\n",
    "            'name': task['name'],\n",
    "            'input_tokens': input_tokens,\n",
    "            'output_tokens': output_tokens\n",
    "        })\n",
    "\n",
    "    compression = total_output / total_input if total_input > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'summaries': summaries,\n",
    "        'total_input_tokens': total_input,\n",
    "        'total_output_tokens': total_output,\n",
    "        'compression_ratio': compression,\n",
    "        'per_agent': per_agent\n",
    "    }\n",
    "\n",
    "\n",
    "# Verify reference solution\n",
    "result_ref = dispatch_to_subagents_solution(test_tasks, test_docs)\n",
    "print(\"Reference solution:\")\n",
    "print(f\"  Total input:  {result_ref['total_input_tokens']:,} tokens\")\n",
    "print(f\"  Total output: {result_ref['total_output_tokens']:,} tokens\")\n",
    "print(f\"  Compression:  {result_ref['compression_ratio']:.1%}\")\n",
    "for agent in result_ref['per_agent']:\n",
    "    print(f\"  {agent['name']}: {agent['input_tokens']} -> {agent['output_tokens']} tokens\")"
   ],
   "id": "cell_34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Complete Engine\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/19_complete_engine.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_19_complete_engine"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 (continued). The Complete ContextEngine\n",
    "\n",
    "Now we combine all four strategies into a single engine that manages the entire context budget."
   ],
   "id": "cell_35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEngine:\n",
    "    \"\"\"\n",
    "    The Complete Context Engine â€” all four strategies working together.\n",
    "\n",
    "    This is the production pattern used (in various forms) by Claude Code,\n",
    "    Cursor, Devin, and other frontier agent systems.\n",
    "\n",
    "    Architecture:\n",
    "        1. Write:    MemoryStore persists facts outside the window\n",
    "        2. Select:   DocumentSelector retrieves just-in-time\n",
    "        3. Compress: ContextCompressor summarizes and compacts\n",
    "        4. Isolate:  SubAgentManager splits across focused agents\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_tokens=128000, reserved_for_output=35000):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.reserved = reserved_for_output\n",
    "        self.available = max_tokens - reserved_for_output\n",
    "\n",
    "        # Initialize all four strategy components\n",
    "        self.memory = MemoryStore()\n",
    "        self.selector = DocumentSelector()\n",
    "        self.compressor = ContextCompressor()\n",
    "        self.sub_agent_mgr = SubAgentManager(max_summary_tokens=500)\n",
    "\n",
    "        # Budget allocation (percentage of available tokens)\n",
    "        self.budget_allocation = {\n",
    "            \"system\":   0.10,  # 10% for system prompt\n",
    "            \"memory\":   0.05,  # 5% for persistent memory\n",
    "            \"history\":  0.30,  # 30% for conversation history\n",
    "            \"retrieved\": 0.45, # 45% for retrieved documents\n",
    "            \"query\":    0.10,  # 10% for the current query\n",
    "        }\n",
    "\n",
    "    def _compute_budgets(self):\n",
    "        \"\"\"Compute token budgets for each context section.\"\"\"\n",
    "        return {k: int(self.available * v)\n",
    "                for k, v in self.budget_allocation.items()}\n",
    "\n",
    "    def assemble(self, query, system_prompt, history, doc_query=None):\n",
    "        \"\"\"\n",
    "        Assemble the full context using all four strategies.\n",
    "\n",
    "        Returns:\n",
    "            dict with context string, token breakdown, and metadata\n",
    "        \"\"\"\n",
    "        budgets = self._compute_budgets()\n",
    "\n",
    "        # --- Strategy 1: Write (load persistent memory) ---\n",
    "        memory_block = self.memory.format_for_context()\n",
    "        memory_tokens = estimate_tokens(memory_block)\n",
    "\n",
    "        # --- Strategy 2: Select (retrieve relevant documents) ---\n",
    "        retrieved_docs = []\n",
    "        retrieved_tokens = 0\n",
    "        if doc_query and self.selector.index:\n",
    "            selected = self.selector.select(doc_query, top_k=5)\n",
    "            for doc_id, score, meta in selected:\n",
    "                content = self.selector.fetch(doc_id)\n",
    "                if content:\n",
    "                    doc_tokens = estimate_tokens(content)\n",
    "                    if retrieved_tokens + doc_tokens <= budgets[\"retrieved\"]:\n",
    "                        retrieved_docs.append((doc_id, content, score))\n",
    "                        retrieved_tokens += doc_tokens\n",
    "\n",
    "        # --- Strategy 3: Compress (fit history into budget) ---\n",
    "        # First, clear tool results\n",
    "        cleaned_history, _ = self.compressor.clear_tool_results(history)\n",
    "        # Then truncate to fit budget\n",
    "        compressed_history, history_tokens = self.compressor.compress_history(\n",
    "            cleaned_history, budgets[\"history\"]\n",
    "        )\n",
    "\n",
    "        # --- Strategy 4: Isolate (not used during assembly, but available) ---\n",
    "        # Sub-agent isolation happens before assembly, at dispatch time\n",
    "\n",
    "        # --- Assemble the final context ---\n",
    "        system_tokens = estimate_tokens(system_prompt)\n",
    "        query_tokens = estimate_tokens(query)\n",
    "\n",
    "        context = f\"<system>\\n{system_prompt}\\n</system>\\n\\n\"\n",
    "\n",
    "        if memory_block:\n",
    "            context += f\"{memory_block}\\n\\n\"\n",
    "\n",
    "        if compressed_history:\n",
    "            context += \"<history>\\n\"\n",
    "            context += \"\\n\".join(compressed_history)\n",
    "            context += \"\\n</history>\\n\\n\"\n",
    "\n",
    "        if retrieved_docs:\n",
    "            context += \"<retrieved_context>\\n\"\n",
    "            for doc_id, content, score in retrieved_docs:\n",
    "                # Include a relevance header\n",
    "                context += f\"  --- [{score:.2f}] {doc_id} ---\\n\"\n",
    "                context += f\"  {content[:500]}...\\n\\n\"  # truncate individual docs too\n",
    "            context += \"</retrieved_context>\\n\\n\"\n",
    "\n",
    "        context += f\"<query>{query}</query>\"\n",
    "\n",
    "        # Token accounting\n",
    "        total_tokens = estimate_tokens(context)\n",
    "        breakdown = {\n",
    "            \"system\": system_tokens,\n",
    "            \"memory\": memory_tokens,\n",
    "            \"history\": history_tokens,\n",
    "            \"retrieved\": retrieved_tokens,\n",
    "            \"query\": query_tokens,\n",
    "            \"total\": total_tokens,\n",
    "            \"available\": self.available,\n",
    "            \"utilization\": total_tokens / self.available * 100,\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"context\": context,\n",
    "            \"breakdown\": breakdown,\n",
    "            \"strategies_used\": {\n",
    "                \"write\": memory_tokens > 0,\n",
    "                \"select\": len(retrieved_docs) > 0,\n",
    "                \"compress\": len(compressed_history) < len(history),\n",
    "                \"isolate\": len(self.sub_agent_mgr.sub_agents) > 0,\n",
    "            },\n",
    "            \"docs_selected\": len(retrieved_docs),\n",
    "            \"history_compressed\": f\"{len(compressed_history)}/{len(history)} messages\",\n",
    "        }\n",
    "\n",
    "    def print_budget_report(self, breakdown):\n",
    "        \"\"\"Print a detailed budget utilization report.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"  CONTEXT ENGINE â€” BUDGET REPORT\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\n  Available budget:    {breakdown['available']:>8,} tokens\")\n",
    "        print(f\"  Total used:          {breakdown['total']:>8,} tokens\")\n",
    "        print(f\"  Utilization:         {breakdown['utilization']:>7.1f}%\")\n",
    "        print(f\"\\n  Breakdown:\")\n",
    "        for key in ['system', 'memory', 'history', 'retrieved', 'query']:\n",
    "            pct = breakdown[key] / breakdown['available'] * 100\n",
    "            bar_len = int(pct / 2)\n",
    "            bar = \"â–ˆ\" * bar_len + \"â–‘\" * (50 - bar_len)\n",
    "            print(f\"    {key:<12s} {breakdown[key]:>7,} tokens ({pct:>5.1f}%) {bar}\")\n",
    "        print(\"=\" * 60)"
   ],
   "id": "cell_36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the complete engine and populate it with our simulated data\n",
    "\n",
    "engine = ContextEngine(max_tokens=128000, reserved_for_output=35000)\n",
    "\n",
    "# Strategy 1: Populate memory\n",
    "for key, value, _, tags in [\n",
    "    (\"build\", \"pytest tests/ -v --cov\", \"project\", [\"test\"]),\n",
    "    (\"formatter\", \"Black, 88 char line length\", \"project\", [\"style\"]),\n",
    "    (\"database\", \"PostgreSQL 15, alembic migrations\", \"project\", [\"db\"]),\n",
    "    (\"deploy\", \"docker-compose up --build\", \"project\", [\"deploy\"]),\n",
    "    (\"naming\", \"snake_case for Python, camelCase for JS\", \"style\", [\"convention\"]),\n",
    "]:\n",
    "    engine.memory.save(key, value, category=\"project\")\n",
    "\n",
    "# Strategy 2: Register documents in selector\n",
    "for filepath, summary, content, tags in files:\n",
    "    engine.selector.register(filepath, summary, content, tags)\n",
    "\n",
    "# Now assemble context for a query\n",
    "query = \"Fix the JWT token refresh bug in the authentication module\"\n",
    "system_prompt = \"You are a senior software engineer. Help debug and fix issues in the codebase. Always explain your reasoning step by step.\"\n",
    "\n",
    "result = engine.assemble(\n",
    "    query=query,\n",
    "    system_prompt=system_prompt,\n",
    "    history=conversation,\n",
    "    doc_query=\"authentication JWT token refresh\"\n",
    ")\n",
    "\n",
    "# Print the budget report\n",
    "engine.print_budget_report(result[\"breakdown\"])\n",
    "\n",
    "print(f\"\\n  Strategies active:\")\n",
    "for strategy, used in result[\"strategies_used\"].items():\n",
    "    status = \"ON\" if used else \"OFF\"\n",
    "    print(f\"    {strategy:<10s}: {status}\")\n",
    "print(f\"\\n  Documents selected: {result['docs_selected']}\")\n",
    "print(f\"  History: {result['history_compressed']}\")"
   ],
   "id": "cell_37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Strategy Comparison\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/20_strategy_comparison.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_20_strategy_comparison"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together â€” The Strategy Comparison Experiment\n",
    "\n",
    "Now for the grand finale: we run the same query through four configurations and compare token usage."
   ],
   "id": "cell_38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration 1: No strategies (raw context dump)\n",
    "raw_context_parts = [\n",
    "    system_prompt,\n",
    "    \"\\n\".join(project_memory),\n",
    "    \"\\n\".join(conversation),\n",
    "    \"\\n\".join(selector.fetch(fid) for fid in selector.store),\n",
    "    query,\n",
    "]\n",
    "raw_tokens = sum(estimate_tokens(part) for part in raw_context_parts)\n",
    "\n",
    "# Configuration 2: Write only\n",
    "write_only_parts = [\n",
    "    system_prompt,\n",
    "    engine.memory.format_for_context(),\n",
    "    \"\\n\".join(conversation),\n",
    "    \"\\n\".join(selector.fetch(fid) for fid in selector.store),\n",
    "    query,\n",
    "]\n",
    "write_only_tokens = sum(estimate_tokens(part) for part in write_only_parts)\n",
    "\n",
    "# Configuration 3: Write + Select\n",
    "selected_for_query = engine.selector.select(\"authentication JWT token refresh\", top_k=3)\n",
    "selected_ids_q = [doc_id for doc_id, _, _ in selected_for_query]\n",
    "write_select_parts = [\n",
    "    system_prompt,\n",
    "    engine.memory.format_for_context(),\n",
    "    \"\\n\".join(conversation),\n",
    "    \"\\n\".join(selector.fetch(fid) for fid in selected_ids_q if selector.fetch(fid)),\n",
    "    query,\n",
    "]\n",
    "write_select_tokens = sum(estimate_tokens(part) for part in write_select_parts)\n",
    "\n",
    "# Configuration 4: Write + Select + Compress\n",
    "cleaned, _ = engine.compressor.clear_tool_results(conversation)\n",
    "compressed, comp_tokens = engine.compressor.compress_history(cleaned, int(engine.available * 0.3))\n",
    "write_select_compress_parts = [\n",
    "    system_prompt,\n",
    "    engine.memory.format_for_context(),\n",
    "    \"\\n\".join(compressed),\n",
    "    \"\\n\".join(selector.fetch(fid) for fid in selected_ids_q if selector.fetch(fid)),\n",
    "    query,\n",
    "]\n",
    "write_select_compress_tokens = sum(estimate_tokens(part) for part in write_select_compress_parts)\n",
    "\n",
    "# Configuration 5: All four strategies (Write + Select + Compress + Isolate)\n",
    "# For isolate, replace full docs with sub-agent summaries\n",
    "sub_tasks = [\n",
    "    {'name': 'auth', 'description': 'Auth analysis', 'doc_ids': selected_ids_q}\n",
    "]\n",
    "sub_docs = {fid: selector.fetch(fid) for fid in selected_ids_q if selector.fetch(fid)}\n",
    "sub_result = dispatch_to_subagents_solution(sub_tasks, sub_docs, max_summary_tokens=400)\n",
    "sub_summary_text = \"\\n\".join(s for _, s in sub_result['summaries'])\n",
    "\n",
    "all_four_parts = [\n",
    "    system_prompt,\n",
    "    engine.memory.format_for_context(),\n",
    "    \"\\n\".join(compressed),\n",
    "    sub_summary_text,\n",
    "    query,\n",
    "]\n",
    "all_four_tokens = sum(estimate_tokens(part) for part in all_four_parts)\n",
    "\n",
    "# Results\n",
    "configs = [\n",
    "    (\"No strategies\\n(raw dump)\", raw_tokens),\n",
    "    (\"Write\\nonly\", write_only_tokens),\n",
    "    (\"Write +\\nSelect\", write_select_tokens),\n",
    "    (\"Write + Select\\n+ Compress\", write_select_compress_tokens),\n",
    "    (\"All four\\nstrategies\", all_four_tokens),\n",
    "]\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  STRATEGY COMPARISON â€” TOKEN USAGE\")\n",
    "print(\"=\" * 65)\n",
    "for name, tokens in configs:\n",
    "    pct_of_raw = tokens / raw_tokens * 100\n",
    "    savings = raw_tokens - tokens\n",
    "    print(f\"  {name.replace(chr(10), ' '):<30s} {tokens:>8,} tokens  \"\n",
    "          f\"({pct_of_raw:>5.1f}% of raw)  saves {savings:>6,}\")\n",
    "print(\"=\" * 65)"
   ],
   "id": "cell_39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Comparison Barchart\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/21_comparison_barchart.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_21_comparison_barchart"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Visualization Checkpoint 2: Strategy Comparison Bar Chart"
   ],
   "id": "cell_40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart of token usage\n",
    "names = [c[0] for c in configs]\n",
    "tokens_list = [c[1] for c in configs]\n",
    "colors_bar = ['#E53935', '#FF7043', '#FFA726', '#66BB6A', '#26A69A']\n",
    "\n",
    "bars = axes[0].bar(range(len(names)), tokens_list, color=colors_bar,\n",
    "                    edgecolor='white', linewidth=2, width=0.65)\n",
    "\n",
    "# Add budget line\n",
    "axes[0].axhline(y=engine.available, color='red', linestyle='--', linewidth=2,\n",
    "                 label=f'Budget ({engine.available:,})')\n",
    "\n",
    "for bar, tok in zip(bars, tokens_list):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200,\n",
    "                 f'{tok:,}', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "axes[0].set_xticks(range(len(names)))\n",
    "axes[0].set_xticklabels(names, fontsize=9)\n",
    "axes[0].set_ylabel('Tokens', fontsize=12)\n",
    "axes[0].set_title('Token Usage by Configuration', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Savings percentage chart\n",
    "savings_pcts = [(1 - tok / raw_tokens) * 100 for tok in tokens_list]\n",
    "bars2 = axes[1].bar(range(len(names)), savings_pcts, color=colors_bar,\n",
    "                     edgecolor='white', linewidth=2, width=0.65)\n",
    "\n",
    "for bar, pct in zip(bars2, savings_pcts):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                 f'{pct:.0f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "axes[1].set_xticks(range(len(names)))\n",
    "axes[1].set_xticklabels(names, fontsize=9)\n",
    "axes[1].set_ylabel('Token Savings (%)', fontsize=12)\n",
    "axes[1].set_title('Cumulative Savings', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Context Engineering: Adding Strategies One by One',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Pie Charts\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/22_pie_charts.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_22_pie_charts"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Visualization Checkpoint 3: Context Composition â€” Before and After"
   ],
   "id": "cell_42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PIE 1: Before (no strategies)\n",
    "before_sizes = [\n",
    "    estimate_tokens(system_prompt),\n",
    "    sum(estimate_tokens(m) for m in project_memory),\n",
    "    sum(estimate_tokens(m) for m in conversation),\n",
    "    sum(estimate_tokens(selector.fetch(fid)) for fid in selector.store),\n",
    "    estimate_tokens(query),\n",
    "]\n",
    "before_labels = ['System\\nPrompt', 'Memory\\n(repeated)', 'Full\\nHistory',\n",
    "                 'All Docs\\n(eager)', 'Query']\n",
    "before_colors = ['#42A5F5', '#66BB6A', '#FFA726', '#EF5350', '#AB47BC']\n",
    "\n",
    "wedges1, texts1, autotexts1 = axes[0].pie(\n",
    "    before_sizes, labels=before_labels, colors=before_colors,\n",
    "    autopct='%1.0f%%', pctdistance=0.75, startangle=90,\n",
    "    textprops={'fontsize': 9}\n",
    ")\n",
    "axes[0].set_title(f'Before: No Strategies\\n({sum(before_sizes):,} tokens)',\n",
    "                   fontsize=13, fontweight='bold')\n",
    "\n",
    "# PIE 2: After (all four strategies)\n",
    "after_system = estimate_tokens(system_prompt)\n",
    "after_memory = engine.memory.get_token_cost()\n",
    "after_history = comp_tokens\n",
    "after_docs = estimate_tokens(sub_summary_text)\n",
    "after_query = estimate_tokens(query)\n",
    "\n",
    "after_sizes = [after_system, after_memory, after_history, after_docs, after_query]\n",
    "after_labels = ['System\\nPrompt', 'Memory\\n(file)', 'Compressed\\nHistory',\n",
    "                'Sub-agent\\nSummaries', 'Query']\n",
    "\n",
    "wedges2, texts2, autotexts2 = axes[1].pie(\n",
    "    after_sizes, labels=after_labels, colors=before_colors,\n",
    "    autopct='%1.0f%%', pctdistance=0.75, startangle=90,\n",
    "    textprops={'fontsize': 9}\n",
    ")\n",
    "axes[1].set_title(f'After: All Four Strategies\\n({sum(after_sizes):,} tokens)',\n",
    "                   fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Context Composition: Before vs After Optimization',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "reduction = (1 - sum(after_sizes) / sum(before_sizes)) * 100\n",
    "print(f\"Total reduction: {sum(before_sizes):,} -> {sum(after_sizes):,} tokens ({reduction:.0f}% savings)\")"
   ],
   "id": "cell_43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Results\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/23_results.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_23_results"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results â€” The Assembled Context\n",
    "\n",
    "Let us see the final assembled context itself, properly formatted."
   ],
   "id": "cell_44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full engine and display the output\n",
    "final_result = engine.assemble(\n",
    "    query=\"Fix the JWT token refresh bug in the authentication module\",\n",
    "    system_prompt=\"You are a senior software engineer. Help debug and fix issues.\",\n",
    "    history=conversation,\n",
    "    doc_query=\"authentication JWT token refresh\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  FINAL ASSEMBLED CONTEXT (truncated for display)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "context_lines = final_result[\"context\"].split(\"\\n\")\n",
    "# Show first 40 lines and last 10 lines\n",
    "display_lines = context_lines[:40]\n",
    "if len(context_lines) > 50:\n",
    "    display_lines.append(f\"\\n  ... [{len(context_lines) - 50} lines omitted] ...\\n\")\n",
    "    display_lines.extend(context_lines[-10:])\n",
    "\n",
    "for line in display_lines:\n",
    "    print(f\"  {line}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ],
   "id": "cell_45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final budget report with color-coded utilization\n",
    "\n",
    "engine.print_budget_report(final_result[\"breakdown\"])\n",
    "\n",
    "# Strategy summary\n",
    "print(\"\\n  Strategy Effectiveness:\")\n",
    "print(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "\n",
    "strategy_data = [\n",
    "    (\"Write\",    \"Persistent memory\",        \"Avoid repeating project facts\",\n",
    "     memory.get_token_cost(), \"tokens in memory file\"),\n",
    "    (\"Select\",   \"Just-in-time retrieval\",   f\"Loaded {final_result['docs_selected']} of {len(selector.store)} docs\",\n",
    "     final_result[\"breakdown\"][\"retrieved\"], \"tokens retrieved\"),\n",
    "    (\"Compress\", \"History summarization\",     final_result[\"history_compressed\"],\n",
    "     final_result[\"breakdown\"][\"history\"], \"tokens in history\"),\n",
    "    (\"Isolate\",  \"Sub-agent delegation\",     \"Condensed summaries from focused agents\",\n",
    "     estimate_tokens(sub_summary_text), \"tokens in summaries\"),\n",
    "]\n",
    "\n",
    "for name, mechanism, detail, tokens, unit in strategy_data:\n",
    "    status = \"ACTIVE\" if final_result[\"strategies_used\"].get(name.lower(), False) else \"READY\"\n",
    "    print(f\"  [{status:>6s}] {name:<10s} | {mechanism:<25s} | {tokens:>6,} {unit}\")\n",
    "    print(f\"           {'':<10s} | {detail}\")"
   ],
   "id": "cell_46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Waterfall\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/24_waterfall.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_24_waterfall"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grand summary visualization: strategy impact waterfall chart\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Waterfall chart showing how each strategy reduces tokens\n",
    "labels = ['Raw\\n(no strategies)', 'After\\nWrite', 'After\\nSelect',\n",
    "          'After\\nCompress', 'After\\nIsolate', 'Final\\nContext']\n",
    "values = [raw_tokens, write_only_tokens, write_select_tokens,\n",
    "          write_select_compress_tokens, all_four_tokens, all_four_tokens]\n",
    "\n",
    "# Compute the changes\n",
    "changes = [0]  # first bar starts from 0\n",
    "for i in range(1, len(values) - 1):\n",
    "    changes.append(values[i] - values[i-1])\n",
    "changes.append(0)  # last bar is the final total\n",
    "\n",
    "# Draw waterfall\n",
    "bottoms = [0] * len(labels)\n",
    "bar_colors = ['#E53935']  # first bar red (full)\n",
    "\n",
    "for i in range(1, len(values) - 1):\n",
    "    bottoms[i] = values[i]\n",
    "    bar_colors.append('#66BB6A')  # green for savings\n",
    "\n",
    "bottoms[-1] = 0\n",
    "bar_colors.append('#2196F3')  # blue for final\n",
    "\n",
    "# Draw the bars\n",
    "bar_heights = [raw_tokens]  # first bar\n",
    "for i in range(1, len(values) - 1):\n",
    "    bar_heights.append(values[i-1] - values[i])  # savings\n",
    "bar_heights.append(all_four_tokens)  # final bar\n",
    "\n",
    "# Recompute bottoms for waterfall\n",
    "cumulative = raw_tokens\n",
    "waterfall_bottoms = [0]\n",
    "waterfall_heights = [raw_tokens]\n",
    "\n",
    "for i in range(1, len(values) - 1):\n",
    "    saving = values[i-1] - values[i]\n",
    "    cumulative -= saving\n",
    "    waterfall_bottoms.append(cumulative)\n",
    "    waterfall_heights.append(saving)\n",
    "\n",
    "waterfall_bottoms.append(0)\n",
    "waterfall_heights.append(all_four_tokens)\n",
    "\n",
    "bars = ax.bar(range(len(labels)), waterfall_heights, bottom=waterfall_bottoms,\n",
    "              color=bar_colors, edgecolor='white', linewidth=2, width=0.6)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, height, bottom) in enumerate(zip(bars, waterfall_heights, waterfall_bottoms)):\n",
    "    if i == 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, raw_tokens + 200,\n",
    "                f'{raw_tokens:,}', ha='center', fontsize=10, fontweight='bold')\n",
    "    elif i == len(labels) - 1:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, all_four_tokens + 200,\n",
    "                f'{all_four_tokens:,}', ha='center', fontsize=10,\n",
    "                fontweight='bold', color='#1565C0')\n",
    "    else:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bottom + height/2,\n",
    "                f'-{height:,}', ha='center', fontsize=10,\n",
    "                fontweight='bold', color='white')\n",
    "\n",
    "# Add connector lines\n",
    "for i in range(len(labels) - 2):\n",
    "    y = waterfall_bottoms[i+1] + waterfall_heights[i+1] if i > 0 else raw_tokens\n",
    "    ax.plot([i + 0.3, i + 0.7], [waterfall_bottoms[i+1] + waterfall_heights[i+1]] * 2,\n",
    "            color='gray', linewidth=1, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Budget line\n",
    "ax.axhline(y=engine.available, color='red', linestyle='--', linewidth=2,\n",
    "           alpha=0.7, label=f'Budget limit ({engine.available:,})')\n",
    "\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, fontsize=10)\n",
    "ax.set_ylabel('Tokens', fontsize=12)\n",
    "ax.set_title('Context Engineering Waterfall: How Each Strategy Reduces Tokens',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='upper right')\n",
    "ax.grid(True, alpha=0.2, axis='y')\n",
    "\n",
    "# Custom legend\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#E53935', label='Raw context (no optimization)'),\n",
    "    mpatches.Patch(color='#66BB6A', label='Tokens saved by strategy'),\n",
    "    mpatches.Patch(color='#2196F3', label='Final optimized context'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, fontsize=10, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal reduction: {raw_tokens:,} -> {all_four_tokens:,} tokens\")\n",
    "print(f\"Savings: {raw_tokens - all_four_tokens:,} tokens ({(1 - all_four_tokens/raw_tokens)*100:.0f}%)\")"
   ],
   "id": "cell_47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Dashboard\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/25_dashboard.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_25_dashboard"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive dashboard\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Layout: 2x3 grid\n",
    "ax1 = fig.add_subplot(2, 3, 1)  # Strategy savings bars\n",
    "ax2 = fig.add_subplot(2, 3, 2)  # Before pie\n",
    "ax3 = fig.add_subplot(2, 3, 3)  # After pie\n",
    "ax4 = fig.add_subplot(2, 1, 2)  # Budget utilization timeline\n",
    "\n",
    "# 1. Individual strategy savings\n",
    "individual_savings = {\n",
    "    'Write': raw_tokens - write_only_tokens,\n",
    "    'Select': write_only_tokens - write_select_tokens,\n",
    "    'Compress': write_select_tokens - write_select_compress_tokens,\n",
    "    'Isolate': write_select_compress_tokens - all_four_tokens,\n",
    "}\n",
    "strat_names = list(individual_savings.keys())\n",
    "strat_values = list(individual_savings.values())\n",
    "strat_colors = ['#4CAF50', '#2196F3', '#FF9800', '#9C27B0']\n",
    "\n",
    "bars_ind = ax1.barh(strat_names, strat_values, color=strat_colors,\n",
    "                     edgecolor='white', linewidth=2, height=0.5)\n",
    "for bar, val in zip(bars_ind, strat_values):\n",
    "    ax1.text(bar.get_width() + 50, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:,}', va='center', fontsize=10, fontweight='bold')\n",
    "ax1.set_xlabel('Tokens Saved', fontsize=11)\n",
    "ax1.set_title('Savings per Strategy', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Before pie\n",
    "ax2.pie(before_sizes, labels=['System', 'Memory', 'History', 'Docs', 'Query'],\n",
    "        colors=before_colors, autopct='%1.0f%%', startangle=90,\n",
    "        textprops={'fontsize': 8})\n",
    "ax2.set_title(f'Before\\n({sum(before_sizes):,} tokens)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. After pie\n",
    "ax3.pie(after_sizes, labels=['System', 'Memory', 'History', 'Docs', 'Query'],\n",
    "        colors=before_colors, autopct='%1.0f%%', startangle=90,\n",
    "        textprops={'fontsize': 8})\n",
    "ax3.set_title(f'After\\n({sum(after_sizes):,} tokens)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 4. Budget utilization bar (horizontal stacked)\n",
    "sections = ['System', 'Memory', 'History', 'Retrieved', 'Query', 'Free']\n",
    "section_tokens = [\n",
    "    final_result[\"breakdown\"][\"system\"],\n",
    "    final_result[\"breakdown\"][\"memory\"],\n",
    "    final_result[\"breakdown\"][\"history\"],\n",
    "    final_result[\"breakdown\"][\"retrieved\"],\n",
    "    final_result[\"breakdown\"][\"query\"],\n",
    "    engine.available - final_result[\"breakdown\"][\"total\"],\n",
    "]\n",
    "section_colors = ['#42A5F5', '#66BB6A', '#FFA726', '#EF5350', '#AB47BC', '#E0E0E0']\n",
    "\n",
    "left = 0\n",
    "for name, tokens, color in zip(sections, section_tokens, section_colors):\n",
    "    width = tokens / engine.available * 100\n",
    "    ax4.barh(0, width, left=left, color=color, edgecolor='white',\n",
    "             linewidth=1.5, height=0.4, label=f'{name} ({tokens:,})')\n",
    "    if width > 4:\n",
    "        ax4.text(left + width/2, 0, f'{name}\\n{width:.0f}%',\n",
    "                 ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "    left += width\n",
    "\n",
    "ax4.set_xlim(0, 100)\n",
    "ax4.set_yticks([])\n",
    "ax4.set_xlabel('Budget Utilization (%)', fontsize=11)\n",
    "ax4.set_title('Final Context Budget Allocation', fontsize=12, fontweight='bold')\n",
    "ax4.legend(fontsize=8, loc='upper right', ncol=3)\n",
    "\n",
    "plt.suptitle('Complete Context Engine â€” Dashboard',\n",
    "             fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Reflection\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/26_reflection.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_26_reflection"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reflection and Next Steps\n",
    "\n",
    "### ðŸ’¡ Key Takeaways\n",
    "\n",
    "1. **Write** is the simplest strategy but prevents costly repetition. Claude Code's `CLAUDE.md` is a production example. Even saving 5 project facts eliminates hundreds of tokens of redundant conversation.\n",
    "\n",
    "2. **Select** delivers the largest single-strategy savings. Loading 3 files instead of 15 cuts document tokens by 80%. The key insight: maintain a cheap index, fetch content just-in-time.\n",
    "\n",
    "3. **Compress** is essential for long sessions. Conversation history grows linearly with time. TF-IDF extractive summarization keeps the signal (architectural decisions, bug reports) and discards the noise (greetings, confirmations). Clearing tool results alone can save thousands of tokens.\n",
    "\n",
    "4. **Isolate** shines on parallelizable tasks. Instead of one agent drowning in 15 files, three sub-agents each process 2-3 files and return compact summaries. Anthropic's multi-agent researcher demonstrated that isolation improves both quality and efficiency.\n",
    "\n",
    "5. **The strategies compound.** Each strategy targets a different part of the context budget. Write handles memory, Select handles documents, Compress handles history, Isolate handles complexity. Together, they can reduce context usage by 60-80%.\n",
    "\n",
    "### ðŸ¤” Reflection Questions\n",
    "\n",
    "1. In your own projects, which strategy would give you the **biggest immediate win**? Why?\n",
    "\n",
    "2. Claude Code auto-compacts at 95% capacity. Why 95% and not 50%? What is the tradeoff between compacting early vs late?\n",
    "\n",
    "3. The Isolate strategy works best for \"read-only\" tasks (research, analysis). Why might it be dangerous for \"write\" tasks (code editing, file creation)?\n",
    "\n",
    "4. Could you build a context engine that **learns** the optimal budget allocation over time? What signal would you use to tune the percentages?"
   ],
   "id": "cell_49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick self-check: revisit your predictions from Section 2\n",
    "\n",
    "print(\"Revisit Your Predictions:\")\n",
    "print(\"=\" * 55)\n",
    "print()\n",
    "print(\"1. Which strategy saves the MOST tokens?\")\n",
    "print(\"   Answer: SELECT (just-in-time retrieval)\")\n",
    "print(\"   Loading 3 of 15 files saves ~80% of document tokens.\")\n",
    "print()\n",
    "print(\"2. Which strategy is CHEAPEST to implement?\")\n",
    "print(\"   Answer: WRITE (persistent memory)\")\n",
    "print(\"   It is just JSON read/write â€” no ML, no embeddings.\")\n",
    "print()\n",
    "print(\"3. Do you need all four strategies?\")\n",
    "print(\"   Answer: Each targets a different budget section.\")\n",
    "print(\"   You COULD survive with just Select + Compress,\")\n",
    "print(\"   but all four together give the best results.\")\n",
    "print()\n",
    "print(\"Did your predictions match? If not, that is learning!\")"
   ],
   "id": "cell_50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: What You Built\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/27_what_you_built.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_27_what_you_built"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You Built\n",
    "\n",
    "In this notebook, you built a complete context engineering system:\n",
    "\n",
    "| Component | Class | Strategy | Key Method |\n",
    "|-----------|-------|----------|------------|\n",
    "| Persistent memory | `MemoryStore` | Write | `save()`, `search()`, `format_for_context()` |\n",
    "| Document retrieval | `DocumentSelector` | Select | `select()`, `fetch()` |\n",
    "| History compression | `ContextCompressor` | Compress | `compress_history()`, `clear_tool_results()` |\n",
    "| Sub-agent dispatch | `SubAgentManager` | Isolate | `dispatch()`, `simulate_execution()` |\n",
    "| Full engine | `ContextEngine` | All four | `assemble()`, `print_budget_report()` |\n",
    "\n",
    "### The Central Lesson\n",
    "\n",
    "Context engineering is not about having a bigger window. It is about using the window you have **intelligently**. The four strategies â€” Write, Select, Compress, Isolate â€” are the building blocks that every frontier agent system uses, from Claude Code to Cursor to Devin.\n",
    "\n",
    "The best context is not the most context. It is the **right** context, at the **right** time, in the **right** amount."
   ],
   "id": "cell_51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  BUILDING A COMPLETE CONTEXT ENGINE â€” KEY TAKEAWAYS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"  1. WRITE:    Persist facts outside the window\")\n",
    "print(\"               Save once, read on demand, never repeat\")\n",
    "print()\n",
    "print(\"  2. SELECT:   Retrieve just-in-time\")\n",
    "print(\"               Cheap index + lazy fetch = massive savings\")\n",
    "print()\n",
    "print(\"  3. COMPRESS: Summarize, don't truncate\")\n",
    "print(\"               TF-IDF extracts signal, drops noise\")\n",
    "print()\n",
    "print(\"  4. ISOLATE:  Divide and conquer\")\n",
    "print(\"               Sub-agents with focused context > one bloated agent\")\n",
    "print()\n",
    "print(\"  Combined: 60-80% token reduction with no quality loss.\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"  Great work! You have completed the Context Engine notebook.\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "cell_52"
  }
 ]
}