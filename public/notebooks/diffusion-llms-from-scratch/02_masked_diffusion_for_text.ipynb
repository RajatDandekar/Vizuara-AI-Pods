{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Masked Diffusion for Text ‚Äî Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1Szlw2uIb0f2EpTdm_4p4cFRzB3zgMemA\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/02_00_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Masked Diffusion for Text: The Forward Process\n",
    "\n",
    "*Part 2 of the Vizuara series on Diffusion LLMs from Scratch*\n",
    "*Estimated time: 35 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "In Notebook 1, we built a working image diffusion model. But we hit a wall: **Gaussian noise is meaningless for discrete tokens.** You cannot add 0.3 units of noise to the word \"cat.\"\n",
    "\n",
    "In this notebook, we solve that problem with a beautifully simple idea: **replace Gaussian noise with masking.** Instead of corrupting images with static, we corrupt text by replacing tokens with [MASK].\n",
    "\n",
    "This turns out to be equivalent to BERT's masked language modeling ‚Äî but generalized across all masking ratios. And it gives us a fully valid diffusion model for text.\n",
    "\n",
    "**By the end of this notebook, you will:**\n",
    "- Implement the masked forward process for text\n",
    "- Build and train a bidirectional Transformer that predicts masked tokens\n",
    "- See how this is mathematically connected to BERT\n",
    "- Visualize the model's predictions at different masking levels"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_01_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_01_intuition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "### Masking = Erasing Words from a Page\n",
    "\n",
    "In image diffusion, the forward process *destroys* an image by adding noise. After enough noise, you have pure static ‚Äî no information remains.\n",
    "\n",
    "For text, the equivalent of \"destroying\" a sentence is **masking out the words.** If every word is masked, no information remains ‚Äî just like pure noise for an image.\n",
    "\n",
    "| Timestep $t$ | Masking Probability | What the Model Sees |\n",
    "|---|---|---|\n",
    "| $t = 0.0$ | 0% masked | The cat sat on the mat |\n",
    "| $t = 0.2$ | 20% masked | The cat sat [M] the mat |\n",
    "| $t = 0.5$ | 50% masked | [M] cat [M] on [M] mat |\n",
    "| $t = 0.8$ | 80% masked | [M] [M] [M] on [M] [M] |\n",
    "| $t = 1.0$ | 100% masked | [M] [M] [M] [M] [M] [M] |\n",
    "\n",
    "### The BERT Connection\n",
    "\n",
    "If you have studied BERT, this should look very familiar. BERT is trained by masking 15% of tokens and predicting what they should be. Diffusion LLMs do exactly the same thing ‚Äî but instead of always masking 15%, they train with **every possible masking ratio from 0% to 100%.**\n",
    "\n",
    "This single change transforms BERT from a language *understanding* model into a full *generative* model.\n",
    "\n",
    "### ü§î Think About This\n",
    "\n",
    "If you saw \"[M] cat [M] on [M] mat\", what would you guess the masked words are? What clues helped you? Notice that you use **both left and right context** ‚Äî you know the first word is probably \"The\" because of \"cat\" to its right, not just because of what is to its left."
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Math\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_02_math.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_02_math"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "### The Forward Process\n",
    "\n",
    "At timestep $t$, each token is independently masked with probability $t$:\n",
    "\n",
    "$$q(x_t^{(i)} \\mid x_0^{(i)}) = \\begin{cases} x_0^{(i)} & \\text{with probability } 1 - t \\\\ [\\text{MASK}] & \\text{with probability } t \\end{cases}$$\n",
    "\n",
    "**What this says computationally:** For each token, flip a coin with bias $t$. Heads ‚Üí replace with [MASK]. Tails ‚Üí keep the original token. Each token is treated independently."
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worked Example\n",
    "\n",
    "Suppose we have 10 tokens and $t = 0.4$. Each token has a 40% chance of being masked. The expected number of masked tokens is $10 \\times 0.4 = 4$. On average, 4 out of 10 tokens are replaced with [MASK].\n",
    "\n",
    "### The Training Objective\n",
    "\n",
    "The loss is cross-entropy on masked positions ‚Äî identical to BERT:\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = \\mathbb{E}_{t \\sim U(0,1)} \\, \\mathbb{E}_{x_t \\sim q(x_t \\mid x_0)} \\left[ -\\sum_{i : x_t^{(i)} = [\\text{MASK}]} \\log p_\\theta\\!\\left(x_0^{(i)} \\mid x_t\\right) \\right]$$\n",
    "\n",
    "Breaking this down term by term:\n",
    "- $t \\sim U(0,1)$: randomly sample a masking ratio between 0% and 100%\n",
    "- $x_t \\sim q(x_t \\mid x_0)$: create a corrupted version by masking tokens with probability $t$\n",
    "- The sum runs over all masked positions $i$\n",
    "- $\\log p_\\theta(x_0^{(i)} \\mid x_t)$: log probability the model assigns to the correct token\n",
    "\n",
    "### Worked Loss Example\n",
    "\n",
    "Sentence: \"The cat sat\" (3 tokens). Sample $t = 0.67$, which masks 2 tokens: \"[M] cat [M]\".\n",
    "\n",
    "Model predicts:\n",
    "- Position 1: P(\"The\") = 0.6\n",
    "- Position 3: P(\"sat\") = 0.8\n",
    "\n",
    "Loss: $\\mathcal{L} = -\\log(0.6) - \\log(0.8) = 0.511 + 0.223 = 0.734$\n",
    "\n",
    "As training progresses, these probabilities increase and the loss decreases."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Setup Data\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_03_setup_data.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_03_setup_data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It ‚Äî Component by Component\n",
    "\n",
    "### 4.1 Setup and Dataset\n",
    "\n",
    "We will use a character-level dataset with simple repeating patterns. This is small enough to train in minutes but rich enough to show the model learning real structure."
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "VOCAB_SIZE = 16       # Token IDs 0-15, where 0 is [MASK]\n",
    "SEQ_LEN = 32          # Sequence length\n",
    "MASK_TOKEN = 0        # Token ID for [MASK]\n",
    "BATCH_SIZE = 64\n",
    "D_MODEL = 64\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 3\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pattern_data(batch_size, seq_len, vocab_size):\n",
    "    \"\"\"Generate sequences with repeating patterns.\n",
    "\n",
    "    Each sequence picks a random short pattern (length 2-4) and\n",
    "    tiles it to fill the sequence. The model must learn these patterns.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for _ in range(batch_size):\n",
    "        pattern_len = np.random.randint(2, 5)\n",
    "        # Use tokens 1 to vocab_size-1 (avoid 0 = MASK)\n",
    "        pattern = np.random.randint(1, vocab_size, size=pattern_len)\n",
    "        seq = np.tile(pattern, seq_len // pattern_len + 1)[:seq_len]\n",
    "        sequences.append(seq)\n",
    "    return torch.tensor(np.array(sequences), dtype=torch.long, device=device)\n",
    "\n",
    "# Show some examples\n",
    "examples = generate_pattern_data(5, SEQ_LEN, VOCAB_SIZE)\n",
    "for i, seq in enumerate(examples):\n",
    "    print(f\"Pattern {i+1}: {seq.tolist()}\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Masking Function\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_04_masking_function.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_04_masking_function"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Forward Process (Masking)\n",
    "\n",
    "This is the heart of masked diffusion ‚Äî randomly masking tokens with probability $t$."
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tokens(x_0, t):\n",
    "    \"\"\"Apply the forward masking process.\n",
    "\n",
    "    Args:\n",
    "        x_0: Clean token sequences, shape (B, L)\n",
    "        t: Masking probability for each sample, shape (B, 1)\n",
    "\n",
    "    Returns:\n",
    "        x_t: Masked sequences, shape (B, L)\n",
    "        mask: Boolean mask showing which positions were masked\n",
    "    \"\"\"\n",
    "    # For each token, independently mask with probability t\n",
    "    random_vals = torch.rand_like(x_0.float())\n",
    "    mask = random_vals < t                  # True where masked\n",
    "    x_t = x_0.clone()\n",
    "    x_t[mask] = MASK_TOKEN\n",
    "    return x_t, mask"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize the forward process at different timesteps\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 2.5))\n",
    "sample = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "\n",
    "for ax, t_val in zip(axes, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]):\n",
    "    t = torch.tensor([[t_val]], device=device)\n",
    "    masked, _ = mask_tokens(sample, t)\n",
    "    display = masked[0].cpu().numpy()\n",
    "\n",
    "    for pos in range(SEQ_LEN):\n",
    "        if display[pos] == MASK_TOKEN:\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color='#333333'))\n",
    "            ax.text(pos + 0.5, 0.5, 'M', ha='center', va='center',\n",
    "                    color='white', fontsize=7, fontweight='bold')\n",
    "        else:\n",
    "            color = plt.cm.Set2(display[pos] / VOCAB_SIZE)\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color=color))\n",
    "            ax.text(pos + 0.5, 0.5, str(display[pos]), ha='center',\n",
    "                    va='center', fontsize=7)\n",
    "\n",
    "    ax.set_xlim(0, SEQ_LEN)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(f't = {t_val}', fontsize=11)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.suptitle('Forward Process: Gradually Masking Tokens', fontsize=14, y=1.08)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Dark cells = [MASK]. As t increases, more tokens are masked.\")"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Stats Bert\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_05_stats_bert.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_05_stats_bert"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Masking Statistics\n",
    "\n",
    "Let us verify that the implementation matches the math."
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Run the forward process many times and check statistics\n",
    "n_trials = 1000\n",
    "t_values = torch.linspace(0.05, 0.95, 20)\n",
    "actual_fractions = []\n",
    "\n",
    "for t_val in t_values:\n",
    "    fracs = []\n",
    "    for _ in range(n_trials):\n",
    "        sample = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "        t = torch.tensor([[t_val.item()]], device=device)\n",
    "        _, mask = mask_tokens(sample, t)\n",
    "        fracs.append(mask.float().mean().item())\n",
    "    actual_fractions.append(np.mean(fracs))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t_values.numpy(), actual_fractions, 'o-', color='#1565c0',\n",
    "         label='Actual masked fraction', markersize=5)\n",
    "plt.plot([0, 1], [0, 1], '--', color='#e53935', label='Expected (y = t)')\n",
    "plt.xlabel('Masking probability t', fontsize=12)\n",
    "plt.ylabel('Fraction of tokens masked', fontsize=12)\n",
    "plt.title('Forward Process Verification', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚úÖ The actual masking fraction matches the expected fraction perfectly.\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 BERT vs Diffusion: Masking Ratio Comparison"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä BERT uses a fixed 15% masking rate. Diffusion trains at ALL rates.\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# BERT: spike at 0.15\n",
    "x = np.linspace(0, 1, 100)\n",
    "bert_dist = np.zeros_like(x)\n",
    "bert_dist[np.argmin(np.abs(x - 0.15))] = 1.0\n",
    "axes[0].bar([0.15], [1.0], width=0.03, color='#e53935', label='BERT (15% only)')\n",
    "axes[0].set_xlabel('Masking ratio t', fontsize=11)\n",
    "axes[0].set_ylabel('Training frequency', fontsize=11)\n",
    "axes[0].set_title('BERT: Fixed Masking Ratio', fontsize=13)\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Diffusion: uniform over [0, 1]\n",
    "axes[1].fill_between([0, 1], [1, 1], color='#1565c0', alpha=0.5,\n",
    "                      label='Diffusion LLM (all ratios)')\n",
    "axes[1].set_xlabel('Masking ratio t', fontsize=11)\n",
    "axes[1].set_ylabel('Training frequency', fontsize=11)\n",
    "axes[1].set_title('Diffusion LLM: All Masking Ratios', fontsize=13)\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_ylim(0, 1.5)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"BERT trains at one fixed ratio. Diffusion trains at EVERY ratio.\")\n",
    "print(\"This is what makes diffusion a full generative model.\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Transformer\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_06_transformer.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_06_transformer"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 The Bidirectional Transformer\n",
    "\n",
    "Our model is a standard Transformer **encoder** ‚Äî with **no causal mask**. Every token can attend to every other token, both left and right."
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Standard sinusoidal positional encoding.\"\"\"\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionLM(nn.Module):\n",
    "    \"\"\"Bidirectional Transformer for masked diffusion language modeling.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_layers, max_len=512):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, d_model),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(d_model, d_model),\n",
    "        )\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=0.1, batch_first=True, norm_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, n_layers)\n",
    "        self.output_head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x_t, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_t: Masked token IDs, shape (B, L)\n",
    "            t: Masking ratio, shape (B, 1)\n",
    "        Returns:\n",
    "            Logits, shape (B, L, V)\n",
    "        \"\"\"\n",
    "        h = self.token_embed(x_t)\n",
    "        h = self.pos_enc(h)\n",
    "        t_emb = self.time_mlp(t).unsqueeze(1)\n",
    "        h = h + t_emb\n",
    "        # Bidirectional ‚Äî NO causal mask!\n",
    "        h = self.transformer(h)\n",
    "        return self.output_head(h)\n",
    "\n",
    "\n",
    "model = DiffusionLM(VOCAB_SIZE, D_MODEL, N_HEADS, N_LAYERS).to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"DiffusionLM parameters: {n_params:,}\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Key Insight: Why No Causal Mask?\n",
    "\n",
    "In GPT, a causal mask prevents each position from seeing future tokens. This enforces left-to-right generation.\n",
    "\n",
    "In our model, we **want** every position to see every other position. This bidirectional attention lets the model:\n",
    "- Use tokens on the *right* to predict masked tokens on the *left*\n",
    "- Fill in tokens in any order, not just left-to-right\n",
    "- Overcome the \"reversal curse\" that plagues autoregressive models"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Training\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_07_training.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_07_training"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 The Training Loop"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion_lm(model, n_steps=3000, lr=3e-4):\n",
    "    \"\"\"Train the masked diffusion language model.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_steps)\n",
    "    losses = []\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        x_0 = generate_pattern_data(BATCH_SIZE, SEQ_LEN, VOCAB_SIZE)\n",
    "\n",
    "        # Random masking ratio for each sample\n",
    "        t = torch.rand(BATCH_SIZE, 1, device=device) * 0.98 + 0.02\n",
    "\n",
    "        # Mask tokens\n",
    "        x_t, mask = mask_tokens(x_0, t)\n",
    "\n",
    "        # Predict original tokens\n",
    "        logits = model(x_t, t)\n",
    "\n",
    "        # Cross-entropy loss ONLY at masked positions\n",
    "        logits_masked = logits[mask]\n",
    "        targets_masked = x_0[mask]\n",
    "\n",
    "        if logits_masked.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        loss = F.cross_entropy(logits_masked, targets_masked)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if (step + 1) % 500 == 0:\n",
    "            print(f\"Step {step+1}/{n_steps} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "print(\"Training...\")\n",
    "losses = train_diffusion_lm(model, n_steps=3000)\n",
    "print(\"Done!\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Training loss curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "window = 50\n",
    "smoothed = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "plt.plot(smoothed, color='#1565c0', linewidth=2)\n",
    "plt.xlabel('Training Step', fontsize=11)\n",
    "plt.ylabel('Cross-Entropy Loss', fontsize=11)\n",
    "plt.title('Diffusion LM Training Loss', fontsize=13)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo1\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_08_todo1.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_08_todo1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üîß Your Turn\n",
    "\n",
    "### TODO 1: Compute the Loss for a Single Example"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_loss(model, x_0, t_val):\n",
    "    \"\"\"Compute the masked diffusion loss for one sequence.\n",
    "\n",
    "    Args:\n",
    "        model: Trained DiffusionLM\n",
    "        x_0: Clean tokens, shape (1, L)\n",
    "        t_val: Float masking probability\n",
    "\n",
    "    Returns:\n",
    "        loss: Scalar loss value\n",
    "        n_masked: Number of masked tokens\n",
    "    \"\"\"\n",
    "    t = torch.tensor([[t_val]], device=device)\n",
    "    x_t, mask = mask_tokens(x_0, t)\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Get model predictions (logits)\n",
    "    logits = ???  # YOUR CODE HERE\n",
    "\n",
    "    # Step 2: Extract logits and targets at masked positions\n",
    "    logits_masked = ???  # YOUR CODE HERE\n",
    "    targets_masked = ???  # YOUR CODE HERE\n",
    "\n",
    "    # Step 3: Compute cross-entropy loss\n",
    "    loss = ???  # YOUR CODE HERE\n",
    "    # ==============================\n",
    "\n",
    "    return loss.item(), mask.sum().item()"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification\n",
    "try:\n",
    "    test_seq = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "    loss_val, n_masked = compute_single_loss(model, test_seq, 0.5)\n",
    "    assert isinstance(loss_val, float), \"Loss should be a float\"\n",
    "    assert n_masked > 0, \"Should have masked some tokens\"\n",
    "    print(f\"‚úÖ Loss = {loss_val:.4f}, masked {n_masked}/{SEQ_LEN} tokens\")\n",
    "except NameError:\n",
    "    print(\"‚ùå Replace the ??? placeholders.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo2\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_09_todo2.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_09_todo2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Predict Masked Tokens"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_masked(model, x_0, t_val, top_k=3):\n",
    "    \"\"\"Mask a sequence and show the model's top-k predictions.\n",
    "\n",
    "    Args:\n",
    "        model: Trained DiffusionLM\n",
    "        x_0: Clean tokens, shape (1, L)\n",
    "        t_val: Masking probability\n",
    "        top_k: Number of top predictions to show\n",
    "\n",
    "    Returns:\n",
    "        x_t: Masked sequence\n",
    "        predictions: List of (position, true_token, [(pred_token, prob), ...])\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    t = torch.tensor([[t_val]], device=device)\n",
    "    x_t, mask = mask_tokens(x_0, t)\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Get model logits\n",
    "    logits = ???  # YOUR CODE HERE\n",
    "\n",
    "    # Step 2: Convert to probabilities\n",
    "    probs = ???  # YOUR CODE HERE: softmax over vocabulary dimension\n",
    "\n",
    "    # Step 3: For each masked position, get top-k predictions\n",
    "    predictions = []\n",
    "    for pos in range(SEQ_LEN):\n",
    "        if mask[0, pos]:\n",
    "            top_probs, top_tokens = ???  # YOUR CODE: topk on probs[0, pos]\n",
    "            preds = [(t.item(), p.item()) for t, p in zip(top_tokens, top_probs)]\n",
    "            predictions.append((pos, x_0[0, pos].item(), preds))\n",
    "    # ==============================\n",
    "\n",
    "    model.train()\n",
    "    return x_t, predictions"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification\n",
    "try:\n",
    "    test_seq = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "    masked_seq, preds = predict_masked(model, test_seq, 0.5, top_k=3)\n",
    "    assert len(preds) > 0, \"Should have predictions\"\n",
    "    print(\"‚úÖ Model predictions for masked positions:\")\n",
    "    for pos, true_tok, top_preds in preds[:5]:\n",
    "        pred_str = \", \".join([f\"tok {t}({p:.2f})\" for t, p in top_preds])\n",
    "        correct = \"‚úÖ\" if top_preds[0][0] == true_tok else \"‚ùå\"\n",
    "        print(f\"  Pos {pos:2d}: true={true_tok:2d} | preds: {pred_str} {correct}\")\n",
    "except NameError:\n",
    "    print(\"‚ùå Replace the ??? placeholders.\")"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Results\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_10_results.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_10_results"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model predictions at different masking ratios\n",
    "test_seq = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "print(f\"Original sequence: {test_seq[0].tolist()}\\n\")\n",
    "\n",
    "for t_val in [0.2, 0.5, 0.8]:\n",
    "    masked_seq, preds = predict_masked(model, test_seq, t_val)\n",
    "    n_correct = sum(1 for _, true, top in preds if top[0][0] == true)\n",
    "    n_total = len(preds)\n",
    "    acc = n_correct / max(n_total, 1) * 100\n",
    "\n",
    "    masked_display = masked_seq[0].cpu().tolist()\n",
    "    display_str = \" \".join(\n",
    "        f\"[M]\" if tok == MASK_TOKEN else f\" {tok:2d}\" for tok in masked_display\n",
    "    )\n",
    "    print(f\"t={t_val}: {display_str}\")\n",
    "    print(f\"  Accuracy: {n_correct}/{n_total} = {acc:.0f}%\\n\")"
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üéØ Final Output"
   ],
   "id": "cell_31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Beautiful visualization: masked sequence with model's predictions\n",
    "torch.manual_seed(99)\n",
    "test_seq = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "masked_seq, preds = predict_masked(model, test_seq, 0.5, top_k=3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "display = masked_seq[0].cpu().numpy()\n",
    "original = test_seq[0].cpu().numpy()\n",
    "\n",
    "pred_dict = {pos: (true, top) for pos, true, top in preds}\n",
    "\n",
    "for pos in range(SEQ_LEN):\n",
    "    if display[pos] == MASK_TOKEN:\n",
    "        # Masked position ‚Äî show prediction\n",
    "        ax.add_patch(plt.Rectangle((pos, 0.5), 1, 0.5, color='#333333'))\n",
    "        ax.text(pos + 0.5, 0.75, '[M]', ha='center', va='center',\n",
    "                color='white', fontsize=8, fontweight='bold')\n",
    "\n",
    "        if pos in pred_dict:\n",
    "            true_tok, top_preds = pred_dict[pos]\n",
    "            for j, (tok, prob) in enumerate(top_preds[:3]):\n",
    "                color = '#2e7d32' if tok == true_tok else '#e53935'\n",
    "                ax.text(pos + 0.5, 0.35 - j * 0.12,\n",
    "                        f'{tok}({prob:.1f})', ha='center', fontsize=7,\n",
    "                        color=color, fontweight='bold' if j == 0 else 'normal')\n",
    "    else:\n",
    "        color = plt.cm.Set2(display[pos] / VOCAB_SIZE)\n",
    "        ax.add_patch(plt.Rectangle((pos, 0.5), 1, 0.5, color=color))\n",
    "        ax.text(pos + 0.5, 0.75, str(display[pos]), ha='center',\n",
    "                va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlim(0, SEQ_LEN)\n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Model Predictions for Masked Tokens (green = correct, red = wrong)',\n",
    "             fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Top row: the masked sequence. Below each [M]: model's top-3 predictions.\")"
   ],
   "id": "cell_32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Accuracy\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_11_accuracy.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_11_accuracy"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Accuracy vs masking ratio\n",
    "t_values = np.linspace(0.1, 0.95, 15)\n",
    "accuracies = []\n",
    "\n",
    "for t_val in t_values:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for _ in range(50):\n",
    "        test_seq = generate_pattern_data(1, SEQ_LEN, VOCAB_SIZE)\n",
    "        _, preds = predict_masked(model, test_seq, t_val, top_k=1)\n",
    "        correct += sum(1 for _, true, top in preds if top[0][0] == true)\n",
    "        total += len(preds)\n",
    "    accuracies.append(correct / max(total, 1) * 100)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(t_values, accuracies, 'o-', color='#1565c0', linewidth=2, markersize=6)\n",
    "plt.xlabel('Masking ratio t', fontsize=12)\n",
    "plt.ylabel('Prediction accuracy (%)', fontsize=12)\n",
    "plt.title('Model Accuracy vs Masking Ratio', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Higher masking = harder task (less context). Accuracy decreases as expected.\")"
   ],
   "id": "cell_33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_12_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_12_closing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reflection and Next Steps\n",
    "\n",
    "### ü§î Reflection Questions\n",
    "\n",
    "1. **Why is bidirectional attention crucial?** With causal (left-to-right) attention, the model could not use \"mat\" at position 6 to predict \"[M]\" at position 1. Bidirectional attention gives full context from both directions.\n",
    "\n",
    "2. **Why train with all masking ratios instead of just 15% like BERT?** BERT at 15% learns to fill in occasional blanks. But for *generation*, we start from 100% masked and progressively unmask. The model needs to handle every ratio from 0% to 100%.\n",
    "\n",
    "3. **At what masking ratio is the task hardest?** At very high $t$ (e.g., 90%), the model sees very few tokens. At very low $t$, most tokens are visible and the few masked ones are easy to infer. The hardest regime is high masking with limited context.\n",
    "\n",
    "### üèÜ Optional Challenges\n",
    "\n",
    "1. Try different timestep embedding strategies (learned vs sinusoidal)\n",
    "2. Compare model performance at different masking ratios ‚Äî plot a loss breakdown\n",
    "3. Visualize the attention patterns ‚Äî are they different from BERT?\n",
    "\n",
    "---\n",
    "\n",
    "**Up Next ‚Äî Notebook 3:** *Training a Diffusion LLM.* We will dive into the ELBO, train a complete masked diffusion language model on real text, and see how the mathematical theory confirms that \"train BERT at all masking ratios\" is a rigorous diffusion process."
   ],
   "id": "cell_34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "chatbot"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üí¨ AI Teaching Assistant ‚Äî Click ‚ñ∂ to start\n",
    "#@markdown This AI chatbot reads your notebook and can answer questions about any concept, code, or exercise.\n",
    "\n",
    "import json as _json\n",
    "import requests as _requests\n",
    "from google.colab import output as _output\n",
    "from IPython.display import display, HTML as _HTML, Markdown as _Markdown\n",
    "\n",
    "# --- Read notebook content for context ---\n",
    "def _get_notebook_context():\n",
    "    try:\n",
    "        from google.colab import _message\n",
    "        nb = _message.blocking_request(\"get_ipynb\", request=\"\", timeout_sec=10)\n",
    "        cells = nb.get(\"ipynb\", {}).get(\"cells\", [])\n",
    "        parts = []\n",
    "        for cell in cells:\n",
    "            src = \"\".join(cell.get(\"source\", []))\n",
    "            tags = cell.get(\"metadata\", {}).get(\"tags\", [])\n",
    "            if \"chatbot\" in tags:\n",
    "                continue\n",
    "            if src.strip():\n",
    "                ct = cell.get(\"cell_type\", \"unknown\")\n",
    "                parts.append(f\"[{ct.upper()}]\\n{src}\")\n",
    "        return \"\\n\\n---\\n\\n\".join(parts)\n",
    "    except Exception:\n",
    "        return \"Notebook content unavailable.\"\n",
    "\n",
    "_NOTEBOOK_CONTEXT = _get_notebook_context()\n",
    "_CHAT_HISTORY = []\n",
    "_API_URL = \"https://course-creator-brown.vercel.app/api/chat\"\n",
    "\n",
    "def _notebook_chat(question):\n",
    "    global _CHAT_HISTORY\n",
    "    try:\n",
    "        resp = _requests.post(_API_URL, json={\n",
    "            'question': question,\n",
    "            'context': _NOTEBOOK_CONTEXT[:100000],\n",
    "            'history': _CHAT_HISTORY[-10:],\n",
    "        }, timeout=60)\n",
    "        data = resp.json()\n",
    "        answer = data.get('answer', 'Sorry, I could not generate a response.')\n",
    "        _CHAT_HISTORY.append({'role': 'user', 'content': question})\n",
    "        _CHAT_HISTORY.append({'role': 'assistant', 'content': answer})\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f'Error connecting to teaching assistant: {str(e)}'\n",
    "\n",
    "_output.register_callback('notebook_chat', _notebook_chat)\n",
    "\n",
    "def ask(question):\n",
    "    \"\"\"Ask the AI teaching assistant a question about this notebook.\"\"\"\n",
    "    answer = _notebook_chat(question)\n",
    "    display(_Markdown(answer))\n",
    "\n",
    "print(\"\\u2705 AI Teaching Assistant is ready!\")\n",
    "print(\"\\U0001f4a1 Use the chat below, or call ask(\\'your question\\') in any cell.\")\n",
    "\n",
    "# --- Display chat widget ---\n",
    "display(_HTML('''<style>\n  .vc-wrap{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;max-width:100%;border-radius:16px;overflow:hidden;box-shadow:0 4px 24px rgba(0,0,0,.12);background:#fff;border:1px solid #e5e7eb}\n  .vc-hdr{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:16px 20px;display:flex;align-items:center;gap:12px}\n  .vc-avatar{width:42px;height:42px;background:rgba(255,255,255,.2);border-radius:50%;display:flex;align-items:center;justify-content:center;font-size:22px}\n  .vc-hdr h3{font-size:16px;font-weight:600;margin:0}\n  .vc-hdr p{font-size:12px;opacity:.85;margin:2px 0 0}\n  .vc-msgs{height:420px;overflow-y:auto;padding:16px;background:#f8f9fb;display:flex;flex-direction:column;gap:10px}\n  .vc-msg{display:flex;flex-direction:column;animation:vc-fade .25s ease}\n  .vc-msg.user{align-items:flex-end}\n  .vc-msg.bot{align-items:flex-start}\n  .vc-bbl{max-width:85%;padding:10px 14px;border-radius:16px;font-size:14px;line-height:1.55;word-wrap:break-word}\n  .vc-msg.user .vc-bbl{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border-bottom-right-radius:4px}\n  .vc-msg.bot .vc-bbl{background:#fff;color:#1a1a2e;border:1px solid #e8e8e8;border-bottom-left-radius:4px}\n  .vc-bbl code{background:rgba(0,0,0,.07);padding:2px 6px;border-radius:4px;font-size:13px;font-family:'Fira Code',monospace}\n  .vc-bbl pre{background:#1e1e2e;color:#cdd6f4;padding:12px;border-radius:8px;overflow-x:auto;margin:8px 0;font-size:13px}\n  .vc-bbl pre code{background:none;padding:0;color:inherit}\n  .vc-bbl h3,.vc-bbl h4{margin:10px 0 4px;font-size:15px}\n  .vc-bbl ul,.vc-bbl ol{margin:4px 0;padding-left:20px}\n  .vc-bbl li{margin:2px 0}\n  .vc-chips{display:flex;flex-wrap:wrap;gap:8px;padding:0 16px 12px;background:#f8f9fb}\n  .vc-chip{background:#fff;border:1px solid #d1d5db;border-radius:20px;padding:6px 14px;font-size:12px;cursor:pointer;transition:all .15s;color:#4b5563}\n  .vc-chip:hover{border-color:#667eea;color:#667eea;background:#f0f0ff}\n  .vc-input{display:flex;padding:12px 16px;background:#fff;border-top:1px solid #eee;gap:8px}\n  .vc-input input{flex:1;padding:10px 16px;border:2px solid #e8e8e8;border-radius:24px;font-size:14px;outline:none;transition:border-color .2s}\n  .vc-input input:focus{border-color:#667eea}\n  .vc-input button{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border:none;border-radius:50%;width:42px;height:42px;cursor:pointer;display:flex;align-items:center;justify-content:center;font-size:18px;transition:transform .1s}\n  .vc-input button:hover{transform:scale(1.05)}\n  .vc-input button:disabled{opacity:.5;cursor:not-allowed;transform:none}\n  .vc-typing{display:flex;gap:5px;padding:4px 0}\n  .vc-typing span{width:8px;height:8px;background:#667eea;border-radius:50%;animation:vc-bounce 1.4s infinite ease-in-out}\n  .vc-typing span:nth-child(2){animation-delay:.2s}\n  .vc-typing span:nth-child(3){animation-delay:.4s}\n  @keyframes vc-bounce{0%,80%,100%{transform:scale(0)}40%{transform:scale(1)}}\n  @keyframes vc-fade{from{opacity:0;transform:translateY(8px)}to{opacity:1;transform:translateY(0)}}\n  .vc-note{text-align:center;font-size:11px;color:#9ca3af;padding:8px 16px 12px;background:#fff}\n</style>\n<div class=\"vc-wrap\">\n  <div class=\"vc-hdr\">\n    <div class=\"vc-avatar\">&#129302;</div>\n    <div>\n      <h3>Vizuara Teaching Assistant</h3>\n      <p>Ask me anything about this notebook</p>\n    </div>\n  </div>\n  <div class=\"vc-msgs\" id=\"vcMsgs\">\n    <div class=\"vc-msg bot\">\n      <div class=\"vc-bbl\">&#128075; Hi! I've read through this entire notebook. Ask me about any concept, code block, or exercise &mdash; I'm here to help you learn!</div>\n    </div>\n  </div>\n  <div class=\"vc-chips\" id=\"vcChips\">\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Explain the main concept</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Help with the TODO exercise</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Summarize what I learned</span>\n  </div>\n  <div class=\"vc-input\">\n    <input type=\"text\" id=\"vcIn\" placeholder=\"Ask about concepts, code, exercises...\" />\n    <button id=\"vcSend\" onclick=\"vcSendMsg()\">&#10148;</button>\n  </div>\n  <div class=\"vc-note\">AI-generated &middot; Verify important information &middot; <a href=\"#\" onclick=\"vcClear();return false\" style=\"color:#667eea\">Clear chat</a></div>\n</div>\n<script>\n(function(){\n  var msgs=document.getElementById('vcMsgs'),inp=document.getElementById('vcIn'),\n      btn=document.getElementById('vcSend'),chips=document.getElementById('vcChips');\n\n  function esc(s){var d=document.createElement('div');d.textContent=s;return d.innerHTML}\n\n  function md(t){\n    return t\n      .replace(/```(\\w*)\\n([\\s\\S]*?)```/g,function(_,l,c){return '<pre><code>'+esc(c)+'</code></pre>'})\n      .replace(/`([^`]+)`/g,'<code>$1</code>')\n      .replace(/\\*\\*([^*]+)\\*\\*/g,'<strong>$1</strong>')\n      .replace(/\\*([^*]+)\\*/g,'<em>$1</em>')\n      .replace(/^#### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^## (.+)$/gm,'<h3>$1</h3>')\n      .replace(/^\\d+\\. (.+)$/gm,'<li>$1</li>')\n      .replace(/^- (.+)$/gm,'<li>$1</li>')\n      .replace(/\\n\\n/g,'<br><br>')\n      .replace(/\\n/g,'<br>');\n  }\n\n  function addMsg(text,isUser){\n    var m=document.createElement('div');m.className='vc-msg '+(isUser?'user':'bot');\n    var b=document.createElement('div');b.className='vc-bbl';\n    b.innerHTML=isUser?esc(text):md(text);\n    m.appendChild(b);msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function showTyping(){\n    var m=document.createElement('div');m.className='vc-msg bot';m.id='vcTyping';\n    m.innerHTML='<div class=\"vc-bbl\"><div class=\"vc-typing\"><span></span><span></span><span></span></div></div>';\n    msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function hideTyping(){var e=document.getElementById('vcTyping');if(e)e.remove()}\n\n  window.vcSendMsg=function(){\n    var q=inp.value.trim();if(!q)return;\n    inp.value='';chips.style.display='none';\n    addMsg(q,true);showTyping();btn.disabled=true;\n    google.colab.kernel.invokeFunction('notebook_chat',[q],{})\n      .then(function(r){\n        hideTyping();\n        var a=r.data['application/json'];\n        addMsg(typeof a==='string'?a:JSON.stringify(a),false);\n      })\n      .catch(function(){\n        hideTyping();\n        addMsg('Sorry, I encountered an error. Please check your internet connection and try again.',false);\n      })\n      .finally(function(){btn.disabled=false;inp.focus()});\n  };\n\n  window.vcAsk=function(q){inp.value=q;vcSendMsg()};\n  window.vcClear=function(){\n    msgs.innerHTML='<div class=\"vc-msg bot\"><div class=\"vc-bbl\">&#128075; Chat cleared. Ask me anything!</div></div>';\n    chips.style.display='flex';\n  };\n\n  inp.addEventListener('keypress',function(e){if(e.key==='Enter')vcSendMsg()});\n  inp.focus();\n})();\n</script>'''))"
   ],
   "id": "vizuara_chatbot"
  }
 ]
}