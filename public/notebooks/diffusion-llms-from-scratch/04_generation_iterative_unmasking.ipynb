{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Generation: Iterative Unmasking ‚Äî Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1N8Z5j5PJiwMRZO-F3b_vfz0oQi19MNIs\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/04_00_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Generation: Iterative Unmasking ‚Äî The Grand Finale\n",
    "\n",
    "*Part 4 of the Vizuara series on Diffusion LLMs from Scratch*\n",
    "*Estimated time: 35 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "chatbot"
    ]
   },
   "source": [
    "# ü§ñ AI Teaching Assistant\n",
    "\n",
    "Need help with this notebook? Open the **AI Teaching Assistant** ‚Äî it has already read this entire notebook and can help with concepts, code, and exercises.\n",
    "\n",
    "**[üëâ Open AI Teaching Assistant](https://pods.vizuara.ai/courses/diffusion-llms-from-scratch/practice/4/assistant)**\n",
    "\n",
    "*Tip: Open it in a separate tab and work through this notebook side-by-side.*\n"
   ],
   "id": "vizuara_chatbot"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "We have trained a model that predicts masked tokens. Now comes the payoff: **generating brand new text from scratch.**\n",
    "\n",
    "The process is called **iterative unmasking**: start with a fully masked sequence, predict all tokens, keep the most confident ones, re-mask the rest, and repeat. In just a handful of steps, coherent text emerges from pure [MASK] tokens.\n",
    "\n",
    "The remarkable thing? **Tokens appear in order of confidence, not left-to-right.** The model might fill in \"the\" at position 1 and \".\" at the end before it fills in the middle. It generates like an artist ‚Äî broad strokes first, details last.\n",
    "\n",
    "**By the end of this notebook, you will:**\n",
    "- Implement the full generation pipeline\n",
    "- Watch text materialize step-by-step from pure masks\n",
    "- Experiment with temperature, number of steps, and sampling strategies\n",
    "- Demonstrate infilling ‚Äî the killer feature of diffusion LLMs"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Artist Analogy\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_01_artist_analogy.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_01_artist_analogy"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "### The Artist Analogy ‚Äî Revisited\n",
    "\n",
    "An artist does not paint left to right. They:\n",
    "1. Start with a blank canvas\n",
    "2. Sketch the broadest composition (big shapes, layout)\n",
    "3. Add medium details (forms, proportions)\n",
    "4. Refine fine details (textures, edges)\n",
    "\n",
    "Our generation process works the same way:\n",
    "1. Start with all [MASK] tokens\n",
    "2. Fill in the most confident tokens first (common words, structural elements)\n",
    "3. Use that context to fill in less obvious tokens\n",
    "4. The last tokens are the trickiest ‚Äî subtle word choices that depend on everything else\n",
    "\n",
    "### ü§î Think About This\n",
    "\n",
    "What are the advantages of generating in confidence order vs left-to-right?\n",
    "\n",
    "- The ending can inform the beginning (bidirectional context)\n",
    "- Easy tokens settle first, creating scaffolding for harder tokens\n",
    "- The model can effectively \"change its mind\" through the iterative process"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Algorithm\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_02_algorithm.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_02_algorithm"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Generation Algorithm\n",
    "\n",
    "### Step-by-Step Walkthrough\n",
    "\n",
    "Using the article's example ‚Äî generating a 6-token sentence in 4 steps:\n",
    "\n",
    "**Step 1:** Input: [M] [M] [M] [M] [M] [M]\n",
    "Model is most confident about positions 1 and 6 ‚Üí unmask \"The\" and \"mat\"\n",
    "\n",
    "**Step 2:** Input: The [M] [M] [M] [M] mat\n",
    "Now has context from both ends ‚Üí unmask \"sat\" and \"the\"\n",
    "\n",
    "**Step 3:** Input: The [M] sat [M] the mat\n",
    "Strong bidirectional signal ‚Üí unmask \"cat\"\n",
    "\n",
    "**Step 4:** Input: The cat sat [M] the mat\n",
    "Only one mask left ‚Üí unmask \"on\"\n",
    "\n",
    "**Result: \"The cat sat on the mat\"**\n",
    "\n",
    "Notice: \"mat\" at position 6 was filled before \"cat\" at position 2. The model generated in **confidence order, not positional order.**\n",
    "\n",
    "### The Key Formula\n",
    "\n",
    "At each step, unmask the top-$k$ most confident predictions among currently masked positions. A simple schedule: $k = \\text{remaining\\_masks} / \\text{remaining\\_steps}$."
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Setup Training\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_03_setup_training.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_03_setup_training"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It ‚Äî Component by Component\n",
    "\n",
    "### 4.1 Rebuild and Train the Model\n",
    "\n",
    "We need a self-contained notebook, so we retrain on TinyShakespeare. This takes about 3-5 minutes on a T4 GPU."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import urllib.request\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "\n",
    "# Download TinyShakespeare\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = \"shakespeare.txt\"\n",
    "try:\n",
    "    with open(filepath, 'r') as f:\n",
    "        text = f.read()\n",
    "except FileNotFoundError:\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "    with open(filepath, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars) + 1\n",
    "MASK_TOKEN = 0\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 64\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 4\n",
    "\n",
    "char_to_id = {ch: i + 1 for i, ch in enumerate(chars)}\n",
    "id_to_char = {i + 1: ch for i, ch in enumerate(chars)}\n",
    "id_to_char[MASK_TOKEN] = '‚ñà'\n",
    "\n",
    "def encode(s):\n",
    "    return [char_to_id[c] for c in s]\n",
    "def decode(ids):\n",
    "    return ''.join(id_to_char.get(i, '?') for i in ids)\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n_seq = len(data) // SEQ_LEN\n",
    "sequences = data[:n_seq * SEQ_LEN].reshape(n_seq, SEQ_LEN).to(device)\n",
    "n_train = int(0.9 * len(sequences))\n",
    "train_data = sequences[:n_train]\n",
    "\n",
    "def mask_tokens(x_0, t):\n",
    "    mask = torch.rand_like(x_0.float()) < t\n",
    "    x_t = x_0.clone()\n",
    "    x_t[mask] = MASK_TOKEN\n",
    "    return x_t, mask\n",
    "\n",
    "print(f\"Vocab: {VOCAB_SIZE} | Sequences: {len(sequences):,} | Training: {n_train:,}\")"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class DiffusionLM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        self.time_mlp = nn.Sequential(nn.Linear(1, d_model), nn.SiLU(), nn.Linear(d_model, d_model))\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4,\n",
    "            dropout=0.1, batch_first=True, norm_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, n_layers)\n",
    "        self.output_head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x_t, t):\n",
    "        h = self.token_embed(x_t)\n",
    "        h = self.pos_enc(h)\n",
    "        h = h + self.time_mlp(t).unsqueeze(1)\n",
    "        h = self.transformer(h)\n",
    "        return self.output_head(h)\n",
    "\n",
    "model = DiffusionLM(VOCAB_SIZE, D_MODEL, N_HEADS, N_LAYERS).to(device)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training (~3-5 min on T4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "print(\"Training...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    perm = torch.randperm(len(train_data))\n",
    "    epoch_loss = []\n",
    "    for i in range(0, len(train_data) - BATCH_SIZE, BATCH_SIZE):\n",
    "        batch = train_data[perm[i:i+BATCH_SIZE]]\n",
    "        t = torch.rand(BATCH_SIZE, 1, device=device) * 0.98 + 0.02\n",
    "        x_t, mask = mask_tokens(batch, t)\n",
    "        logits = model(x_t, t)\n",
    "        if mask.sum() == 0: continue\n",
    "        loss = F.cross_entropy(logits[mask], batch[mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"  Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {np.mean(epoch_loss):.3f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Generate Function\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_04_generate_function.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_04_generate_function"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Basic Generation Function"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, seq_len=SEQ_LEN, num_steps=10, temperature=1.0):\n",
    "    \"\"\"Generate text via iterative confidence-based unmasking.\n",
    "\n",
    "    Args:\n",
    "        model: Trained DiffusionLM\n",
    "        seq_len: Length of sequence to generate\n",
    "        num_steps: Number of unmasking steps\n",
    "        temperature: Sampling temperature (lower = more deterministic)\n",
    "\n",
    "    Returns:\n",
    "        Generated token IDs, shape (1, seq_len)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.full((1, seq_len), MASK_TOKEN, dtype=torch.long, device=device)\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        # Current noise level (decreasing from 1 to 0)\n",
    "        t = torch.tensor([[1.0 - step / num_steps]], device=device)\n",
    "\n",
    "        # Model predicts all tokens\n",
    "        logits = model(x, t)\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "        # Sample tokens from predicted distribution\n",
    "        predicted = torch.multinomial(\n",
    "            probs.view(-1, VOCAB_SIZE), 1\n",
    "        ).view(1, seq_len)\n",
    "\n",
    "        # Confidence = max probability\n",
    "        confidence = probs.max(dim=-1).values\n",
    "\n",
    "        # How many to unmask this step\n",
    "        is_masked = (x == MASK_TOKEN)\n",
    "        remaining = is_masked.sum().item()\n",
    "        remaining_steps = max(1, num_steps - step)\n",
    "        n_to_unmask = max(1, int(remaining / remaining_steps))\n",
    "\n",
    "        # Unmask the most confident predictions among masked positions\n",
    "        masked_confidence = confidence.clone()\n",
    "        masked_confidence[~is_masked] = -float('inf')\n",
    "        _, top_idx = masked_confidence.view(-1).topk(min(n_to_unmask, remaining))\n",
    "        x.view(-1)[top_idx] = predicted.view(-1)[top_idx]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# Generate some text!\n",
    "print(\"Generated samples:\")\n",
    "print(\"=\" * 65)\n",
    "for i in range(5):\n",
    "    gen = generate(model, num_steps=12)\n",
    "    print(f\"  {decode(gen[0].tolist())}\")\n",
    "print(\"=\" * 65)"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Visualization\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_05_visualization.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_05_visualization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualizing the Generation Process\n",
    "\n",
    "This is the centerpiece visualization ‚Äî watching tokens appear step by step."
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_with_history(model, seq_len=SEQ_LEN, num_steps=10, temperature=0.8):\n",
    "    \"\"\"Generate text and record the state at every step.\"\"\"\n",
    "    model.eval()\n",
    "    x = torch.full((1, seq_len), MASK_TOKEN, dtype=torch.long, device=device)\n",
    "    history = [(x[0].cpu().clone(), 'Start (all masked)')]\n",
    "    confidence_history = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        t = torch.tensor([[1.0 - step / num_steps]], device=device)\n",
    "        logits = model(x, t)\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        predicted = torch.multinomial(probs.view(-1, VOCAB_SIZE), 1).view(1, seq_len)\n",
    "        confidence = probs.max(dim=-1).values\n",
    "\n",
    "        is_masked = (x == MASK_TOKEN)\n",
    "        remaining = is_masked.sum().item()\n",
    "        if remaining == 0:\n",
    "            break\n",
    "        n_to_unmask = max(1, int(remaining / max(1, num_steps - step)))\n",
    "\n",
    "        masked_conf = confidence.clone()\n",
    "        masked_conf[~is_masked] = -float('inf')\n",
    "        _, top_idx = masked_conf.view(-1).topk(min(n_to_unmask, remaining))\n",
    "        x.view(-1)[top_idx] = predicted.view(-1)[top_idx]\n",
    "\n",
    "        history.append((x[0].cpu().clone(), f'Step {step+1}'))\n",
    "        confidence_history.append(confidence[0].cpu().clone())\n",
    "\n",
    "    return x, history, confidence_history"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Step-by-step generation visualization\n",
    "gen, history, conf_hist = generate_with_history(model, num_steps=10)\n",
    "\n",
    "fig, axes = plt.subplots(len(history), 1, figsize=(18, len(history) * 0.9))\n",
    "\n",
    "for ax, (seq, label) in zip(axes, history):\n",
    "    tokens = seq.numpy()\n",
    "    for pos in range(SEQ_LEN):\n",
    "        if tokens[pos] == MASK_TOKEN:\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color='#333333', alpha=0.85))\n",
    "            ax.text(pos + 0.5, 0.5, '‚ñà', ha='center', va='center',\n",
    "                    color='#666', fontsize=7)\n",
    "        else:\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color='#e8f5e9', alpha=0.9))\n",
    "            char = id_to_char.get(tokens[pos], '?')\n",
    "            ax.text(pos + 0.5, 0.5, char, ha='center', va='center',\n",
    "                    fontsize=7, color='#1b5e20', fontweight='bold')\n",
    "    ax.set_xlim(0, SEQ_LEN)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(label, fontsize=9, rotation=0, ha='right', va='center',\n",
    "                  labelpad=80)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.suptitle('Iterative Unmasking: Text Emerging from Pure Masks',\n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Dark = still masked. Green = revealed token.\")\n",
    "print(\"Notice: tokens appear in confidence order, not left-to-right!\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Temperature\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_06_temperature.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_06_temperature"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Temperature and Sampling"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Effect of temperature on generation diversity\n",
    "print(\"Temperature Comparison:\")\n",
    "print(\"=\" * 65)\n",
    "for temp in [0.3, 0.7, 1.0, 1.5]:\n",
    "    print(f\"\\nTemperature = {temp}:\")\n",
    "    for _ in range(3):\n",
    "        gen = generate(model, num_steps=12, temperature=temp)\n",
    "        print(f\"  {decode(gen[0].tolist())}\")\n",
    "print(\"=\" * 65)\n",
    "print(\"\\nLow temperature ‚Üí repetitive but coherent\")\n",
    "print(\"High temperature ‚Üí diverse but potentially noisy\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Num Steps\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_07_num_steps.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_07_num_steps"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Number of Steps"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Quality vs number of unmasking steps\n",
    "print(\"Effect of Number of Steps:\")\n",
    "print(\"=\" * 65)\n",
    "for n_steps in [1, 2, 5, 10, 20]:\n",
    "    torch.manual_seed(42)\n",
    "    gen = generate(model, num_steps=n_steps, temperature=0.7)\n",
    "    text_out = decode(gen[0].tolist())\n",
    "    print(f\"  steps={n_steps:2d}: {text_out}\")\n",
    "print(\"=\" * 65)\n",
    "print(\"\\n1 step = unmask everything at once (worst quality)\")\n",
    "print(\"More steps = iterative refinement (better quality)\")\n",
    "print(\"This is why diffusion LLMs are fast ‚Äî even a few steps work!\")"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Infilling\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_08_infilling.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_08_infilling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Infilling ‚Äî The Killer Feature\n",
    "\n",
    "This is something autoregressive models **cannot** do naturally. We fix some tokens and let the model fill in the blanks."
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infill(model, template_str, num_steps=15, temperature=0.7):\n",
    "    \"\"\"Fill in masked positions while keeping fixed tokens.\n",
    "\n",
    "    Use '‚ñà' in the template to indicate positions to fill.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    template = template_str[:SEQ_LEN]\n",
    "    if len(template) < SEQ_LEN:\n",
    "        template = template + '‚ñà' * (SEQ_LEN - len(template))\n",
    "\n",
    "    ids = []\n",
    "    fixed_mask = []\n",
    "    for ch in template:\n",
    "        if ch == '‚ñà':\n",
    "            ids.append(MASK_TOKEN)\n",
    "            fixed_mask.append(False)\n",
    "        else:\n",
    "            ids.append(char_to_id.get(ch, MASK_TOKEN))\n",
    "            fixed_mask.append(True)\n",
    "\n",
    "    x = torch.tensor([ids], dtype=torch.long, device=device)\n",
    "    fixed = torch.tensor([fixed_mask], device=device)\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        t = torch.tensor([[1.0 - step / num_steps]], device=device)\n",
    "        logits = model(x, t)\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        predicted = torch.multinomial(probs.view(-1, VOCAB_SIZE), 1).view(1, SEQ_LEN)\n",
    "        confidence = probs.max(dim=-1).values\n",
    "\n",
    "        is_masked = (x == MASK_TOKEN) & ~fixed\n",
    "        remaining = is_masked.sum().item()\n",
    "        if remaining == 0:\n",
    "            break\n",
    "        n_to_unmask = max(1, int(remaining / max(1, num_steps - step)))\n",
    "\n",
    "        masked_conf = confidence.clone()\n",
    "        masked_conf[~is_masked] = -float('inf')\n",
    "        _, top_idx = masked_conf.view(-1).topk(min(n_to_unmask, remaining))\n",
    "        x.view(-1)[top_idx] = predicted.view(-1)[top_idx]\n",
    "\n",
    "    return decode(x[0].tolist())[:len(template_str)]"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Infilling demonstrations\n",
    "print(\"Infilling Demonstrations:\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "templates = [\n",
    "    \"To be‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñàthat is the question\",\n",
    "    \"ROMEO:‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\",\n",
    "    \"‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñàlight‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\",\n",
    "    \"First Citizen:‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\",\n",
    "]\n",
    "\n",
    "for template in templates:\n",
    "    result = infill(model, template, num_steps=20, temperature=0.7)\n",
    "    print(f\"  Template:  {template[:60]}\")\n",
    "    print(f\"  Filled:    {result[:60]}\")\n",
    "    print()\n",
    "\n",
    "print(\"The model fills in the blanks using BIDIRECTIONAL context!\")\n",
    "print(\"It sees text on BOTH sides of each blank ‚Äî AR models cannot do this.\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Lr Comparison\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_09_lr_comparison.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_09_lr_comparison"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Comparison with Left-to-Right Generation"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_left_to_right(model, seq_len=SEQ_LEN, temperature=0.8):\n",
    "    \"\"\"Generate by unmasking strictly left-to-right.\"\"\"\n",
    "    model.eval()\n",
    "    x = torch.full((1, seq_len), MASK_TOKEN, dtype=torch.long, device=device)\n",
    "\n",
    "    for pos in range(seq_len):\n",
    "        t_val = 1.0 - pos / seq_len\n",
    "        t = torch.tensor([[t_val]], device=device)\n",
    "        logits = model(x, t)\n",
    "        probs = F.softmax(logits[0, pos] / temperature, dim=-1)\n",
    "        x[0, pos] = torch.multinomial(probs, 1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "print(\"Generation Comparison:\")\n",
    "print(\"=\" * 65)\n",
    "print(\"Confidence-order (diffusion):\")\n",
    "for _ in range(3):\n",
    "    gen = generate(model, num_steps=12, temperature=0.7)\n",
    "    print(f\"  {decode(gen[0].tolist())}\")\n",
    "\n",
    "print(\"\\nLeft-to-right (forced):\")\n",
    "for _ in range(3):\n",
    "    gen = generate_left_to_right(model, temperature=0.7)\n",
    "    print(f\"  {decode(gen[0].tolist())}\")\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"Diffusion can use bidirectional context; L‚ÜíR generation cannot.\")"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo Topp\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_10_todo_topp.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_10_todo_topp"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üîß Your Turn\n",
    "\n",
    "### TODO 1: Implement Top-p (Nucleus) Sampling"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_sample(probs, p=0.9):\n",
    "    \"\"\"Sample from the top-p (nucleus) of the distribution.\n",
    "\n",
    "    Args:\n",
    "        probs: Probability distribution, shape (V,)\n",
    "        p: Cumulative probability threshold\n",
    "\n",
    "    Returns:\n",
    "        Sampled token ID\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Sort probabilities descending\n",
    "    sorted_probs, sorted_indices = ???  # YOUR CODE\n",
    "\n",
    "    # Step 2: Compute cumulative sum\n",
    "    cumulative = ???  # YOUR CODE\n",
    "\n",
    "    # Step 3: Create mask ‚Äî keep tokens up to cumulative prob p\n",
    "    mask = cumulative - sorted_probs > p  # True for tokens past threshold\n",
    "\n",
    "    # Step 4: Zero out and renormalize\n",
    "    sorted_probs[mask] = 0.0\n",
    "    sorted_probs = sorted_probs / sorted_probs.sum()\n",
    "\n",
    "    # Step 5: Sample\n",
    "    sampled_idx = torch.multinomial(sorted_probs, 1)\n",
    "    token = sorted_indices[sampled_idx]\n",
    "    # ==============================\n",
    "    return token.item()"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification\n",
    "try:\n",
    "    test_probs = torch.tensor([0.4, 0.3, 0.15, 0.1, 0.05])\n",
    "    samples = [top_p_sample(test_probs, p=0.9) for _ in range(100)]\n",
    "    from collections import Counter\n",
    "    counts = Counter(samples)\n",
    "    print(\"‚úÖ Top-p sampling works!\")\n",
    "    print(f\"   Distribution: {dict(sorted(counts.items()))}\")\n",
    "    print(f\"   Token 4 (prob=0.05) appeared {counts.get(4, 0)} times\")\n",
    "except NameError:\n",
    "    print(\"‚ùå Replace the ??? placeholders.\")"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo Prompted\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_11_todo_prompted.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_11_todo_prompted"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Implement Prompted Generation"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_with_prompt(model, prompt_str, total_len=SEQ_LEN,\n",
    "                          num_steps=15, temperature=0.7):\n",
    "    \"\"\"Generate text that continues from a given prompt.\n",
    "\n",
    "    Args:\n",
    "        model: Trained DiffusionLM\n",
    "        prompt_str: Starting text\n",
    "        total_len: Total output length\n",
    "        num_steps: Unmasking steps\n",
    "        temperature: Sampling temperature\n",
    "\n",
    "    Returns:\n",
    "        Generated string (prompt + completion)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Encode the prompt\n",
    "    prompt_ids = ???  # YOUR CODE: encode(prompt_str)\n",
    "\n",
    "    # Step 2: Create sequence ‚Äî prompt tokens + MASK for the rest\n",
    "    x = torch.full((1, total_len), MASK_TOKEN, dtype=torch.long, device=device)\n",
    "    prompt_len = min(len(prompt_ids), total_len)\n",
    "    x[0, :prompt_len] = ???  # YOUR CODE: fill in prompt\n",
    "\n",
    "    # Step 3: Create fixed mask ‚Äî True for prompt positions\n",
    "    fixed = torch.zeros(1, total_len, dtype=torch.bool, device=device)\n",
    "    fixed[0, :prompt_len] = ???  # YOUR CODE: True\n",
    "\n",
    "    # Step 4: Iterative unmasking (skip fixed positions)\n",
    "    for step in range(num_steps):\n",
    "        t = torch.tensor([[1.0 - step / num_steps]], device=device)\n",
    "        logits = model(x, t)\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        predicted = torch.multinomial(probs.view(-1, VOCAB_SIZE), 1).view(1, total_len)\n",
    "        confidence = probs.max(dim=-1).values\n",
    "\n",
    "        is_masked = (x == MASK_TOKEN) & ~fixed\n",
    "        remaining = is_masked.sum().item()\n",
    "        if remaining == 0: break\n",
    "        n_to_unmask = max(1, int(remaining / max(1, num_steps - step)))\n",
    "\n",
    "        masked_conf = confidence.clone()\n",
    "        masked_conf[~is_masked] = -float('inf')\n",
    "        _, top_idx = masked_conf.view(-1).topk(min(n_to_unmask, remaining))\n",
    "        x.view(-1)[top_idx] = predicted.view(-1)[top_idx]\n",
    "    # ==============================\n",
    "\n",
    "    return decode(x[0].tolist())"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification\n",
    "try:\n",
    "    prompts = [\"ROMEO:\\n\", \"To be, \", \"First C\"]\n",
    "    for p in prompts:\n",
    "        result = generate_with_prompt(model, p, num_steps=15, temperature=0.7)\n",
    "        print(f\"  Prompt: '{p}'\")\n",
    "        print(f\"  Output: '{result[:60]}'\")\n",
    "        print()\n",
    "    print(\"‚úÖ Prompted generation works!\")\n",
    "except NameError:\n",
    "    print(\"‚ùå Replace the ??? placeholders.\")"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Grand Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_12_grand_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_12_grand_viz"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batch of text samples\n",
    "print(\"Final Generation Showcase:\")\n",
    "print(\"=\" * 65)\n",
    "for i in range(8):\n",
    "    gen = generate(model, num_steps=15, temperature=0.7)\n",
    "    text_out = decode(gen[0].tolist())\n",
    "    print(f\"  Sample {i+1}: {text_out}\")\n",
    "print(\"=\" * 65)"
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üéØ Final Output"
   ],
   "id": "cell_31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä The Grand Visualization: step-by-step unmasking with highlights\n",
    "torch.manual_seed(7)\n",
    "gen_final, history_final, _ = generate_with_history(model, num_steps=12, temperature=0.7)\n",
    "\n",
    "fig, axes = plt.subplots(len(history_final), 1, figsize=(20, len(history_final) * 1.0))\n",
    "\n",
    "prev_seq = history_final[0][0].numpy()\n",
    "\n",
    "for idx, (ax, (seq, label)) in enumerate(zip(axes, history_final)):\n",
    "    tokens = seq.numpy()\n",
    "    for pos in range(SEQ_LEN):\n",
    "        if tokens[pos] == MASK_TOKEN:\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color='#424242'))\n",
    "            ax.text(pos + 0.5, 0.5, '‚ñà', ha='center', va='center',\n",
    "                    color='#616161', fontsize=8)\n",
    "        elif idx > 0 and prev_seq[pos] == MASK_TOKEN:\n",
    "            # NEWLY revealed ‚Äî highlight in yellow!\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color='#ffeb3b', alpha=0.9))\n",
    "            char = id_to_char.get(tokens[pos], '?')\n",
    "            ax.text(pos + 0.5, 0.5, char, ha='center', va='center',\n",
    "                    fontsize=8, fontweight='bold', color='#e65100')\n",
    "        else:\n",
    "            # Previously revealed\n",
    "            ax.add_patch(plt.Rectangle((pos, 0), 1, 1, color='#c8e6c9'))\n",
    "            char = id_to_char.get(tokens[pos], '?')\n",
    "            ax.text(pos + 0.5, 0.5, char, ha='center', va='center',\n",
    "                    fontsize=8, color='#2e7d32')\n",
    "\n",
    "    ax.set_xlim(0, SEQ_LEN)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(label, fontsize=9, rotation=0, ha='right', va='center', labelpad=100)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    prev_seq = tokens.copy()\n",
    "\n",
    "plt.suptitle('üéØ Text Generation via Iterative Unmasking\\n'\n",
    "             '(dark=masked, yellow=newly revealed, green=previously revealed)',\n",
    "             fontsize=13, y=1.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Congrats Recap\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_13_congrats_recap.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_13_congrats_recap"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Congratulations! You've Built a Complete Diffusion LLM from Scratch!\")\n",
    "print(\"=\" * 65)\n",
    "print()\n",
    "print(\"Over these 4 notebooks, you built:\")\n",
    "print(\"  1. Image diffusion foundations (forward + reverse process)\")\n",
    "print(\"  2. Masked diffusion for text (masking = noise for tokens)\")\n",
    "print(\"  3. A trained bidirectional Transformer on Shakespeare\")\n",
    "print(\"  4. Generation via iterative unmasking (this notebook!)\")\n",
    "print()\n",
    "print(\"Key insights:\")\n",
    "print(\"  ‚Ä¢ Masking replaces Gaussian noise for discrete tokens\")\n",
    "print(\"  ‚Ä¢ Training = BERT at all masking ratios (ELBO confirms it)\")\n",
    "print(\"  ‚Ä¢ Generation = iterative unmasking by confidence\")\n",
    "print(\"  ‚Ä¢ Bidirectional context ‚Üí better than left-to-right\")\n",
    "print(\"  ‚Ä¢ Infilling is natural (impossible for autoregressive models)\")\n",
    "print()\n",
    "print(\"This exact architecture, scaled to 8B parameters, gives LLaDA ‚Äî\")\n",
    "print(\"competitive with LLaMA 3. Mercury generates 1,000+ tok/s.\")\n",
    "print()\n",
    "print(\"The era of one-token-at-a-time may be coming to an end.\")"
   ],
   "id": "cell_33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Bigger Picture\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_14_bigger_picture.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_14_bigger_picture"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. The Bigger Picture\n",
    "\n",
    "Our tiny character-level model is conceptually identical to the largest diffusion LLMs. The architecture, training, and generation are the same ‚Äî only the scale differs:\n",
    "\n",
    "| | Our Model | LLaDA | Mercury |\n",
    "|---|---|---|---|\n",
    "| Parameters | ~500K | 8B | Undisclosed |\n",
    "| Vocabulary | ~66 chars | 32K tokens | 32K+ tokens |\n",
    "| Training data | 1MB Shakespeare | Trillions of tokens | Trillions |\n",
    "| Speed | Instant | Fast | 1,000+ tok/s |\n",
    "\n",
    "### Why Diffusion LLMs Might Be the Future\n",
    "\n",
    "1. **Speed** ‚Äî Parallel prediction means 5-10x faster generation\n",
    "2. **Bidirectional context** ‚Äî Every token sees past AND future\n",
    "3. **Natural infilling** ‚Äî Just mask the middle, no special tricks\n",
    "4. **Error correction** ‚Äî Iterative refinement lets the model \"change its mind\"\n",
    "\n",
    "### Open Challenges\n",
    "\n",
    "- Variable-length generation (how long should the output be?)\n",
    "- Sequential reasoning (counting, arithmetic)\n",
    "- Training compute (currently needs more than AR models of same size)"
   ],
   "id": "cell_34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_15_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_15_closing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "### ü§î Reflection Questions\n",
    "\n",
    "1. **Why does confidence-order generation work better than left-to-right?** Easy tokens settle first, creating scaffolding for harder predictions. Bidirectional context means the ending informs the beginning.\n",
    "\n",
    "2. **What is the tradeoff between steps and quality?** More steps = more refinement = higher quality, but diminishing returns. Even 5-10 steps work ‚Äî this is why diffusion LLMs are fast.\n",
    "\n",
    "3. **How would you generate variable-length text?** Include an [END] token and let the model place it. Or generate to max length and truncate.\n",
    "\n",
    "4. **Could you combine autoregressive and diffusion?** Yes ‚Äî generate blocks via diffusion, process blocks left-to-right. Best of both worlds.\n",
    "\n",
    "### üèÜ Optional Challenges\n",
    "\n",
    "1. Implement remasking ‚Äî occasionally re-mask some tokens and re-predict\n",
    "2. Try word-level (BPE) tokenization\n",
    "3. Scale up to a larger model and dataset\n",
    "4. Implement classifier-free guidance for conditional generation\n",
    "5. Compare generation quality between AR and diffusion approaches\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ You have completed the Diffusion LLMs from Scratch series!**\n",
    "\n",
    "You now understand how diffusion models work for language ‚Äî from the math through training to generation. These ideas power commercial systems generating 1,000+ tokens per second. The future of language generation may not be one token at a time."
   ],
   "id": "cell_35"
  }
 ]
}