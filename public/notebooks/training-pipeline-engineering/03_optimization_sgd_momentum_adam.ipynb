{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Optimization: SGD, Momentum, and Adam â€” Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_00_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1_yOuaRupWcvvBB5tNnjVrtDllXqg6x4Q\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/03_00_intro.mp3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_01_setup",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Setup\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_01_setup.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_04_visualize_landscape",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize Landscape\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_04_visualize_landscape.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_02_why_it_matters",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_02_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization: SGD, Momentum, and Adam -- Vizuara\n",
    "\n",
    "> **What you will build:** Three optimizers from scratch -- SGD, SGD with Momentum, and Adam -- and watch them compete on a real loss landscape."
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "The optimizer is the engine of learning. It takes the gradients computed during backpropagation and uses them to update the model's weights. A bad optimizer means the model learns slowly, gets stuck in poor solutions, or diverges entirely.\n",
    "\n",
    "The history of deep learning optimizers tells a clear story: **SGD** is simple but slow. **Momentum** adds acceleration. **Adam** adapts the learning rate per-weight. Understanding this progression is essential because Adam (and its variant AdamW) is used in virtually every modern LLM.\n",
    "\n",
    "In this notebook, we will implement all three from scratch, trace through them numerically, and watch them compete."
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_03_building_intuition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Building Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_03_building_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "Imagine you are blindfolded in a hilly landscape, trying to find the lowest valley. You can feel the slope beneath your feet (the gradient), but you cannot see where you are going.\n",
    "\n",
    "**SGD:** You take a fixed-size step downhill at every moment. Simple, but you zigzag wildly in narrow valleys.\n",
    "\n",
    "**Momentum:** You roll a ball downhill. It builds up speed in consistent directions and smooths out oscillations.\n",
    "\n",
    "**Adam:** You have a smart GPS that tracks both the average slope and how much it has been changing. It tells you exactly how big a step to take for each direction independently."
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a loss landscape: a narrow valley (Rosenbrock-like)\n",
    "def loss_fn(x, y):\n",
    "    \"\"\"A narrow valley loss landscape -- hard for SGD, easier for Adam.\"\"\"\n",
    "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
    "\n",
    "# Visualize the landscape\n",
    "x = np.linspace(-2, 2, 200)\n",
    "y = np.linspace(-1, 3, 200)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = loss_fn(X, Y)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 3D view\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot_surface(X, Y, np.log1p(Z), cmap='viridis', alpha=0.8, linewidth=0)\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('log(1 + Loss)')\n",
    "ax1.set_title('Loss Landscape (3D)', fontweight='bold')\n",
    "\n",
    "# Contour view\n",
    "ax2 = fig.add_subplot(122)\n",
    "contour = ax2.contour(X, Y, np.log1p(Z), levels=30, cmap='viridis')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('Loss Landscape (Contours)', fontweight='bold')\n",
    "ax2.plot(1, 1, 'r*', markersize=15, label='Minimum (1,1)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('loss_landscape.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Checkpoint: The minimum is at (1, 1). The narrow valley makes optimization hard.\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_05_the_mathematics",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: The Mathematics\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_05_the_mathematics.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The simplest update rule:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla L(\\theta_t)$$\n",
    "\n",
    "where $\\eta$ is the learning rate and $\\nabla L$ is the gradient.\n",
    "\n",
    "### SGD with Momentum\n",
    "\n",
    "Add a velocity term that accumulates past gradients:\n",
    "\n",
    "$$v_{t+1} = \\beta v_t + \\nabla L(\\theta_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\, v_{t+1}$$\n",
    "\n",
    "where $\\beta$ is the momentum coefficient (typically 0.9).\n",
    "\n",
    "### Adam (Adaptive Moment Estimation)\n",
    "\n",
    "Maintain two running statistics per weight:\n",
    "\n",
    "**First moment** (mean of gradients):\n",
    "$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$$\n",
    "\n",
    "**Second moment** (mean of squared gradients):\n",
    "$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$$\n",
    "\n",
    "**Bias correction:**\n",
    "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "\n",
    "**Update:**\n",
    "$$\\theta_t = \\theta_{t-1} - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
    "\n",
    "The key insight: dividing by $\\sqrt{\\hat{v}_t}$ makes the effective step size **smaller** for weights with large, variable gradients and **larger** for weights with small, consistent gradients."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_06_numerical_trace",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Numerical Trace\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_06_numerical_trace.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical trace: one step of each optimizer\n",
    "theta = 0.5\n",
    "gradient = 0.2\n",
    "lr = 0.01\n",
    "\n",
    "# SGD\n",
    "theta_sgd = theta - lr * gradient\n",
    "print(f\"SGD:      theta = {theta} - {lr} * {gradient} = {theta_sgd}\")\n",
    "\n",
    "# Momentum (first step, v0 = 0)\n",
    "beta = 0.9\n",
    "v = 0.0\n",
    "v_new = beta * v + gradient\n",
    "theta_mom = theta - lr * v_new\n",
    "print(f\"Momentum: v = {beta}*{v} + {gradient} = {v_new}\")\n",
    "print(f\"          theta = {theta} - {lr} * {v_new} = {theta_mom}\")\n",
    "\n",
    "# Adam (first step, m0 = 0, v0 = 0)\n",
    "beta1, beta2, eps = 0.9, 0.999, 1e-8\n",
    "m = (1 - beta1) * gradient  # 0.1 * 0.2 = 0.02\n",
    "v_adam = (1 - beta2) * gradient**2  # 0.001 * 0.04 = 0.00004\n",
    "m_hat = m / (1 - beta1**1)  # 0.02 / 0.1 = 0.2\n",
    "v_hat = v_adam / (1 - beta2**1)  # 0.00004 / 0.001 = 0.04\n",
    "theta_adam = theta - 0.001 * m_hat / (np.sqrt(v_hat) + eps)\n",
    "print(f\"Adam:     m_hat = {m_hat:.4f}, v_hat = {v_hat:.4f}\")\n",
    "print(f\"          theta = {theta} - 0.001 * {m_hat:.4f} / ({np.sqrt(v_hat):.4f}) = {theta_adam:.6f}\")"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_07_build_sgd_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Build Sgd Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_07_build_sgd_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 SGD from Scratch"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_08_sgd_from_scratch",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Sgd From Scratch\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_08_sgd_from_scratch.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"Stochastic Gradient Descent optimizer.\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.data -= self.lr * p.grad.data\n",
    "\n",
    "# Test: minimize f(x) = (x - 3)^2\n",
    "x = torch.tensor([0.0], requires_grad=True)\n",
    "optimizer = SGD([x], lr=0.1)\n",
    "\n",
    "trajectory = [x.item()]\n",
    "for step in range(20):\n",
    "    loss = (x - 3)**2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    trajectory.append(x.item())\n",
    "\n",
    "print(f\"SGD: x went from {trajectory[0]:.3f} to {trajectory[-1]:.3f} (target: 3.0)\")\n",
    "print(f\"Trajectory: {[f'{t:.2f}' for t in trajectory[:6]]}...\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_09_momentum_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Momentum Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_09_momentum_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 SGD with Momentum from Scratch"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_10_sgdmomentum_from_scratch",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Sgdmomentum From Scratch\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_10_sgdmomentum_from_scratch.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum:\n",
    "    \"\"\"SGD with momentum optimizer.\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=0.01, momentum=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        # Initialize velocity for each parameter\n",
    "        self.velocities = [torch.zeros_like(p.data) for p in self.params]\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def step(self):\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is not None:\n",
    "                # Update velocity\n",
    "                self.velocities[i] = self.momentum * self.velocities[i] + p.grad.data\n",
    "                # Update parameter\n",
    "                p.data -= self.lr * self.velocities[i]\n",
    "\n",
    "# Test: minimize f(x) = (x - 3)^2\n",
    "x = torch.tensor([0.0], requires_grad=True)\n",
    "optimizer = SGDMomentum([x], lr=0.1, momentum=0.9)\n",
    "\n",
    "trajectory = [x.item()]\n",
    "for step in range(20):\n",
    "    loss = (x - 3)**2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    trajectory.append(x.item())\n",
    "\n",
    "print(f\"Momentum: x went from {trajectory[0]:.3f} to {trajectory[-1]:.3f} (target: 3.0)\")\n",
    "print(f\"Trajectory: {[f'{t:.2f}' for t in trajectory[:6]]}...\")\n",
    "print(\"Notice: Momentum overshoots then corrects -- it oscillates around the target!\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_11_adam_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Adam Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_11_adam_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Adam from Scratch"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_12_adam_from_scratch",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Adam From Scratch\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_12_adam_from_scratch.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    \"\"\"Adam optimizer (Adaptive Moment Estimation).\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta1, self.beta2 = betas\n",
    "        self.eps = eps\n",
    "        self.t = 0  # Step counter for bias correction\n",
    "\n",
    "        # Initialize moments for each parameter\n",
    "        self.m = [torch.zeros_like(p.data) for p in self.params]  # First moment\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]  # Second moment\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is not None:\n",
    "                g = p.grad.data\n",
    "\n",
    "                # Update first moment (mean of gradients)\n",
    "                self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * g\n",
    "\n",
    "                # Update second moment (mean of squared gradients)\n",
    "                self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * g**2\n",
    "\n",
    "                # Bias correction\n",
    "                m_hat = self.m[i] / (1 - self.beta1**self.t)\n",
    "                v_hat = self.v[i] / (1 - self.beta2**self.t)\n",
    "\n",
    "                # Update parameters\n",
    "                p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "\n",
    "# Test: minimize f(x) = (x - 3)^2\n",
    "x = torch.tensor([0.0], requires_grad=True)\n",
    "optimizer = Adam([x], lr=0.1)\n",
    "\n",
    "trajectory = [x.item()]\n",
    "for step in range(50):\n",
    "    loss = (x - 3)**2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    trajectory.append(x.item())\n",
    "\n",
    "print(f\"Adam: x went from {trajectory[0]:.3f} to {trajectory[-1]:.3f} (target: 3.0)\")\n",
    "print(f\"Trajectory: {[f'{t:.2f}' for t in trajectory[:8]]}...\")"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_13_1d_comparison_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: 1d Comparison Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_13_1d_comparison_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Comparing Optimizer Trajectories on 1D"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_14_visualize_1d_comparison",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize 1d Comparison\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_14_visualize_1d_comparison.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Track all three optimizers on f(x) = (x - 3)^2\n",
    "trajectories = {}\n",
    "\n",
    "for OptClass, name, lr, kwargs in [\n",
    "    (SGD, 'SGD', 0.1, {}),\n",
    "    (SGDMomentum, 'SGD + Momentum', 0.1, {'momentum': 0.9}),\n",
    "    (Adam, 'Adam', 0.1, {}),\n",
    "]:\n",
    "    x = torch.tensor([0.0], requires_grad=True)\n",
    "    opt = OptClass([x], lr=lr, **kwargs)\n",
    "    traj = [x.item()]\n",
    "    for step in range(30):\n",
    "        loss = (x - 3)**2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        traj.append(x.item())\n",
    "    trajectories[name] = traj\n",
    "\n",
    "colors = {'SGD': '#e74c3c', 'SGD + Momentum': '#3498db', 'Adam': '#2ecc71'}\n",
    "for name, traj in trajectories.items():\n",
    "    ax.plot(traj, label=name, linewidth=2, color=colors[name], marker='o', markersize=3)\n",
    "\n",
    "ax.axhline(y=3.0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Target (x=3)')\n",
    "ax.set_xlabel('Step', fontsize=12)\n",
    "ax.set_ylabel('x value', fontsize=12)\n",
    "ax.set_title('Optimizer Comparison: Minimizing f(x) = (x - 3)^2', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimizer_comparison_1d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Checkpoint: SGD converges linearly, Momentum overshoots, Adam adapts.\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_15_todo1_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_15_todo1_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn\n",
    "\n",
    "### TODO 1: Implement AdamW (Adam with Decoupled Weight Decay)\n",
    "\n",
    "Standard Adam applies weight decay through the gradient (L2 regularization). AdamW decouples weight decay from the gradient update, applying it directly to the weights."
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_16_todo1_adamw",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Adamw\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_16_todo1_adamw.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamW:\n",
    "    \"\"\"Adam with decoupled weight decay (used in every modern LLM).\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta1, self.beta2 = betas\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.t = 0\n",
    "\n",
    "        self.m = [torch.zeros_like(p.data) for p in self.params]\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is not None:\n",
    "                g = p.grad.data\n",
    "\n",
    "                # TODO: Update first moment (m)\n",
    "                # self.m[i] = ...  # YOUR CODE HERE\n",
    "\n",
    "                # TODO: Update second moment (v)\n",
    "                # self.v[i] = ...  # YOUR CODE HERE\n",
    "\n",
    "                # TODO: Bias correction\n",
    "                # m_hat = ...  # YOUR CODE HERE\n",
    "                # v_hat = ...  # YOUR CODE HERE\n",
    "\n",
    "                # TODO: Adam update (WITHOUT weight decay)\n",
    "                # p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "\n",
    "                # TODO: Apply DECOUPLED weight decay\n",
    "                # p.data -= ...  # YOUR CODE HERE\n",
    "                pass\n",
    "\n",
    "    # SOLUTION (uncomment to verify):\n",
    "    # def step(self):\n",
    "    #     self.t += 1\n",
    "    #     for i, p in enumerate(self.params):\n",
    "    #         if p.grad is not None:\n",
    "    #             g = p.grad.data\n",
    "    #             self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * g\n",
    "    #             self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * g**2\n",
    "    #             m_hat = self.m[i] / (1 - self.beta1**self.t)\n",
    "    #             v_hat = self.v[i] / (1 - self.beta2**self.t)\n",
    "    #             p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "    #             p.data -= self.lr * self.weight_decay * p.data"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_17_todo2_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_17_todo2_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Trace Through Adam Manually\n",
    "\n",
    "Given: $\\theta_0 = 1.0$, $m_0 = 0$, $v_0 = 0$, $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\eta = 0.01$, $\\epsilon = 10^{-8}$\n",
    "\n",
    "Gradients over 3 steps: $g_1 = 0.5$, $g_2 = -0.3$, $g_3 = 0.4$"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_18_todo2_manual_trace",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Manual Trace\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_18_todo2_manual_trace.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute m, v, m_hat, v_hat, and theta for each step\n",
    "# Fill in the values below\n",
    "\n",
    "# Step 1: g = 0.5\n",
    "# m1 = 0.9 * 0 + 0.1 * 0.5 = ???\n",
    "# v1 = 0.999 * 0 + 0.001 * 0.5^2 = ???\n",
    "# m_hat1 = m1 / (1 - 0.9^1) = ???\n",
    "# v_hat1 = v1 / (1 - 0.999^1) = ???\n",
    "# theta1 = 1.0 - 0.01 * m_hat1 / (sqrt(v_hat1) + 1e-8) = ???\n",
    "\n",
    "# Step 2: g = -0.3\n",
    "# m2 = ???\n",
    "# v2 = ???\n",
    "# ...\n",
    "\n",
    "# Step 3: g = 0.4\n",
    "# m3 = ???\n",
    "# ...\n",
    "\n",
    "print(\"Verify your manual calculation against the code:\")\n",
    "theta = 1.0\n",
    "m, v = 0.0, 0.0\n",
    "beta1, beta2, lr, eps = 0.9, 0.999, 0.01, 1e-8\n",
    "grads = [0.5, -0.3, 0.4]\n",
    "\n",
    "for t, g in enumerate(grads, 1):\n",
    "    m = beta1 * m + (1 - beta1) * g\n",
    "    v = beta2 * v + (1 - beta2) * g**2\n",
    "    m_hat = m / (1 - beta1**t)\n",
    "    v_hat = v / (1 - beta2**t)\n",
    "    theta = theta - lr * m_hat / (np.sqrt(v_hat) + eps)\n",
    "    print(f\"Step {t}: g={g:+.1f}, m_hat={m_hat:.6f}, v_hat={v_hat:.6f}, theta={theta:.6f}\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_19_2d_race_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: 2d Race Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_19_2d_race_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together: 2D Optimizer Race\n",
    "\n",
    "Let us race all three optimizers on a challenging 2D loss surface."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_20_run_2d_optimizer",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Run 2d Optimizer\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_20_run_2d_optimizer.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimizer_2d(OptClass, start, lr, steps, **kwargs):\n",
    "    \"\"\"Run an optimizer on the Rosenbrock loss surface.\"\"\"\n",
    "    x = torch.tensor([start[0]], requires_grad=True, dtype=torch.float)\n",
    "    y = torch.tensor([start[1]], requires_grad=True, dtype=torch.float)\n",
    "    opt = OptClass([x, y], lr=lr, **kwargs)\n",
    "\n",
    "    trajectory = [(x.item(), y.item())]\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        loss = (1 - x)**2 + 100 * (y - x**2)**2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        trajectory.append((x.item(), y.item()))\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return trajectory, losses\n",
    "\n",
    "# Run all three optimizers\n",
    "start = (-1.0, 2.0)\n",
    "steps = 500\n",
    "\n",
    "results = {}\n",
    "configs = [\n",
    "    ('SGD', SGD, 0.0001, {}),\n",
    "    ('Momentum', SGDMomentum, 0.0001, {'momentum': 0.9}),\n",
    "    ('Adam', Adam, 0.01, {}),\n",
    "]\n",
    "\n",
    "for name, OptClass, lr, kwargs in configs:\n",
    "    traj, losses = run_optimizer_2d(OptClass, start, lr, steps, **kwargs)\n",
    "    results[name] = {'trajectory': traj, 'losses': losses}\n",
    "    final_x, final_y = traj[-1]\n",
    "    print(f\"{name:>10s}: Final ({final_x:>7.3f}, {final_y:>7.3f})  Loss: {losses[-1]:.4f}\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_21_visualize_2d_race",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize 2d Race\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_21_visualize_2d_race.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimizer race on the contour plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Contour plot with trajectories\n",
    "ax = axes[0]\n",
    "x = np.linspace(-2, 2, 200)\n",
    "y = np.linspace(-1, 3, 200)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.log1p(loss_fn(X, Y))\n",
    "ax.contour(X, Y, Z, levels=40, cmap='viridis', alpha=0.6)\n",
    "\n",
    "colors = {'SGD': '#e74c3c', 'Momentum': '#3498db', 'Adam': '#2ecc71'}\n",
    "for name, data in results.items():\n",
    "    traj = np.array(data['trajectory'])\n",
    "    ax.plot(traj[:, 0], traj[:, 1], '-o', color=colors[name], label=name,\n",
    "            markersize=1, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.plot(1, 1, 'k*', markersize=15, zorder=5, label='Minimum')\n",
    "ax.plot(start[0], start[1], 'ko', markersize=8, zorder=5)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Optimizer Paths on Rosenbrock Surface', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Loss curves\n",
    "ax = axes[1]\n",
    "for name, data in results.items():\n",
    "    ax.plot(data['losses'], label=name, linewidth=2, color=colors[name])\n",
    "\n",
    "ax.set_xlabel('Step', fontsize=12)\n",
    "ax.set_ylabel('Loss (log scale)', fontsize=12)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Loss vs Training Step', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimizer_race_2d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Checkpoint: Adam converges fastest by adapting learning rates per-parameter.\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_22_real_neural_network_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Real Neural Network Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_22_real_neural_network_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results: Real Neural Network\n",
    "\n",
    "Let us test our optimizers on an actual neural network."
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_23_train_nn",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Train Nn\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_23_train_nn.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Create a simple regression problem\n",
    "torch.manual_seed(42)\n",
    "X = torch.linspace(-3, 3, 200).unsqueeze(1)\n",
    "y = torch.sin(X) + 0.1 * torch.randn_like(X)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_net(OptClass, lr, kwargs, epochs=200):\n",
    "    model = SimpleNet()\n",
    "    opt = OptClass(model.parameters(), lr=lr, **kwargs)\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        pred = model(X)\n",
    "        loss = nn.MSELoss()(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    return losses, model\n",
    "\n",
    "# Compare optimizers on the neural network\n",
    "nn_results = {}\n",
    "nn_configs = [\n",
    "    ('SGD', SGD, 0.01, {}),\n",
    "    ('Momentum', SGDMomentum, 0.01, {'momentum': 0.9}),\n",
    "    ('Adam', Adam, 0.01, {}),\n",
    "    ('PyTorch Adam', torch.optim.Adam, 0.01, {}),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for name, OptClass, lr, kwargs in nn_configs:\n",
    "    losses, model = train_net(OptClass, lr, kwargs)\n",
    "    ax.plot(losses, label=name, linewidth=2)\n",
    "    print(f\"{name:>15s}: Final loss = {losses[-1]:.6f}\")\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('MSE Loss', fontsize=12)\n",
    "ax.set_title('Optimizer Comparison on Neural Network (sin fitting)', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimizer_nn.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Our custom Adam matches PyTorch's implementation!\")"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_24_final_output_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Final Output Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_24_final_output_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_25_summary_visualization",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Summary Visualization\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_25_summary_visualization.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: Weight update magnitudes over training\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "theta_vals = {'SGD': [], 'Momentum': [], 'Adam': []}\n",
    "grads_sequence = np.sin(np.linspace(0, 4*np.pi, 100)) + 0.5  # Oscillating + bias\n",
    "\n",
    "for OptClass, name, lr, kwargs in [\n",
    "    (SGD, 'SGD', 0.01, {}),\n",
    "    (SGDMomentum, 'Momentum', 0.01, {'momentum': 0.9}),\n",
    "    (Adam, 'Adam', 0.01, {}),\n",
    "]:\n",
    "    x = torch.tensor([5.0], requires_grad=True)\n",
    "    opt = OptClass([x], lr=lr, **kwargs)\n",
    "\n",
    "    for g_val in grads_sequence:\n",
    "        x.grad = torch.tensor([g_val])\n",
    "        opt.step()\n",
    "        theta_vals[name].append(x.item())\n",
    "        x.grad = None\n",
    "\n",
    "for ax, (name, vals) in zip(axes, theta_vals.items()):\n",
    "    ax.plot(vals, linewidth=1.5, color=colors.get(name, '#333'))\n",
    "    ax.set_title(name, fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Parameter Value')\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('How Each Optimizer Responds to Oscillating Gradients', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimizer_behavior.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"  SGD: Follows every gradient exactly -- noisy and slow\")\n",
    "print(\"  Momentum: Smooths oscillations, accelerates in consistent directions\")\n",
    "print(\"  Adam: Adapts per-weight learning rates based on gradient history\")\n",
    "print(\"\\nAdam (and AdamW) is the standard optimizer for modern LLM training.\")"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_26_closing",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Wrap-Up: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_26_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "**What we built:** Three optimizers from scratch -- SGD, Momentum, and Adam -- and verified they match PyTorch's implementations.\n",
    "\n",
    "**Key takeaways:**\n",
    "- SGD is the foundation: $\\theta_{t+1} = \\theta_t - \\eta \\nabla L$\n",
    "- Momentum adds acceleration by tracking past gradients\n",
    "- Adam combines momentum with per-weight adaptive learning rates\n",
    "- Bias correction in Adam prevents early training instability\n",
    "- AdamW decouples weight decay from the gradient update\n",
    "\n",
    "**What is next:** In Notebook 4, we will build learning rate schedulers (warmup + cosine decay) and gradient clipping -- the safety mechanisms that prevent training from diverging."
   ],
   "id": "cell_26"
  }
 ]
}