{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Tokenization and Byte Pair Encoding â€” Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_00_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1K3QJmxvgc0_ZwXawSeV_oQll-6WeibaO\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/01_00_intro.mp3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_01_setup",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Setup\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_01_setup.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_02_why_it_matters",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_02_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Byte Pair Encoding -- Vizuara\n",
    "\n",
    "> **What you will build:** A complete BPE tokenizer from scratch, train it on real text, and compare it against GPT-2's production tokenizer."
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "Neural networks operate on numbers, not text. Before a language model can process a single word, every character of input must be converted into a numerical representation. This conversion -- **tokenization** -- is the very first step in the entire training pipeline.\n",
    "\n",
    "Get it wrong, and nothing downstream works. A broken tokenizer means the model receives garbage input, and no amount of clever architecture or optimization can fix that.\n",
    "\n",
    "In this notebook, we will build a Byte Pair Encoding (BPE) tokenizer from scratch, understand why it dominates modern NLP, and see exactly how GPT-2 and LLaMA handle text."
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_03_building_intuition",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Building Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_03_building_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "There are three approaches to tokenization, and understanding the tradeoffs between them is essential.\n",
    "\n",
    "**Character-level:** Every character gets a unique ID. Tiny vocabulary (~256), but sequences become extremely long.\n",
    "\n",
    "**Word-level:** Every word gets a unique ID. Short sequences, but the vocabulary explodes to millions. Unknown words simply cannot be processed.\n",
    "\n",
    "**Subword (BPE):** The sweet spot. Common words stay as single tokens. Rare words get split into meaningful pieces.\n",
    "\n",
    "Let us see this concretely."
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_04_char_word_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Char Word Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_04_char_word_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character-level tokenization\n",
    "text = \"transformer\"\n",
    "char_tokens = [ord(c) for c in text]\n",
    "print(f\"Character-level: '{text}' -> {char_tokens}\")\n",
    "print(f\"  Vocabulary size: 256 (ASCII)\")\n",
    "print(f\"  Sequence length: {len(char_tokens)} tokens for one word!\\n\")\n",
    "\n",
    "# Word-level tokenization\n",
    "vocabulary = {\"the\": 0, \"cat\": 1, \"sat\": 2, \"on\": 3, \"mat\": 4}\n",
    "sentence = \"the cat sat on the mat\"\n",
    "word_tokens = [vocabulary[w] for w in sentence.split()]\n",
    "print(f\"Word-level: '{sentence}' -> {word_tokens}\")\n",
    "print(f\"  Vocabulary size: {len(vocabulary)} (just for this sentence)\")\n",
    "print(f\"  Sequence length: {len(word_tokens)} tokens\")\n",
    "print(f\"  Problem: What about 'transformer'? -> KeyError!\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_05_visualize_tradeoff_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Visualize Tradeoff Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_05_visualize_tradeoff_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the tradeoff between vocabulary size and sequence length."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_06_visualize_tradeoff_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize Tradeoff Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_06_visualize_tradeoff_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data for different tokenization strategies\n",
    "strategies = ['Character\\n(~256 tokens)', 'BPE\\n(~50K tokens)', 'Word\\n(~170K+ tokens)']\n",
    "vocab_sizes = [256, 50000, 170000]\n",
    "seq_lengths = [11, 3, 1]  # Tokens for \"transformer\"\n",
    "colors = ['#e74c3c', '#2ecc71', '#3498db']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.bar(strategies, vocab_sizes, color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_ylabel('Vocabulary Size', fontsize=12)\n",
    "ax1.set_title('Vocabulary Size by Strategy', fontsize=13, fontweight='bold')\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax2.bar(strategies, seq_lengths, color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax2.set_ylabel('Tokens per Word', fontsize=12)\n",
    "ax2.set_title('Sequence Length (for \"transformer\")', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tokenization_tradeoff.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Checkpoint: BPE finds the sweet spot between vocabulary size and sequence length.\")"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_07_mathematics",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Mathematics\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_07_mathematics.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "BPE is built on a simple greedy algorithm. Starting from individual characters, we repeatedly merge the most frequent adjacent pair of tokens.\n",
    "\n",
    "Given a corpus $C$ with word frequencies $f(w)$, BPE proceeds as:\n",
    "\n",
    "**Step 1:** Initialize vocabulary $V$ with all individual characters.\n",
    "\n",
    "**Step 2:** For each word $w$, split into character sequence: $w = c_1, c_2, \\ldots, c_n$\n",
    "\n",
    "**Step 3:** Count all adjacent pairs across the corpus:\n",
    "\n",
    "$$\\text{count}(a, b) = \\sum_{w \\in C} f(w) \\cdot \\text{occurrences of } (a, b) \\text{ in } w$$\n",
    "\n",
    "**Step 4:** Merge the pair $(a^*, b^*)$ with the highest count:\n",
    "\n",
    "$$(a^*, b^*) = \\arg\\max_{(a,b)} \\text{count}(a, b)$$\n",
    "\n",
    "**Step 5:** Replace all occurrences of $(a^*, b^*)$ with the new token $ab$ in every word.\n",
    "\n",
    "**Step 6:** Add $ab$ to $V$. Repeat from Step 3 until $|V|$ reaches the desired size.\n",
    "\n",
    "The **embedding memory** cost for vocabulary of size $V$ with embedding dimension $d$ is:\n",
    "\n",
    "$$\\text{Memory} = V \\times d \\times 4 \\text{ bytes (for float32)}$$\n",
    "\n",
    "For GPT-2 ($V = 50{,}257$, $d = 768$): $\\text{Memory} = 50{,}257 \\times 768 \\times 4 \\approx 154$ MB."
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_08_embedding_memory_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Embedding Memory Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_08_embedding_memory_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute embedding memory for different vocabulary sizes\n",
    "d = 4096  # embedding dimension (common for large LLMs)\n",
    "bytes_per_float = 4  # float32\n",
    "\n",
    "print(\"Embedding Table Memory (d=4096, float32):\")\n",
    "print(\"-\" * 45)\n",
    "for V in [256, 32000, 50257, 100000]:\n",
    "    mem_bytes = V * d * bytes_per_float\n",
    "    mem_mb = mem_bytes / (1024 ** 2)\n",
    "    print(f\"  V = {V:>7,d}  ->  {mem_mb:>8.1f} MB\")\n",
    "\n",
    "print(\"\\nThis is why vocabulary size is an engineering tradeoff!\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_09_build_components_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Build Components Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_09_build_components_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 Word Frequency Counter\n",
    "\n",
    "First, we need to count how often each word appears in our corpus, represented as sequences of characters with an end-of-word marker."
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_10_word_freq_counter_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Word Freq Counter Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_10_word_freq_counter_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def get_word_frequencies(text):\n",
    "    \"\"\"\n",
    "    Count word frequencies in the corpus.\n",
    "    Each word is represented as a tuple of characters + end-of-word marker '_'.\n",
    "    \"\"\"\n",
    "    words = text.lower().split()\n",
    "    word_freqs = Counter(words)\n",
    "\n",
    "    # Convert to character sequences with end-of-word marker\n",
    "    vocab_freqs = {}\n",
    "    for word, freq in word_freqs.items():\n",
    "        # Split word into characters, add end marker\n",
    "        char_tuple = tuple(list(word) + ['_'])\n",
    "        vocab_freqs[char_tuple] = freq\n",
    "\n",
    "    return vocab_freqs\n",
    "\n",
    "# Test on a small corpus\n",
    "corpus = \"low low low low low lowest lowest newer newer newer wider wider wider wider\"\n",
    "freqs = get_word_frequencies(corpus)\n",
    "\n",
    "print(\"Word frequencies (as character tuples):\")\n",
    "for word, freq in sorted(freqs.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {' '.join(word):20s}  (freq: {freq})\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_11_pair_counter_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Pair Counter Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_11_pair_counter_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pair Counter\n",
    "\n",
    "Next, we count all adjacent pairs of tokens across the corpus."
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_12_pair_counter_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Pair Counter Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_12_pair_counter_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_counts(vocab_freqs):\n",
    "    \"\"\"Count frequencies of all adjacent token pairs in the vocabulary.\"\"\"\n",
    "    pair_counts = defaultdict(int)\n",
    "\n",
    "    for word, freq in vocab_freqs.items():\n",
    "        # Get all adjacent pairs in this word\n",
    "        for i in range(len(word) - 1):\n",
    "            pair = (word[i], word[i + 1])\n",
    "            pair_counts[pair] += freq\n",
    "\n",
    "    return pair_counts\n",
    "\n",
    "pairs = get_pair_counts(freqs)\n",
    "print(\"Top 10 adjacent pairs:\")\n",
    "for pair, count in sorted(pairs.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  ({pair[0]:>3s}, {pair[1]:<3s})  ->  {count} times\")"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_13_merge_op_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Merge Op Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_13_merge_op_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Merge Operation\n",
    "\n",
    "Now the core operation: merging the most frequent pair into a new token."
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_14_merge_op_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Merge Op Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_14_merge_op_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(vocab_freqs, pair_to_merge):\n",
    "    \"\"\"\n",
    "    Merge all occurrences of pair_to_merge in the vocabulary.\n",
    "    Returns a new vocabulary with the merged token.\n",
    "    \"\"\"\n",
    "    new_vocab = {}\n",
    "    bigram = pair_to_merge\n",
    "\n",
    "    for word, freq in vocab_freqs.items():\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            # Check if current position matches the pair to merge\n",
    "            if i < len(word) - 1 and word[i] == bigram[0] and word[i + 1] == bigram[1]:\n",
    "                # Merge the pair into a single token\n",
    "                new_word.append(bigram[0] + bigram[1])\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_vocab[tuple(new_word)] = freq\n",
    "\n",
    "    return new_vocab\n",
    "\n",
    "# Test: merge the most frequent pair\n",
    "best_pair = max(pairs, key=pairs.get)\n",
    "print(f\"Most frequent pair: {best_pair} (count: {pairs[best_pair]})\")\n",
    "print(f\"\\nBefore merge:\")\n",
    "for word, freq in sorted(freqs.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {' '.join(word):20s}  (freq: {freq})\")\n",
    "\n",
    "freqs_after = merge_pair(freqs, best_pair)\n",
    "print(f\"\\nAfter merging {best_pair}:\")\n",
    "for word, freq in sorted(freqs_after.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {' '.join(word):20s}  (freq: {freq})\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_15_todo1_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_15_todo1_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn: Complete the BPE Trainer\n",
    "\n",
    "### TODO 1: Implement the full BPE training loop\n",
    "\n",
    "Complete the `train_bpe` function that runs the merge process for `num_merges` iterations."
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_16_todo1_completion",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Completion\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_16_todo1_completion.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(text, num_merges):\n",
    "    \"\"\"\n",
    "    Train a BPE tokenizer on the given text.\n",
    "\n",
    "    Args:\n",
    "        text: Raw text corpus\n",
    "        num_merges: Number of merge operations to perform\n",
    "\n",
    "    Returns:\n",
    "        merge_rules: List of (pair, merged_token) tuples\n",
    "        final_vocab: The vocabulary after all merges\n",
    "    \"\"\"\n",
    "    vocab_freqs = get_word_frequencies(text)\n",
    "    merge_rules = []\n",
    "\n",
    "    for step in range(num_merges):\n",
    "        # TODO: Count all adjacent pairs\n",
    "        pair_counts = ...  # YOUR CODE HERE\n",
    "\n",
    "        # TODO: Find the most frequent pair\n",
    "        if not pair_counts:\n",
    "            break\n",
    "        best_pair = ...  # YOUR CODE HERE\n",
    "\n",
    "        # TODO: Merge the best pair in the vocabulary\n",
    "        vocab_freqs = ...  # YOUR CODE HERE\n",
    "\n",
    "        # Record the merge rule\n",
    "        merged_token = best_pair[0] + best_pair[1]\n",
    "        merge_rules.append((best_pair, merged_token))\n",
    "\n",
    "        if step < 5 or step == num_merges - 1:\n",
    "            print(f\"Step {step+1}: Merge {best_pair} -> '{merged_token}' (count: {pair_counts[best_pair]})\")\n",
    "\n",
    "    return merge_rules, vocab_freqs\n",
    "\n",
    "# SOLUTION (uncomment to verify):\n",
    "# def train_bpe(text, num_merges):\n",
    "#     vocab_freqs = get_word_frequencies(text)\n",
    "#     merge_rules = []\n",
    "#     for step in range(num_merges):\n",
    "#         pair_counts = get_pair_counts(vocab_freqs)\n",
    "#         if not pair_counts:\n",
    "#             break\n",
    "#         best_pair = max(pair_counts, key=pair_counts.get)\n",
    "#         vocab_freqs = merge_pair(vocab_freqs, best_pair)\n",
    "#         merged_token = best_pair[0] + best_pair[1]\n",
    "#         merge_rules.append((best_pair, merged_token))\n",
    "#         if step < 5 or step == num_merges - 1:\n",
    "#             print(f\"Step {step+1}: Merge {best_pair} -> '{merged_token}' (count: {pair_counts[best_pair]})\")\n",
    "#     return merge_rules, vocab_freqs"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_17_todo2_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_17_todo2_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Implement the BPE Encoder\n",
    "\n",
    "Now implement the `encode` function that applies learned merge rules to tokenize new text."
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_18_todo2_completion",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Completion\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_18_todo2_completion.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_bpe(text, merge_rules):\n",
    "    \"\"\"\n",
    "    Encode text using learned BPE merge rules.\n",
    "\n",
    "    Args:\n",
    "        text: Input string to tokenize\n",
    "        merge_rules: List of (pair, merged_token) from training\n",
    "\n",
    "    Returns:\n",
    "        List of BPE tokens\n",
    "    \"\"\"\n",
    "    words = text.lower().split()\n",
    "    all_tokens = []\n",
    "\n",
    "    for word in words:\n",
    "        # Start with character-level tokens + end marker\n",
    "        tokens = list(word) + ['_']\n",
    "\n",
    "        # TODO: Apply each merge rule in order\n",
    "        for pair, merged in merge_rules:\n",
    "            # YOUR CODE: scan tokens, merge matching adjacent pairs\n",
    "            new_tokens = []\n",
    "            i = 0\n",
    "            while i < len(tokens):\n",
    "                # Check if current pair matches the merge rule\n",
    "                pass  # YOUR CODE HERE\n",
    "                i += 1\n",
    "            tokens = new_tokens\n",
    "\n",
    "        all_tokens.extend(tokens)\n",
    "\n",
    "    return all_tokens\n",
    "\n",
    "# SOLUTION (uncomment to verify):\n",
    "# def encode_bpe(text, merge_rules):\n",
    "#     words = text.lower().split()\n",
    "#     all_tokens = []\n",
    "#     for word in words:\n",
    "#         tokens = list(word) + ['_']\n",
    "#         for pair, merged in merge_rules:\n",
    "#             new_tokens = []\n",
    "#             i = 0\n",
    "#             while i < len(tokens):\n",
    "#                 if i < len(tokens) - 1 and tokens[i] == pair[0] and tokens[i+1] == pair[1]:\n",
    "#                     new_tokens.append(merged)\n",
    "#                     i += 2\n",
    "#                 else:\n",
    "#                     new_tokens.append(tokens[i])\n",
    "#                     i += 1\n",
    "#             tokens = new_tokens\n",
    "#         all_tokens.extend(tokens)\n",
    "#     return all_tokens"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_19_putting_it_together_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Putting It Together Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_19_putting_it_together_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together\n",
    "\n",
    "Let us train our BPE tokenizer on a real corpus and see it in action."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_20_train_on_corpus_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Train On Corpus Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_20_train_on_corpus_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on our example corpus\n",
    "corpus = \"low low low low low lowest lowest newer newer newer wider wider wider wider\"\n",
    "merge_rules, final_vocab = train_bpe(corpus, num_merges=10)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final vocabulary after training:\")\n",
    "print(\"=\"*50)\n",
    "for word, freq in sorted(final_vocab.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {' '.join(word):20s}  (freq: {freq})\")\n",
    "\n",
    "print(f\"\\nMerge rules learned: {len(merge_rules)}\")\n",
    "for pair, merged in merge_rules:\n",
    "    print(f\"  {pair} -> '{merged}'\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_21_encode_text_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Encode Text Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_21_encode_text_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us encode some text and see how BPE handles known and unknown words."
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_22_encoding_examples_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Encoding Examples Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_22_encoding_examples_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text using our trained tokenizer\n",
    "test_texts = [\n",
    "    \"low\",           # Common word -- should be single token\n",
    "    \"lowest\",        # Known compound -- should split meaningfully\n",
    "    \"newer\",         # Known word\n",
    "    \"widest\",        # UNSEEN word -- can BPE handle it?\n",
    "    \"lower\",         # UNSEEN word -- interesting test\n",
    "]\n",
    "\n",
    "print(\"BPE Encoding Results:\")\n",
    "print(\"-\" * 50)\n",
    "for text in test_texts:\n",
    "    tokens = encode_bpe(text, merge_rules)\n",
    "    print(f\"  '{text:10s}'  ->  {tokens}\")\n",
    "\n",
    "print(\"\\nNotice: BPE can handle unseen words by breaking them\")\n",
    "print(\"into known subword pieces!\")"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_23_comparing_gpt2_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Comparing Gpt2 Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_23_comparing_gpt2_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing with GPT-2's Tokenizer\n",
    "\n",
    "Let us compare our toy BPE with the production tokenizer used by GPT-2."
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_24_tiktoken_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Tiktoken Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_24_tiktoken_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.check_call(['pip', 'install', '-q', 'tiktoken'])\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "test_sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"Transformers are incredible\",\n",
    "    \"supercalifragilisticexpialidocious\",\n",
    "    \"def hello_world():\",\n",
    "    \"GPT-4 uses BPE tokenization\",\n",
    "]\n",
    "\n",
    "print(\"GPT-2 Tokenizer (tiktoken):\")\n",
    "print(\"=\" * 60)\n",
    "for sentence in test_sentences:\n",
    "    token_ids = enc.encode(sentence)\n",
    "    token_strings = [enc.decode([t]) for t in token_ids]\n",
    "    print(f\"\\n  Input:  '{sentence}'\")\n",
    "    print(f\"  IDs:    {token_ids}\")\n",
    "    print(f\"  Tokens: {token_strings}\")\n",
    "    print(f\"  Count:  {len(token_ids)} tokens\")\n",
    "\n",
    "print(f\"\\nGPT-2 vocabulary size: {enc.n_vocab:,}\")"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_25_token_dist_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Token Dist Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_25_token_dist_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Token distribution"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_26_token_dist_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Token Dist Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_26_token_dist_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how GPT-2 tokenizes different types of text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_types = {\n",
    "    'English': \"The quick brown fox jumps over the lazy dog\",\n",
    "    'Code': \"def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + fibonacci(n-2)\",\n",
    "    'Math': \"The eigenvalue decomposition A = PDP^{-1} yields orthogonal eigenvectors\",\n",
    "    'Names': \"Schwarzenegger and Dostoyevsky met at Constantinople\",\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "categories = []\n",
    "token_counts = []\n",
    "chars_per_token = []\n",
    "\n",
    "for name, text in text_types.items():\n",
    "    tokens = enc.encode(text)\n",
    "    categories.append(name)\n",
    "    token_counts.append(len(tokens))\n",
    "    chars_per_token.append(len(text) / len(tokens))\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, token_counts, width, label='Token Count', color='#3498db', edgecolor='black', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, chars_per_token, width, label='Chars/Token', color='#e74c3c', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('GPT-2 Tokenization Efficiency by Text Type', fontsize=13, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, fontsize=11)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gpt2_tokenization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Checkpoint: Common English gets ~4 chars/token; rare names get fewer.\")"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_27_final_output_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Final Output Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_27_final_output_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output\n",
    "\n",
    "Let us build a complete, self-contained BPE tokenizer class and demonstrate it end-to-end."
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_28_simplebpe_class_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Narration: Simplebpe Class Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_28_simplebpe_class_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBPE:\n",
    "    \"\"\"A complete BPE tokenizer built from scratch.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.merge_rules = []\n",
    "        self.vocab = set()\n",
    "\n",
    "    def train(self, text, num_merges=100):\n",
    "        \"\"\"Train the BPE tokenizer on a text corpus.\"\"\"\n",
    "        vocab_freqs = get_word_frequencies(text)\n",
    "        self.merge_rules = []\n",
    "\n",
    "        for step in range(num_merges):\n",
    "            pair_counts = get_pair_counts(vocab_freqs)\n",
    "            if not pair_counts:\n",
    "                break\n",
    "            best_pair = max(pair_counts, key=pair_counts.get)\n",
    "            vocab_freqs = merge_pair(vocab_freqs, best_pair)\n",
    "            merged_token = best_pair[0] + best_pair[1]\n",
    "            self.merge_rules.append((best_pair, merged_token))\n",
    "\n",
    "        # Build final vocabulary\n",
    "        self.vocab = set()\n",
    "        for word in vocab_freqs:\n",
    "            for token in word:\n",
    "                self.vocab.add(token)\n",
    "\n",
    "        print(f\"Training complete: {len(self.merge_rules)} merges, {len(self.vocab)} unique tokens\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text into BPE tokens.\"\"\"\n",
    "        return encode_bpe(text, self.merge_rules)\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "# Train on a larger corpus\n",
    "large_corpus = \"\"\"\n",
    "The transformer architecture has revolutionized natural language processing.\n",
    "Transformers use self-attention mechanisms to process sequences in parallel.\n",
    "The key innovation is the attention mechanism which computes query key value products.\n",
    "Language models predict the next token given previous tokens in the sequence.\n",
    "Training requires tokenization data loading and optimization.\n",
    "The training pipeline converts raw text into trained model weights.\n",
    "Byte pair encoding finds the optimal subword vocabulary for the corpus.\n",
    "\"\"\" * 10  # Repeat for more training data\n",
    "\n",
    "tokenizer = SimpleBPE()\n",
    "tokenizer.train(large_corpus, num_merges=50)\n",
    "\n",
    "print(f\"\\nVocabulary size: {tokenizer.vocab_size()}\")\n",
    "print(f\"\\nEncoding examples:\")\n",
    "for test in [\"transformer\", \"attention\", \"tokenization\", \"neural network\"]:\n",
    "    tokens = tokenizer.encode(test)\n",
    "    print(f\"  '{test}' -> {tokens}\")"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_01_29_closing",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Wrap-Up: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_29_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "**What we built:** A complete BPE tokenizer from scratch -- the same algorithm used in GPT-2, GPT-4, and LLaMA.\n",
    "\n",
    "**Key takeaways:**\n",
    "- Tokenization is the critical first step -- get it wrong and nothing downstream works\n",
    "- BPE finds the sweet spot between character-level and word-level approaches\n",
    "- The algorithm is greedy: repeatedly merge the most frequent adjacent pair\n",
    "- Vocabulary size is a direct engineering tradeoff: larger means more memory for embeddings, smaller means longer sequences\n",
    "\n",
    "**What is next:** In Notebook 2, we will take these token sequences and build the dataset pipeline -- creating input-target pairs for next-token prediction using a sliding window approach."
   ],
   "id": "cell_29"
  }
 ]
}