{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Langevin Dynamics: Sampling with Score Functions -- Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_00_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1_yOuaRupWcvvBB5tNnjVrtDllXqg6x4Q\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/03_00_intro.mp3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_01_setup_run_cell",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Setup Run Cell\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_01_setup_run_cell.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"âœ… GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"âš ï¸ No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Python {sys.version.split()[0]}\")\n",
    "print(f\"ðŸ”¥ PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"ðŸŽ² Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_02_why_it_matters",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_02_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_03_drunk_hiker_analogy",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Drunk Hiker Analogy\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_03_drunk_hiker_analogy.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_04_why_both_terms_matter",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Why Both Terms Matter\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_04_why_both_terms_matter.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_05_math_update_rule",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Math Update Rule\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_05_math_update_rule.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_06_sqrt_2_eta",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Sqrt Eta\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_06_sqrt_2_eta.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_07_numerical_example",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Numerical Example\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_07_numerical_example.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_08_recreate_score_model",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Recreate Score Model\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_08_recreate_score_model.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langevin Dynamics: Sampling with Score Functions -- Vizuara\n",
    "\n",
    "## 1. Why Does This Matter?\n",
    "\n",
    "We have learned how to train a score function using Denoising Score Matching. But a score function alone does not generate data -- it only tells us which direction to move at any point in space.\n",
    "\n",
    "**Langevin Dynamics** is the missing piece. It is a sampling algorithm that takes our trained score function and uses it to navigate from random noise to realistic data samples. It is the \"engine\" that powers generation in score-based models.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand Langevin Dynamics as a stochastic process guided by the score\n",
    "- Implement Langevin sampling from scratch\n",
    "- Visualize sampling trajectories from noise to data\n",
    "- Generate new data points that match the training distribution\n",
    "- Understand why the noise term in Langevin updates is critical\n",
    "\n",
    "## 2. Building Intuition\n",
    "\n",
    "### The Drunk Hiker Analogy\n",
    "\n",
    "Imagine you are dropped into a thick fog on a vast landscape. Hidden somewhere are deep valleys (high-probability regions). You have a compass (the score function) that points downhill toward the nearest valley.\n",
    "\n",
    "If you simply follow the compass perfectly (gradient descent), you might get stuck in a small pothole -- a local minimum that is not the true valley.\n",
    "\n",
    "So instead, you follow the compass direction but also stumble randomly at each step. You are a \"drunk hiker.\" This random stumbling lets you escape shallow potholes and eventually find the true deep valleys.\n",
    "\n",
    "The update rule at each step:\n",
    "$$x_{t+1} = x_t + \\underbrace{\\eta \\cdot s_\\theta(x_t)}_{\\text{follow compass}} + \\underbrace{\\sqrt{2\\eta} \\cdot \\epsilon_t}_{\\text{random stumble}}$$\n",
    "\n",
    "The first term pulls you toward high-probability regions. The second term adds randomness to help exploration.\n",
    "\n",
    "### Why Both Terms Matter\n",
    "\n",
    "- **Without the noise term:** Pure gradient ascent. Gets stuck in local modes. Deterministic -- always produces the same output from the same starting point.\n",
    "- **Without the score term:** Pure random walk. Wanders aimlessly forever.\n",
    "- **Together:** Theoretically guaranteed to sample from the correct distribution (given enough steps and small enough step size).\n",
    "\n",
    "## 3. The Mathematics\n",
    "\n",
    "### The Langevin Dynamics Update Rule\n",
    "\n",
    "Starting from a random point $x_0 \\sim \\mathcal{N}(0, I)$, iterate:\n",
    "\n",
    "$$x_{t+1} = x_t + \\eta \\cdot s_\\theta(x_t) + \\sqrt{2\\eta} \\cdot \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0, I)$$\n",
    "\n",
    "where $\\eta$ is the step size and $s_\\theta$ is the learned score function.\n",
    "\n",
    "**Computationally:** at each step, evaluate the score network, scale by step size, add scaled Gaussian noise, and update the position.\n",
    "\n",
    "### Why sqrt(2 * eta)?\n",
    "\n",
    "The specific scaling $\\sqrt{2\\eta}$ comes from the theory of Langevin diffusion. It ensures that as $\\eta \\to 0$ and the number of steps $\\to \\infty$, the samples converge to the true distribution. The factor of 2 ensures the correct balance between drift (score) and diffusion (noise).\n",
    "\n",
    "### Numerical Example\n",
    "\n",
    "Let us trace through 3 steps. Starting point: $x_0 = [4.0, -3.0]$, step size $\\eta = 0.1$, and suppose the score function points toward the origin.\n",
    "\n",
    "**Step 1:** $s_\\theta(x_0) = [-1.5, 1.2]$, $\\epsilon_0 = [0.3, -0.5]$\n",
    "\n",
    "$$x_1 = [4.0, -3.0] + 0.1 \\times [-1.5, 1.2] + \\sqrt{0.2} \\times [0.3, -0.5]$$\n",
    "$$= [4.0, -3.0] + [-0.15, 0.12] + [0.134, -0.224]$$\n",
    "$$= [3.984, -3.104]$$\n",
    "\n",
    "**Step 2:** $s_\\theta(x_1) = [-1.4, 1.3]$, $\\epsilon_1 = [-0.1, 0.8]$\n",
    "\n",
    "$$x_2 = [3.984, -3.104] + 0.1 \\times [-1.4, 1.3] + \\sqrt{0.2} \\times [-0.1, 0.8]$$\n",
    "$$= [3.984, -3.104] + [-0.14, 0.13] + [-0.045, 0.358]$$\n",
    "$$= [3.799, -2.616]$$\n",
    "\n",
    "**Step 3:** $s_\\theta(x_2) = [-1.2, 1.1]$, $\\epsilon_2 = [0.6, 0.2]$\n",
    "\n",
    "$$x_3 = [3.799, -2.616] + 0.1 \\times [-1.2, 1.1] + \\sqrt{0.2} \\times [0.6, 0.2]$$\n",
    "$$= [3.799, -2.616] + [-0.12, 0.11] + [0.268, 0.089]$$\n",
    "$$= [3.947, -2.417]$$\n",
    "\n",
    "The point is gradually moving toward the data region, with a zigzag path due to the noise. Over many more steps, it will converge to a data cluster.\n",
    "\n",
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 Re-create the DSM-trained Score Model\n",
    "\n",
    "First, let us quickly re-train a score model using DSM (from the previous notebook)."
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate data\n",
    "def generate_data(n_samples=2000):\n",
    "    cluster1 = torch.randn(n_samples // 2, 2) * 0.5 + torch.tensor([2.0, 2.0])\n",
    "    cluster2 = torch.randn(n_samples // 2, 2) * 0.5 + torch.tensor([-2.0, -2.0])\n",
    "    return torch.cat([cluster1, cluster2], dim=0)\n",
    "\n",
    "class ScoreNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128), nn.SiLU(),\n",
    "            nn.Linear(128, 128), nn.SiLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Train with DSM\n",
    "data = generate_data(2000)\n",
    "model = ScoreNetwork()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "sigma = 0.5\n",
    "\n",
    "for epoch in range(2000):\n",
    "    noise = torch.randn_like(data) * sigma\n",
    "    noisy_data = data + noise\n",
    "    target = (data - noisy_data) / (sigma ** 2)\n",
    "    pred = model(noisy_data)\n",
    "    loss = ((pred - target) ** 2).sum(dim=-1).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Training complete. Final loss: {loss.item():.4f}\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_09_visualize_score_field",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize Score Field\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_09_visualize_score_field.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify: visualize the learned score field\n",
    "n_grid = 20\n",
    "x_range = torch.linspace(-5, 5, n_grid)\n",
    "y_range = torch.linspace(-5, 5, n_grid)\n",
    "xx, yy = torch.meshgrid(x_range, y_range, indexing='ij')\n",
    "grid = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores = model(grid)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.1, s=3, c='blue')\n",
    "plt.quiver(grid[:, 0], grid[:, 1], scores[:, 0], scores[:, 1],\n",
    "           color='red', alpha=0.7, scale=50)\n",
    "plt.title('Score Field (Our Compass)')\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "print(\"Arrows point toward data clusters. Our compass is ready!\")"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_10_basic_langevin_sampling_heading",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Basic Langevin Sampling Heading\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_10_basic_langevin_sampling_heading.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Basic Langevin Sampling"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_11_langevin_sample_function",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Code Walkthrough: Langevin Sample Function\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_11_langevin_sample_function.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin_sample(model, n_steps=1000, step_size=0.01,\n",
    "                    n_samples=500, dim=2, record_every=50):\n",
    "    \"\"\"\n",
    "    Generate samples using Langevin Dynamics.\n",
    "\n",
    "    Args:\n",
    "        model: trained score network\n",
    "        n_steps: number of Langevin steps\n",
    "        step_size: eta (learning rate for Langevin)\n",
    "        n_samples: how many independent chains to run\n",
    "        dim: data dimensionality\n",
    "        record_every: save trajectory every N steps\n",
    "\n",
    "    Returns:\n",
    "        final_samples: (n_samples, dim) -- final positions\n",
    "        trajectories: list of (n_samples, dim) tensors at intervals\n",
    "    \"\"\"\n",
    "    # Start from random noise\n",
    "    x = torch.randn(n_samples, dim) * 3.0\n",
    "    trajectories = [x.clone()]\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        with torch.no_grad():\n",
    "            score = model(x)\n",
    "\n",
    "        # Langevin update\n",
    "        noise = torch.randn_like(x)\n",
    "        x = x + step_size * score + np.sqrt(2 * step_size) * noise\n",
    "\n",
    "        if (t + 1) % record_every == 0:\n",
    "            trajectories.append(x.clone())\n",
    "\n",
    "    return x, trajectories\n",
    "\n",
    "# Generate samples\n",
    "samples, trajectories = langevin_sample(model, n_steps=1000, step_size=0.01)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.1, s=3, c='blue', label='True data')\n",
    "plt.scatter(samples[:, 0], samples[:, 1], alpha=0.3, s=5, c='red', label='Generated')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Langevin Dynamics: Generated vs True Data')\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {len(samples)} samples using {1000} Langevin steps\")\n",
    "print(f\"The red dots should overlap with the blue clusters!\")"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_12_visualize_trajectories_heading",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Visualize Trajectories Heading\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_12_visualize_trajectories_heading.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualizing Trajectories"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_13_visualize_trajectories_code",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize Trajectories Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_13_visualize_trajectories_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show individual sampling trajectories\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    # Get one chain's trajectory\n",
    "    chain_traj = torch.stack([t[idx] for t in trajectories]).numpy()\n",
    "\n",
    "    # Plot data\n",
    "    ax.scatter(data[:, 0], data[:, 1], alpha=0.05, s=2, c='blue')\n",
    "\n",
    "    # Plot trajectory\n",
    "    ax.plot(chain_traj[:, 0], chain_traj[:, 1], 'g.-', alpha=0.7,\n",
    "            markersize=4, linewidth=1)\n",
    "    ax.plot(chain_traj[0, 0], chain_traj[0, 1], 'go', markersize=10,\n",
    "            label='Start', zorder=5)\n",
    "    ax.plot(chain_traj[-1, 0], chain_traj[-1, 1], 'r*', markersize=15,\n",
    "            label='End', zorder=5)\n",
    "\n",
    "    ax.set_title(f'Trajectory {idx+1}', fontsize=13)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "\n",
    "plt.suptitle('Langevin Sampling Trajectories (Drunk Hiker Paths)', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Each trajectory starts from noise (green) and zigzags toward data (red).\")\n",
    "print(\"The zigzag pattern is from the noise term -- our 'drunk hiker' stumbling.\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_14_todo_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_14_todo_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn -- TODO Exercises\n",
    "\n",
    "### TODO 1: Implement Langevin Sampling Without Noise"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_15_todo1_implement_without_noise",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo1 Implement Without Noise\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_15_todo1_implement_without_noise.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_sample(model, n_steps=1000, step_size=0.01,\n",
    "                         n_samples=500, dim=2):\n",
    "    \"\"\"\n",
    "    Generate samples using pure gradient ascent (NO noise term).\n",
    "    This is Langevin dynamics without the stochastic part.\n",
    "\n",
    "    Args:\n",
    "        model: trained score network\n",
    "        n_steps: number of steps\n",
    "        step_size: eta\n",
    "        n_samples: number of chains\n",
    "        dim: data dimensionality\n",
    "\n",
    "    Returns:\n",
    "        final_samples: (n_samples, dim)\n",
    "    \"\"\"\n",
    "    x = torch.randn(n_samples, dim) * 3.0\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Implement the update WITHOUT the noise term:\n",
    "    # x = x + step_size * score\n",
    "    # (No sqrt(2*eta) * noise term!)\n",
    "    # ==============================\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        pass  # YOUR CODE HERE\n",
    "\n",
    "    return x"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_16_todo1_visualization",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Todo1 Visualization\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_16_todo1_visualization.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: with noise vs without noise\n",
    "det_samples = deterministic_sample(model)\n",
    "\n",
    "if det_samples is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    axes[0].scatter(data[:, 0], data[:, 1], alpha=0.1, s=3, c='blue')\n",
    "    axes[0].scatter(samples[:, 0], samples[:, 1], alpha=0.3, s=5, c='red')\n",
    "    axes[0].set_title('With Noise (Langevin)')\n",
    "    axes[0].set_aspect('equal')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].scatter(data[:, 0], data[:, 1], alpha=0.1, s=3, c='blue')\n",
    "    axes[1].scatter(det_samples[:, 0], det_samples[:, 1], alpha=0.3, s=5, c='orange')\n",
    "    axes[1].set_title('Without Noise (Deterministic)')\n",
    "    axes[1].set_aspect('equal')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Effect of Noise in Langevin Dynamics')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Without noise: samples collapse to mode centers (less diverse)\")\n",
    "    print(\"With noise: samples spread naturally like the true distribution\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_17_todo2_effect_of_step_size_intro",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Effect Of Step Size Intro\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_17_todo2_effect_of_step_size_intro.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Effect of Step Size"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_18_todo2_implement_step_sizes",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Before You Start: Todo2 Implement Step Sizes\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_18_todo2_implement_step_sizes.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_step_sizes(model, step_sizes, n_steps=1000, n_samples=300):\n",
    "    \"\"\"\n",
    "    Run Langevin sampling with different step sizes and return results.\n",
    "\n",
    "    Args:\n",
    "        model: trained score model\n",
    "        step_sizes: list of eta values to try\n",
    "        n_steps: steps per chain\n",
    "        n_samples: chains per experiment\n",
    "\n",
    "    Returns:\n",
    "        results: dict mapping step_size -> final samples tensor\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # For each step_size in step_sizes:\n",
    "    #   1. Call langevin_sample with that step size\n",
    "    #   2. Store the final samples in results[step_size]\n",
    "    # ==============================\n",
    "\n",
    "    return results\n",
    "\n",
    "# step_sizes = [0.001, 0.01, 0.05, 0.2]\n",
    "# results = experiment_step_sizes(model, step_sizes)\n",
    "#\n",
    "# fig, axes = plt.subplots(1, len(step_sizes), figsize=(6*len(step_sizes), 6))\n",
    "# for ax, eta in zip(axes, step_sizes):\n",
    "#     samps = results[eta]\n",
    "#     ax.scatter(data[:, 0], data[:, 1], alpha=0.1, s=3, c='blue')\n",
    "#     ax.scatter(samps[:, 0], samps[:, 1], alpha=0.3, s=5, c='red')\n",
    "#     ax.set_title(f'eta = {eta}')\n",
    "#     ax.set_aspect('equal')\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "#     ax.set_xlim(-7, 7)\n",
    "#     ax.set_ylim(-7, 7)\n",
    "# plt.suptitle('Effect of Step Size on Langevin Sampling')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_19_putting_it_all_together_heading",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Putting It All Together Heading\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_19_putting_it_all_together_heading.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_20_complete_pipeline",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Narration: Complete Pipeline\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_20_complete_pipeline.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline: Data -> DSM Training -> Langevin Sampling\n",
    "print(\"=\" * 60)\n",
    "print(\"Complete Score-Based Generative Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Generate data (already done)\n",
    "print(f\"\\n1. Training data: {len(data)} samples from 2-cluster mixture\")\n",
    "\n",
    "# Step 2: Train score model with DSM (already done)\n",
    "print(f\"2. Score model trained with DSM (sigma={sigma})\")\n",
    "\n",
    "# Step 3: Sample with Langevin dynamics\n",
    "n_generated = 1000\n",
    "final_samples, traj = langevin_sample(model, n_steps=2000,\n",
    "                                       step_size=0.01,\n",
    "                                       n_samples=n_generated,\n",
    "                                       record_every=200)\n",
    "\n",
    "print(f\"3. Generated {n_generated} new samples via Langevin dynamics\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_21_visualize_evolution",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Visualize Evolution\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_21_visualize_evolution.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the evolution of samples over time\n",
    "n_snapshots = len(traj)\n",
    "fig, axes = plt.subplots(2, (n_snapshots + 1) // 2, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (ax, snapshot) in enumerate(zip(axes, traj)):\n",
    "    ax.scatter(data[:, 0], data[:, 1], alpha=0.05, s=2, c='blue')\n",
    "    ax.scatter(snapshot[:, 0], snapshot[:, 1], alpha=0.2, s=5, c='red')\n",
    "    step_num = i * 200 if i > 0 else 0\n",
    "    ax.set_title(f'Step {step_num}', fontsize=11)\n",
    "    ax.set_xlim(-7, 7)\n",
    "    ax.set_ylim(-7, 7)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "# Hide extra axes\n",
    "for j in range(len(traj), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Evolution of Langevin Samples Over Time', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Watch how samples start as random noise and gradually\")\n",
    "print(\"converge to the data distribution!\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_22_training_and_results_heading",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Training And Results Heading\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_22_training_and_results_heading.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_23_kde_comparison",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Kde Comparison\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_23_kde_comparison.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative comparison: KDE of generated vs true\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# X1 marginal\n",
    "for ax, dim_idx, dim_name in [(axes[0], 0, 'x1'), (axes[1], 1, 'x2')]:\n",
    "    true_vals = data[:, dim_idx].numpy()\n",
    "    gen_vals = final_samples[:, dim_idx].numpy()\n",
    "\n",
    "    x_plot = np.linspace(-6, 6, 200)\n",
    "    kde_true = gaussian_kde(true_vals)\n",
    "    kde_gen = gaussian_kde(gen_vals)\n",
    "\n",
    "    ax.plot(x_plot, kde_true(x_plot), 'b-', linewidth=2, label='True')\n",
    "    ax.plot(x_plot, kde_gen(x_plot), 'r--', linewidth=2, label='Generated')\n",
    "    ax.set_title(f'Marginal Distribution: {dim_name}', fontsize=13)\n",
    "    ax.set_xlabel(dim_name)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Generated vs True Marginal Distributions', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The red dashed line (generated) closely follows the blue line (true).\")\n",
    "print(\"Our score-based generative model works!\")"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_24_final_output_heading",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Transition: Final Output Heading\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_24_final_output_heading.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_25_grand_finale_visualization",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ What to Look For: Grand Finale Visualization\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_25_grand_finale_visualization.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grand finale: complete visualization\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Panel 1: Training data\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax1.scatter(data[:, 0], data[:, 1], alpha=0.3, s=5, c='blue')\n",
    "ax1.set_title('1. Training Data', fontsize=14)\n",
    "ax1.set_xlim(-6, 6)\n",
    "ax1.set_ylim(-6, 6)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Learned score field\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "with torch.no_grad():\n",
    "    field_scores = model(grid)\n",
    "ax2.scatter(data[:, 0], data[:, 1], alpha=0.1, s=3, c='blue')\n",
    "ax2.quiver(grid[:, 0], grid[:, 1],\n",
    "           field_scores[:, 0], field_scores[:, 1],\n",
    "           color='red', alpha=0.7, scale=50)\n",
    "ax2.set_title('2. Learned Score Field (DSM)', fontsize=14)\n",
    "ax2.set_xlim(-6, 6)\n",
    "ax2.set_ylim(-6, 6)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Generated samples\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "ax3.scatter(data[:, 0], data[:, 1], alpha=0.15, s=5, c='blue', label='True')\n",
    "ax3.scatter(final_samples[:, 0], final_samples[:, 1],\n",
    "            alpha=0.3, s=5, c='red', label='Generated')\n",
    "ax3.legend(fontsize=12)\n",
    "ax3.set_title('3. Generated Samples (Langevin)', fontsize=14)\n",
    "ax3.set_xlim(-6, 6)\n",
    "ax3.set_ylim(-6, 6)\n",
    "ax3.set_aspect('equal')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Score-Based Generative Modeling: The Full Pipeline', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY: The Score-Based Generative Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Collect training data from the target distribution\")\n",
    "print(\"2. Train a score network using Denoising Score Matching\")\n",
    "print(\"   (add noise, predict direction back to clean data)\")\n",
    "print(\"3. Generate new samples using Langevin Dynamics\")\n",
    "print(\"   (follow the score compass with random stumbles)\")\n",
    "print(\"\\nThis is the foundation of modern diffusion models!\")\n",
    "print(\"DDPM, Stable Diffusion, and DALL-E all build on this principle.\")"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "narration_03_26_reflection_and_next_steps",
    "tags": [
     "narration"
    ]
   },
   "outputs": [],
   "source": [
    "#@title ðŸŽ§ Listen: Reflection And Next Steps\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_26_reflection_and_next_steps.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "### Think About This\n",
    "\n",
    "1. **Why do we start from random noise?** What would happen if we started from a fixed point like [0, 0]?\n",
    "\n",
    "2. **How many Langevin steps are \"enough\"?** What visual cues tell you that the chains have converged?\n",
    "\n",
    "3. **What is the trade-off between step size and number of steps?** Can a large step size compensate for fewer steps?\n",
    "\n",
    "4. **How does this relate to the reverse diffusion process in DDPM?** In DDPM, each denoising step is guided by a noise prediction network. How is that similar to a Langevin step guided by a score network?\n",
    "\n",
    "### Extension Challenges\n",
    "\n",
    "1. **Annealed Langevin Dynamics:** Instead of a fixed noise level, start with large noise (large sigma) and gradually decrease it. This helps the sampler first find the rough location of modes, then refine. Implement this and compare with fixed-sigma sampling.\n",
    "\n",
    "2. **3D Data:** Generate data from a 3D mixture of Gaussians and visualize the sampling trajectories in 3D using plotly or matplotlib's 3D capabilities.\n",
    "\n",
    "3. **Mode coverage:** With two clusters, does Langevin dynamics visit both modes? Run 100 chains and check what fraction end up in each cluster. Is it roughly 50/50?\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "You now understand the complete score-based generative modeling pipeline:\n",
    "\n",
    "- **Score function:** The gradient of the log density, a vector field pointing toward data\n",
    "- **Denoising Score Matching:** A tractable way to learn the score by predicting noise directions\n",
    "- **Langevin Dynamics:** A stochastic sampling algorithm that uses the score to generate new data\n",
    "\n",
    "Modern diffusion models (DDPM, Score SDE) are sophisticated extensions of these exact ideas, with multi-scale noise levels, U-Net architectures, and continuous-time formulations. But the core principle remains the same: learn the score, then sample with it."
   ],
   "id": "cell_20"
  }
 ]
}