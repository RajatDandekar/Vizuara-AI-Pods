{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "QKV Projections from Scratch \u2014 Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\u2705 GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "print(f\"\\n\ud83d\udce6 Python {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udd25 PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\ud83c\udfb2 Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries, Keys, and Values: Building the QKV Projection from Scratch\n",
    "\n",
    "*Part 1 of the Vizuara series on Self-Attention from First Principles*\n",
    "*Estimated time: 35 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "Every modern language model \u2014 GPT, BERT, LLaMA, Gemini \u2014 is built on a single mechanism: **self-attention**. And at the very core of self-attention are three simple objects: the **Query**, the **Key**, and the **Value**.\n",
    "\n",
    "Before we can understand how Transformers \"think,\" we need to understand how every word in a sentence gets transformed into these three representations. That is what this notebook is about.\n",
    "\n",
    "By the end of this notebook, you will have:\n",
    "- Built the QKV projection from scratch in PyTorch\n",
    "- Computed Q, K, V vectors by hand and verified them against PyTorch\n",
    "- Visualized how different weight matrices create different projections\n",
    "- Understood *why* we need three separate projections instead of one\n",
    "\n",
    "Let us get started."
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "Before touching any code or equations, let us understand what Q, K, and V actually *mean*.\n",
    "\n",
    "Think about how you search for something in a library.\n",
    "\n",
    "- **Query (Q):** This is your search question. You walk into the library and say, \"I need a book about marine biology.\" The Query encodes *what you are looking for*.\n",
    "\n",
    "- **Key (K):** This is the label on each book's spine. Every book in the library has a label that says, \"Here is what I am about \u2014 marine biology, quantum physics, French cooking.\" The Key encodes *what each item offers*.\n",
    "\n",
    "- **Value (V):** This is the actual content inside the book. Once you find a matching book (the Key matches your Query), you open it and read the Value \u2014 the actual information.\n",
    "\n",
    "Here is the beautiful part: in self-attention, **every word plays all three roles simultaneously**. The word \"mat\" has its own Query (when it wants to find relevant context), its own Key (so other words can find it), and its own Value (the information it contributes when found).\n",
    "\n",
    "### Think About This\n",
    "\n",
    "If every word just used its raw embedding as both the \"search question\" and the \"label,\" what would go wrong? Why do we need *separate* learned transformations for Q, K, and V?\n",
    "\n",
    "The answer: a word's role as a *searcher* (Query) is fundamentally different from its role as a *searchable item* (Key). The word \"it\" searching for its referent is a different operation than the word \"it\" being found by other words. Separate weight matrices let the model learn these different roles independently."
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "Each word enters the Transformer as an **embedding vector** \u2014 a numerical representation of its meaning. We then create Q, K, V by multiplying this embedding by three separate learned weight matrices:\n",
    "\n",
    "$$Q = X W^Q, \\quad K = X W^K, \\quad V = X W^V$$\n",
    "\n",
    "**What this equation says computationally:** Take the input embedding matrix $X$ (where each row is one word's embedding), and multiply it by three separate weight matrices. The result is three new matrices \u2014 Q, K, and V \u2014 each with the same number of rows (one per word) but potentially different column dimensions.\n",
    "\n",
    "If $X$ has shape $(n, d_{\\text{model}})$ where $n$ is the number of words and $d_{\\text{model}}$ is the embedding dimension, and each weight matrix has shape $(d_{\\text{model}}, d_k)$, then Q, K, and V each have shape $(n, d_k)$.\n",
    "\n",
    "The weight matrices $W^Q$, $W^K$, and $W^V$ are **learned** during training. The model figures out the best way to create Queries, Keys, and Values by seeing millions of sentences and adjusting these weights through backpropagation."
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It \u2014 Component by Component\n",
    "\n",
    "### 4.1 Word Embeddings\n",
    "\n",
    "Let us start with the very first step: representing words as vectors. In a real Transformer, embeddings are learned during training. For our educational example, we will create simple embeddings by hand."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Our tiny vocabulary\n",
    "sentence = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "\n",
    "# Create simple 4-dimensional embeddings for each word\n",
    "# In a real model, these would be learned; here we define them manually\n",
    "embeddings = {\n",
    "    \"The\": [1.0, 0.0, 0.5, 0.2],\n",
    "    \"cat\": [0.3, 1.0, 0.1, 0.7],\n",
    "    \"sat\": [0.5, 0.2, 1.0, 0.3],\n",
    "    \"on\":  [0.1, 0.4, 0.3, 0.9],\n",
    "    \"the\": [0.9, 0.1, 0.4, 0.2],\n",
    "    \"mat\": [1.0, 0.5, -0.3, 0.8],\n",
    "}\n",
    "\n",
    "# Build the input matrix X: shape (6, 4)\n",
    "X = torch.tensor([embeddings[word] for word in sentence], dtype=torch.float32)\n",
    "\n",
    "print(\"Input matrix X (6 words, 4 dimensions):\")\n",
    "print(X)\n",
    "print(f\"\\nShape: {X.shape}\")\n",
    "print(f\"Each row is one word's embedding\")"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see what these embeddings look like visually."
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the embedding matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "im = ax.imshow(X.numpy(), cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels([f'Dim {i}' for i in range(4)])\n",
    "ax.set_yticks(range(6))\n",
    "ax.set_yticklabels(sentence)\n",
    "ax.set_title('Input Embeddings X', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Embedding Dimension')\n",
    "ax.set_ylabel('Word')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(6):\n",
    "    for j in range(4):\n",
    "        ax.text(j, i, f'{X[i, j].item():.1f}', ha='center', va='center',\n",
    "                color='white' if abs(X[i, j].item()) > 0.5 else 'black', fontsize=10)\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Weight Matrices\n",
    "\n",
    "Now let us create the three weight matrices: $W^Q$, $W^K$, and $W^V$. These project our 4-dimensional embeddings down to 2-dimensional Q, K, V vectors (i.e., $d_k = 2$)."
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weight matrices manually\n",
    "# W^Q: projects embeddings into \"query space\"\n",
    "W_Q = torch.tensor([\n",
    "    [0.2, 0.1],\n",
    "    [0.4, -0.3],\n",
    "    [0.1, 0.5],\n",
    "    [-0.2, 0.3]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# W^K: projects embeddings into \"key space\"\n",
    "W_K = torch.tensor([\n",
    "    [0.3, -0.1],\n",
    "    [0.1, 0.4],\n",
    "    [-0.2, 0.2],\n",
    "    [0.5, 0.1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# W^V: projects embeddings into \"value space\"\n",
    "W_V = torch.tensor([\n",
    "    [0.1, 0.3],\n",
    "    [-0.2, 0.5],\n",
    "    [0.4, -0.1],\n",
    "    [0.2, 0.2]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(f\"W_Q shape: {W_Q.shape}  (d_model=4 -> d_k=2)\")\n",
    "print(f\"W_K shape: {W_K.shape}\")\n",
    "print(f\"W_V shape: {W_V.shape}\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Computing Q, K, V\n",
    "\n",
    "This is the core step. We multiply the input embeddings by each weight matrix."
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Q, K, V\n",
    "Q = X @ W_Q  # Matrix multiplication: (6, 4) @ (4, 2) = (6, 2)\n",
    "K = X @ W_K\n",
    "V = X @ W_V\n",
    "\n",
    "print(\"Queries Q:\")\n",
    "print(Q)\n",
    "print(f\"\\nKeys K:\")\n",
    "print(K)\n",
    "print(f\"\\nValues V:\")\n",
    "print(V)\n",
    "\n",
    "print(f\"\\nAll three have shape: {Q.shape} \u2014 6 words, each with a 2D vector\")"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify one computation by hand \u2014 the Query for \"mat\" (the last word):"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual computation for \"mat\"\n",
    "x_mat = X[5]  # [1.0, 0.5, -0.3, 0.8]\n",
    "q_mat_manual = torch.tensor([\n",
    "    x_mat[0]*W_Q[0,0] + x_mat[1]*W_Q[1,0] + x_mat[2]*W_Q[2,0] + x_mat[3]*W_Q[3,0],\n",
    "    x_mat[0]*W_Q[0,1] + x_mat[1]*W_Q[1,1] + x_mat[2]*W_Q[2,1] + x_mat[3]*W_Q[3,1],\n",
    "])\n",
    "\n",
    "print(f\"x_mat = {x_mat.tolist()}\")\n",
    "print(f\"\\nManual computation:\")\n",
    "print(f\"  q[0] = (1.0)(0.2) + (0.5)(0.4) + (-0.3)(0.1) + (0.8)(-0.2)\")\n",
    "print(f\"       = 0.2 + 0.2 - 0.03 - 0.16 = {q_mat_manual[0].item():.4f}\")\n",
    "print(f\"  q[1] = (1.0)(0.1) + (0.5)(-0.3) + (-0.3)(0.5) + (0.8)(0.3)\")\n",
    "print(f\"       = 0.1 - 0.15 - 0.15 + 0.24 = {q_mat_manual[1].item():.4f}\")\n",
    "print(f\"\\nPyTorch result: {Q[5].tolist()}\")\n",
    "print(f\"Manual result:  {q_mat_manual.tolist()}\")\n",
    "print(f\"Match: {torch.allclose(Q[5], q_mat_manual)}\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Q, K, V as 2D scatter plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, matrix, title, color in zip(axes,\n",
    "                                      [Q, K, V],\n",
    "                                      ['Queries (Q)', 'Keys (K)', 'Values (V)'],\n",
    "                                      ['#e74c3c', '#2ecc71', '#3498db']):\n",
    "    data = matrix.detach().numpy()\n",
    "    ax.scatter(data[:, 0], data[:, 1], c=color, s=100, edgecolors='black', linewidth=1, zorder=5)\n",
    "    for i, word in enumerate(sentence):\n",
    "        ax.annotate(word, (data[i, 0], data[i, 1]),\n",
    "                    textcoords=\"offset points\", xytext=(8, 8),\n",
    "                    fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Dimension 0', fontsize=11)\n",
    "    ax.set_ylabel('Dimension 1', fontsize=11)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='gray', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='gray', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('QKV Projections of \"The cat sat on the mat\"', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the same words end up in different positions in Q-space, K-space, and V-space. The weight matrices have learned (well, we defined them) different projections \u2014 each one highlights different aspects of each word."
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn\n",
    "\n",
    "### TODO 1: Implement the QKV Projection as a PyTorch Module"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVProjection(nn.Module):\n",
    "    \"\"\"\n",
    "    Compute Query, Key, and Value projections from input embeddings.\n",
    "\n",
    "    Args:\n",
    "        d_model: Dimension of input embeddings\n",
    "        d_k: Dimension of Q, K, V vectors (projection dimension)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_k):\n",
    "        super().__init__()\n",
    "        # ============ TODO ============\n",
    "        # Create three nn.Linear layers (without bias) for W_Q, W_K, W_V\n",
    "        # Each should project from d_model to d_k\n",
    "        # Hint: nn.Linear(in_features, out_features, bias=False)\n",
    "        # ==============================\n",
    "\n",
    "        self.W_q = ???  # YOUR CODE HERE\n",
    "        self.W_k = ???  # YOUR CODE HERE\n",
    "        self.W_v = ???  # YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model)\n",
    "\n",
    "        Returns:\n",
    "            Q, K, V: Each of shape (batch_size, seq_len, d_k)\n",
    "        \"\"\"\n",
    "        # ============ TODO ============\n",
    "        # Apply each linear layer to x to get Q, K, V\n",
    "        # ==============================\n",
    "\n",
    "        Q = ???  # YOUR CODE HERE\n",
    "        K = ???  # YOUR CODE HERE\n",
    "        V = ???  # YOUR CODE HERE\n",
    "\n",
    "        return Q, K, V"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "torch.manual_seed(42)\n",
    "qkv = QKVProjection(d_model=64, d_k=16)\n",
    "test_input = torch.randn(2, 10, 64)  # batch=2, seq_len=10, d_model=64\n",
    "Q_test, K_test, V_test = qkv(test_input)\n",
    "\n",
    "assert Q_test.shape == (2, 10, 16), f\"Expected Q shape (2, 10, 16), got {Q_test.shape}\"\n",
    "assert K_test.shape == (2, 10, 16), f\"Expected K shape (2, 10, 16), got {K_test.shape}\"\n",
    "assert V_test.shape == (2, 10, 16), f\"Expected V shape (2, 10, 16), got {V_test.shape}\"\n",
    "\n",
    "# Q, K, V should be different (different weight matrices)\n",
    "assert not torch.allclose(Q_test, K_test), \"Q and K should differ (different projections)\"\n",
    "print(\"All assertions passed!\")"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Experiment with Different Projection Dimensions"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_projections(X, d_model, d_k_values):\n",
    "    \"\"\"\n",
    "    Visualize how different projection dimensions affect the QKV vectors.\n",
    "\n",
    "    Args:\n",
    "        X: Input embeddings of shape (seq_len, d_model)\n",
    "        d_model: Input dimension\n",
    "        d_k_values: List of projection dimensions to compare\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # For each d_k in d_k_values:\n",
    "    #   1. Create random weight matrices W_Q of shape (d_model, d_k)\n",
    "    #   2. Compute Q = X @ W_Q\n",
    "    #   3. Compute the pairwise cosine similarity between all Q vectors\n",
    "    #   4. Store the similarity matrix\n",
    "    #\n",
    "    # Then plot the similarity matrices side by side\n",
    "    #\n",
    "    # Hints:\n",
    "    #   - Use torch.randn(d_model, d_k) for random weights\n",
    "    #   - Use F.cosine_similarity with appropriate broadcasting,\n",
    "    #     or compute manually: sim = Q @ Q.T / (norms * norms.T)\n",
    "    # ==============================\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(d_k_values), figsize=(5*len(d_k_values), 4))\n",
    "    if len(d_k_values) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, d_k in zip(axes, d_k_values):\n",
    "        # YOUR CODE HERE: compute Q and similarity matrix\n",
    "        W_Q = torch.randn(d_model, d_k)\n",
    "        Q = X @ W_Q\n",
    "        norms = Q.norm(dim=1, keepdim=True)\n",
    "        sim = (Q @ Q.T) / (norms @ norms.T + 1e-8)\n",
    "\n",
    "        im = ax.imshow(sim.detach().numpy(), cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        ax.set_title(f'd_k = {d_k}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks(range(len(sentence)))\n",
    "        ax.set_xticklabels(sentence, rotation=45)\n",
    "        ax.set_yticks(range(len(sentence)))\n",
    "        ax.set_yticklabels(sentence)\n",
    "        plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "    plt.suptitle('Query Similarity for Different Projection Dimensions', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the comparison\n",
    "compare_projections(X, d_model=4, d_k_values=[1, 2, 4])"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together\n",
    "\n",
    "Let us now build a complete QKV projection that uses `nn.Linear` (the PyTorch way) and verify it matches our manual computation."
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVProjectionComplete(nn.Module):\n",
    "    \"\"\"Complete QKV projection with manual weight initialization.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_k):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(d_model, d_k, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_k, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_k, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.W_q(x), self.W_k(x), self.W_v(x)\n",
    "\n",
    "# Create the module and set weights manually to match our earlier example\n",
    "qkv_module = QKVProjectionComplete(d_model=4, d_k=2)\n",
    "\n",
    "# nn.Linear stores weights transposed: weight shape is (d_k, d_model)\n",
    "with torch.no_grad():\n",
    "    qkv_module.W_q.weight.copy_(W_Q.T)\n",
    "    qkv_module.W_k.weight.copy_(W_K.T)\n",
    "    qkv_module.W_v.weight.copy_(W_V.T)\n",
    "\n",
    "# Compute Q, K, V using the module\n",
    "Q_mod, K_mod, V_mod = qkv_module(X)\n",
    "\n",
    "print(\"Module Q matches manual Q:\", torch.allclose(Q_mod, Q, atol=1e-6))\n",
    "print(\"Module K matches manual K:\", torch.allclose(K_mod, K, atol=1e-6))\n",
    "print(\"Module V matches manual V:\", torch.allclose(V_mod, V, atol=1e-6))\n",
    "\n",
    "print(\"\\nQ from module:\")\n",
    "print(Q_mod)\n",
    "print(\"\\nQ from manual:\")\n",
    "print(Q)"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results\n",
    "\n",
    "Let us see what happens when we *learn* the QKV projections through training. We will set up a simple task: given a pair of words, predict whether they should attend to each other (1) or not (0). We will let the model learn W_Q and W_K to make this prediction."
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training task: learn which word pairs should attend to each other\n",
    "# Ground truth: \"cat\" and \"sat\" should attend (1), random pairs should not (0)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "d_model = 4\n",
    "d_k = 2\n",
    "\n",
    "# Learnable Q and K projections\n",
    "W_q_learn = nn.Linear(d_model, d_k, bias=False)\n",
    "W_k_learn = nn.Linear(d_model, d_k, bias=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(W_q_learn.parameters()) + list(W_k_learn.parameters()), lr=0.01)\n",
    "\n",
    "# Training data: (word_i, word_j, should_attend)\n",
    "pairs = [\n",
    "    (1, 2, 1.0),  # cat-sat: should attend\n",
    "    (5, 1, 1.0),  # mat-cat: should attend\n",
    "    (0, 3, 0.0),  # The-on: should not attend\n",
    "    (3, 2, 0.0),  # on-sat: should not attend\n",
    "    (1, 5, 1.0),  # cat-mat: should attend\n",
    "    (0, 4, 0.0),  # The-the: should not attend\n",
    "]\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    total_loss = 0\n",
    "    for i, j, target in pairs:\n",
    "        q_i = W_q_learn(X[i].unsqueeze(0))  # Query for word i\n",
    "        k_j = W_k_learn(X[j].unsqueeze(0))  # Key for word j\n",
    "\n",
    "        # Attention score = dot product, passed through sigmoid\n",
    "        score = torch.sigmoid((q_i * k_j).sum() / math.sqrt(d_k))\n",
    "        loss = F.binary_cross_entropy(score, torch.tensor(target))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(total_loss / len(pairs))\n",
    "\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curve\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(losses, color='#3498db', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Learning QKV Projections', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the model learned\n",
    "print(\"Learned attention predictions:\")\n",
    "for i, j, target in pairs:\n",
    "    q_i = W_q_learn(X[i].unsqueeze(0))\n",
    "    k_j = W_k_learn(X[j].unsqueeze(0))\n",
    "    score = torch.sigmoid((q_i * k_j).sum() / math.sqrt(d_k))\n",
    "    pred = \"ATTEND\" if score.item() > 0.5 else \"IGNORE\"\n",
    "    correct = \"correct\" if (score.item() > 0.5) == (target > 0.5) else \"WRONG\"\n",
    "    print(f\"  {sentence[i]:4s} -> {sentence[j]:4s}: score={score.item():.3f}  \"\n",
    "          f\"predict={pred:6s}  target={'ATTEND' if target > 0.5 else 'IGNORE':6s}  [{correct}]\")"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive visualization: Q and K projections in learned space\n",
    "with torch.no_grad():\n",
    "    Q_learned = W_q_learn(X)\n",
    "    K_learned = W_k_learn(X)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, data, title, color in zip(axes,\n",
    "                                    [Q_learned, K_learned],\n",
    "                                    ['Learned Queries', 'Learned Keys'],\n",
    "                                    ['#e74c3c', '#2ecc71']):\n",
    "    pts = data.numpy()\n",
    "    ax.scatter(pts[:, 0], pts[:, 1], c=color, s=150, edgecolors='black', linewidth=1.5, zorder=5)\n",
    "    for i, word in enumerate(sentence):\n",
    "        ax.annotate(word, (pts[i, 0], pts[i, 1]),\n",
    "                    textcoords=\"offset points\", xytext=(10, 10),\n",
    "                    fontsize=12, fontweight='bold',\n",
    "                    arrowprops=dict(arrowstyle='->', color='gray', lw=0.5))\n",
    "    ax.set_xlabel('Dimension 0', fontsize=12)\n",
    "    ax.set_ylabel('Dimension 1', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Learned QKV Projections \u2014 Words That Should Attend Are Nearby',\n",
    "             fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCongratulations! You have built QKV projections from scratch!\")\n",
    "print(\"Next up: using these Q, K, V vectors to compute attention scores.\")"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "### Reflection Questions\n",
    "1. Why do we need three separate weight matrices instead of reusing the same one for Q, K, and V? What would happen if $W^Q = W^K$?\n",
    "2. How does the choice of $d_k$ (the projection dimension) affect the model's ability to distinguish between words?\n",
    "3. In our training example, the model learned to make \"cat\" and \"mat\" attend to each other. What does the learned weight matrix $W^Q$ actually encode about these words?\n",
    "\n",
    "### Optional Challenges\n",
    "1. Add a **bias term** to the projections (use `nn.Linear(d_model, d_k, bias=True)`) and see how it affects the learned representations.\n",
    "2. Try different embedding dimensions and projection dimensions. At what point does the model fail to learn the attention patterns?"
   ],
   "id": "cell_30"
  }
 ]
}