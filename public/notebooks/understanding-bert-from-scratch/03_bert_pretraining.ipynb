{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "BERT Architecture & Pre-training from Scratch ‚Äî Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"1adzccVf_oMTz5XoyEIMJ41XEgZuWBzI6\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/seg_01_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ BERT Architecture & Pre-training from Scratch\n",
    "\n",
    "*Part 3 of the Vizuara series on Understanding BERT from Scratch*\n",
    "*Estimated time: 75 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "chatbot"
    ]
   },
   "source": [
    "# ü§ñ AI Teaching Assistant\n",
    "\n",
    "Need help with this notebook? Open the **AI Teaching Assistant** ‚Äî it has already read this entire notebook and can help with concepts, code, and exercises.\n",
    "\n",
    "**[üëâ Open AI Teaching Assistant](https://pods.vizuara.ai/courses/understanding-bert-from-scratch/practice/3/assistant)**\n",
    "\n",
    "*Tip: Open it in a separate tab and work through this notebook side-by-side.*\n"
   ],
   "id": "vizuara_chatbot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 02 Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_02_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_02_why_it_matters"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "In the previous notebook, we built a Transformer encoder from scratch. Now we will turn it into **BERT** ‚Äî the model that changed NLP forever.\n",
    "\n",
    "BERT's magic comes from two things:\n",
    "1. A clever **input representation** that combines token, segment, and position information\n",
    "2. Two simple but powerful **pre-training objectives** ‚Äî Masked Language Modeling (MLM) and Next Sentence Prediction (NSP)\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Build BERT's complete **input pipeline** (token + segment + position embeddings)\n",
    "2. Implement **Masked Language Modeling** with the 80-10-10 masking strategy\n",
    "3. Implement **Next Sentence Prediction**\n",
    "4. Train a **mini-BERT** on a small corpus and watch it learn to fill in masked words"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup ‚Äî run this cell first\n",
    "!pip install -q torch matplotlib numpy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 04 Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_04_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_04_intuition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "BERT needs to understand three things about every token in the input:\n",
    "1. **What** is this token? (token embedding)\n",
    "2. **Which sentence** does it belong to? (segment embedding)\n",
    "3. **Where** does it sit in the sequence? (position embedding)\n",
    "\n",
    "Think of it like a letter in the mail. It needs:\n",
    "- The **content** (the letter itself ‚Äî token embedding)\n",
    "- The **envelope** telling you which batch it belongs to (segment embedding)\n",
    "- The **address** telling you where it goes (position embedding)\n",
    "\n",
    "BERT also has two special tokens:\n",
    "- **[CLS]**: Added at the start. Its final representation is used for classification tasks.\n",
    "- **[SEP]**: Added between sentences and at the end.\n",
    "\n",
    "### ü§î Think About This\n",
    "Why does BERT use *learned* position embeddings instead of the sinusoidal encodings we built in the previous notebook? What are the trade-offs?"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 05 Math\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_05_math.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_05_math"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "### Input Representation\n",
    "\n",
    "For each token at position $i$, the input is:\n",
    "\n",
    "$$\\text{Input}_i = \\text{TokenEmbed}(\\text{token}_i) + \\text{SegmentEmbed}(\\text{segment}_i) + \\text{PositionEmbed}(i)$$\n",
    "\n",
    "Computationally: we look up three separate embedding vectors and add them element-wise. This gives us a single vector that encodes the token's identity, segment membership, and position ‚Äî all in $d_{\\text{model}}$ dimensions.\n",
    "\n",
    "### Masked Language Modeling Loss\n",
    "\n",
    "For the masked positions, we predict the original token using cross-entropy:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{MLM}} = -\\sum_{i \\in \\text{masked}} \\log P(w_i \\mid \\mathbf{w}_{\\text{context}}; \\theta)$$\n",
    "\n",
    "Computationally: for each masked position, the model outputs a probability distribution over the entire vocabulary, and we want to maximize the probability of the correct token.\n",
    "\n",
    "### Next Sentence Prediction Loss\n",
    "\n",
    "Binary cross-entropy on the [CLS] token's prediction:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{NSP}} = -\\left[y \\log(p) + (1-y) \\log(1-p)\\right]$$\n",
    "\n",
    "Computationally: $y=1$ if sentence B actually follows sentence A, $y=0$ otherwise. We want the model to correctly predict whether two sentences are consecutive.\n",
    "\n",
    "### Total Pre-training Loss\n",
    "\n",
    "$$\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{MLM}} + \\mathcal{L}_{\\text{NSP}}$$"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 03 Setup\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_03_setup.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_03_setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 06 Tokenizer Corpus\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_06_tokenizer_corpus.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_06_tokenizer_corpus"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It ‚Äî Component by Component\n",
    "\n",
    "### 4.1 A Simple Tokenizer\n",
    "\n",
    "Real BERT uses WordPiece tokenization, but for our mini-BERT we will use a word-level tokenizer."
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small corpus for pre-training our mini-BERT\n",
    "corpus_sentences = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the cat purred on the rug\",\n",
    "    \"the dog chased the cat\",\n",
    "    \"the dog barked at the cat\",\n",
    "    \"she went to the bank to deposit money\",\n",
    "    \"he walked to the bank to withdraw cash\",\n",
    "    \"money was deposited at the bank\",\n",
    "    \"cash was withdrawn from the bank\",\n",
    "    \"the river bank was covered with grass\",\n",
    "    \"the river bank had beautiful flowers\",\n",
    "    \"he sat on the bank of the river\",\n",
    "    \"the bank of the river was muddy\",\n",
    "    \"she loves the beautiful flowers\",\n",
    "    \"the flowers in the garden are beautiful\",\n",
    "    \"he walked to the garden to see flowers\",\n",
    "    \"the cat slept on the rug all day\",\n",
    "    \"the dog played in the garden\",\n",
    "    \"she deposited cash at the bank\",\n",
    "    \"he withdrew money from the bank\",\n",
    "    \"the mat was on the floor all day\",\n",
    "]\n",
    "\n",
    "# Build vocabulary with special tokens\n",
    "special_tokens = [\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\"]\n",
    "all_words = [w for s in corpus_sentences for w in s.split()]\n",
    "word_counts = Counter(all_words)\n",
    "vocab_words = sorted(word_counts.keys())\n",
    "vocab = special_tokens + vocab_words\n",
    "\n",
    "word_to_id = {w: i for i, w in enumerate(vocab)}\n",
    "id_to_word = {i: w for w, i in word_to_id.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "PAD_ID = word_to_id[\"[PAD]\"]\n",
    "CLS_ID = word_to_id[\"[CLS]\"]\n",
    "SEP_ID = word_to_id[\"[SEP]\"]\n",
    "MASK_ID = word_to_id[\"[MASK]\"]\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Special tokens: [PAD]={PAD_ID}, [CLS]={CLS_ID}, [SEP]={SEP_ID}, [MASK]={MASK_ID}\")\n",
    "print(f\"\\nSample vocabulary: {list(word_to_id.items())[:10]}\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 07 Bert Embedding\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_07_bert_embedding.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_07_bert_embedding"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 BERT Input Embeddings"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Input Embedding = Token + Segment + Position embeddings.\n",
    "\n",
    "    All three are learned embedding tables. Their outputs are\n",
    "    summed element-wise to produce the final input representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_len=128, num_segments=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        self.segment_embedding = nn.Embedding(num_segments, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_len, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, token_ids, segment_ids):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_ids: (batch, seq_len) ‚Äî token indices\n",
    "            segment_ids: (batch, seq_len) ‚Äî 0 for sentence A, 1 for sentence B\n",
    "        Returns:\n",
    "            (batch, seq_len, d_model) ‚Äî combined embedding\n",
    "        \"\"\"\n",
    "        seq_len = token_ids.size(1)\n",
    "        position_ids = torch.arange(seq_len, device=token_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Look up each embedding\n",
    "        tok_emb = self.token_embedding(token_ids)\n",
    "        seg_emb = self.segment_embedding(segment_ids)\n",
    "        pos_emb = self.position_embedding(position_ids)\n",
    "\n",
    "        # Sum them\n",
    "        combined = tok_emb + seg_emb + pos_emb\n",
    "\n",
    "        # Apply layer norm and dropout\n",
    "        return self.dropout(self.layer_norm(combined))"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the embedding layer\n",
    "bert_emb = BERTEmbedding(vocab_size, d_model=64)\n",
    "\n",
    "# Encode: [CLS] the cat sat [SEP] the dog barked [SEP]\n",
    "sample_tokens = torch.tensor([[CLS_ID, word_to_id[\"the\"], word_to_id[\"cat\"],\n",
    "                                word_to_id[\"sat\"], SEP_ID, word_to_id[\"the\"],\n",
    "                                word_to_id[\"dog\"], word_to_id[\"barked\"], SEP_ID]])\n",
    "sample_segments = torch.tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1]])\n",
    "\n",
    "output = bert_emb(sample_tokens, sample_segments)\n",
    "print(f\"Token IDs shape:   {sample_tokens.shape}\")\n",
    "print(f\"Segment IDs shape: {sample_segments.shape}\")\n",
    "print(f\"Embedding output:  {output.shape}\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 08 Embedding Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_08_embedding_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_08_embedding_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize the three embedding components\n",
    "with torch.no_grad():\n",
    "    tok = bert_emb.token_embedding(sample_tokens)[0].numpy()\n",
    "    seg = bert_emb.segment_embedding(sample_segments)[0].numpy()\n",
    "    pos_ids = torch.arange(sample_tokens.size(1)).unsqueeze(0)\n",
    "    pos = bert_emb.position_embedding(pos_ids)[0].numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "words_list = [\"[CLS]\", \"the\", \"cat\", \"sat\", \"[SEP]\", \"the\", \"dog\", \"barked\", \"[SEP]\"]\n",
    "\n",
    "for ax, data, title, cmap in zip(\n",
    "    axes,\n",
    "    [tok, seg, pos],\n",
    "    [\"Token Embeddings\", \"Segment Embeddings\", \"Position Embeddings\"],\n",
    "    [\"Blues\", \"Greens\", \"Oranges\"]\n",
    "):\n",
    "    im = ax.imshow(data[:, :20].T, cmap=cmap, aspect='auto')\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.set_xticks(range(len(words_list)))\n",
    "    ax.set_xticklabels(words_list, rotation=45, fontsize=9)\n",
    "    ax.set_ylabel(\"Dimension\")\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "plt.suptitle(\"BERT Input = Token + Segment + Position\", fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 09 Mini Bert\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_09_mini_bert.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_09_mini_bert"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Building Mini-BERT\n",
    "\n",
    "Now let us assemble the full BERT model using the Transformer encoder from the previous notebook."
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the building blocks (from Notebook 02)\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    d_k = Q.size(-1)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.matmul(weights, V), weights\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.W_O = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, S, _ = x.shape\n",
    "        Q = self.W_Q(x).view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_K(x).view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_V(x).view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        out, weights = scaled_dot_product_attention(Q, K, V, mask)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, S, self.d_model)\n",
    "        return self.W_O(out), weights\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), nn.ReLU(), nn.Linear(d_ff, d_model))\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        a, w = self.attn(x, mask)\n",
    "        x = self.norm1(x + self.drop(a))\n",
    "        x = self.norm2(x + self.drop(self.ff(x)))\n",
    "        return x, w"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBERT(nn.Module):\n",
    "    \"\"\"\n",
    "    A mini BERT model for educational purposes.\n",
    "\n",
    "    Architecture:\n",
    "    - BERT Embeddings (token + segment + position)\n",
    "    - N Transformer encoder blocks\n",
    "    - MLM head (predict masked tokens)\n",
    "    - NSP head (predict if sentence B follows A)\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model=128, num_heads=4, d_ff=512,\n",
    "                 num_layers=4, max_len=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Input embeddings\n",
    "        self.embedding = BERTEmbedding(vocab_size, d_model, max_len, dropout=dropout)\n",
    "\n",
    "        # Transformer encoder stack\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # MLM head: predict masked tokens\n",
    "        self.mlm_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, vocab_size)\n",
    "        )\n",
    "\n",
    "        # NSP head: binary classification from [CLS]\n",
    "        self.nsp_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, token_ids, segment_ids, attention_mask=None):\n",
    "        # Get embeddings\n",
    "        x = self.embedding(token_ids, segment_ids)\n",
    "\n",
    "        # Pass through encoder layers\n",
    "        all_attn_weights = []\n",
    "        for layer in self.encoder_layers:\n",
    "            x, attn_w = layer(x, attention_mask)\n",
    "            all_attn_weights.append(attn_w)\n",
    "\n",
    "        # MLM predictions (for all positions)\n",
    "        mlm_logits = self.mlm_head(x)  # (batch, seq_len, vocab_size)\n",
    "\n",
    "        # NSP prediction (from [CLS] token ‚Äî position 0)\n",
    "        cls_output = x[:, 0, :]\n",
    "        nsp_logits = self.nsp_head(cls_output)  # (batch, 2)\n",
    "\n",
    "        return mlm_logits, nsp_logits, all_attn_weights\n",
    "\n",
    "# Create our mini-BERT\n",
    "model = MiniBERT(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    d_ff=512,\n",
    "    num_layers=4,\n",
    "    max_len=64\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Mini-BERT parameters: {total_params:,}\")\n",
    "print(f\"(Real BERT-Base has 110,000,000 parameters)\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 10 Mlm Masking\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_10_mlm_masking.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_10_mlm_masking"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Data Preparation: MLM Masking"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlm_data(token_ids, mask_id, vocab_size, mask_prob=0.15,\n",
    "                    special_token_ids=None):\n",
    "    \"\"\"\n",
    "    Apply BERT's masking strategy to a token sequence.\n",
    "\n",
    "    The 80-10-10 rule:\n",
    "    - 80% of masked tokens ‚Üí replaced with [MASK]\n",
    "    - 10% of masked tokens ‚Üí replaced with random word\n",
    "    - 10% of masked tokens ‚Üí kept unchanged\n",
    "\n",
    "    Args:\n",
    "        token_ids: list of token IDs\n",
    "        mask_prob: probability of masking each token (default: 15%)\n",
    "\n",
    "    Returns:\n",
    "        masked_ids: token IDs with masking applied\n",
    "        mlm_labels: -100 for non-masked positions (ignored in loss),\n",
    "                    original token ID for masked positions\n",
    "    \"\"\"\n",
    "    if special_token_ids is None:\n",
    "        special_token_ids = {PAD_ID, CLS_ID, SEP_ID}\n",
    "\n",
    "    masked_ids = list(token_ids)\n",
    "    mlm_labels = [-100] * len(token_ids)  # -100 = ignore in loss\n",
    "\n",
    "    for i, token_id in enumerate(token_ids):\n",
    "        if token_id in special_token_ids:\n",
    "            continue  # Never mask special tokens\n",
    "\n",
    "        if random.random() < mask_prob:\n",
    "            mlm_labels[i] = token_id  # Store original for loss computation\n",
    "\n",
    "            r = random.random()\n",
    "            if r < 0.8:\n",
    "                masked_ids[i] = mask_id      # 80% ‚Üí [MASK]\n",
    "            elif r < 0.9:\n",
    "                masked_ids[i] = random.randint(len(special_token_ids), vocab_size - 1)  # 10% ‚Üí random\n",
    "            # else: 10% ‚Üí unchanged (already copied)\n",
    "\n",
    "    return masked_ids, mlm_labels\n",
    "\n",
    "# Demo the masking\n",
    "demo_sentence = \"the cat sat on the mat\"\n",
    "demo_ids = [CLS_ID] + [word_to_id[w] for w in demo_sentence.split()] + [SEP_ID]\n",
    "demo_words = [\"[CLS]\"] + demo_sentence.split() + [\"[SEP]\"]\n",
    "\n",
    "print(\"Original:    \", \" \".join(demo_words))\n",
    "for trial in range(3):\n",
    "    masked_ids, labels = create_mlm_data(demo_ids, MASK_ID, vocab_size)\n",
    "    masked_words = [id_to_word[i] for i in masked_ids]\n",
    "    label_words = [id_to_word[l] if l != -100 else \"‚Äî\" for l in labels]\n",
    "    print(f\"Masked ({trial+1}):  \", \" \".join(masked_words))\n",
    "    print(f\"Labels ({trial+1}):  \", \" \".join(label_words))\n",
    "    print()"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 11 Nsp Data\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_11_nsp_data.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_11_nsp_data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Data Preparation: NSP"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nsp_data(corpus_sentences, word_to_id):\n",
    "    \"\"\"\n",
    "    Create Next Sentence Prediction training pairs.\n",
    "\n",
    "    50% of the time: sentence B actually follows sentence A (IsNext = 1)\n",
    "    50% of the time: sentence B is random (NotNext = 0)\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "\n",
    "    for i in range(len(corpus_sentences) - 1):\n",
    "        # Positive pair: actual consecutive sentences\n",
    "        sent_a = corpus_sentences[i].split()\n",
    "        sent_b = corpus_sentences[i + 1].split()\n",
    "        pairs.append((sent_a, sent_b, 1))  # IsNext\n",
    "\n",
    "        # Negative pair: random sentence for B\n",
    "        random_idx = random.choice([j for j in range(len(corpus_sentences)) if j != i + 1])\n",
    "        sent_b_random = corpus_sentences[random_idx].split()\n",
    "        pairs.append((sent_a, sent_b_random, 0))  # NotNext\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def prepare_bert_input(sent_a, sent_b, word_to_id, max_len=64):\n",
    "    \"\"\"\n",
    "    Prepare a single BERT input from two sentences.\n",
    "\n",
    "    Format: [CLS] sent_a [SEP] sent_b [SEP] [PAD]...\n",
    "    \"\"\"\n",
    "    tokens = [CLS_ID] + [word_to_id.get(w, word_to_id[\"[UNK]\"]) for w in sent_a] + [SEP_ID]\n",
    "    segments = [0] * len(tokens)\n",
    "\n",
    "    tokens += [word_to_id.get(w, word_to_id[\"[UNK]\"]) for w in sent_b] + [SEP_ID]\n",
    "    segments += [1] * (len(tokens) - len(segments))\n",
    "\n",
    "    # Pad to max_len\n",
    "    pad_len = max_len - len(tokens)\n",
    "    tokens += [PAD_ID] * pad_len\n",
    "    segments += [0] * pad_len\n",
    "\n",
    "    return tokens[:max_len], segments[:max_len]\n",
    "\n",
    "# Create NSP training data\n",
    "nsp_pairs = create_nsp_data(corpus_sentences, word_to_id)\n",
    "print(f\"Total NSP training pairs: {len(nsp_pairs)}\")\n",
    "print(f\"  IsNext pairs: {sum(1 for _, _, l in nsp_pairs if l == 1)}\")\n",
    "print(f\"  NotNext pairs: {sum(1 for _, _, l in nsp_pairs if l == 0)}\")\n",
    "print(f\"\\nExample pair (IsNext):\")\n",
    "print(f\"  A: {' '.join(nsp_pairs[0][0])}\")\n",
    "print(f\"  B: {' '.join(nsp_pairs[0][1])}\")\n",
    "print(f\"  Label: {'IsNext' if nsp_pairs[0][2] else 'NotNext'}\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 12 Todo Training Step\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_12_todo_training_step.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_12_todo_training_step"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üîß Your Turn\n",
    "\n",
    "### TODO: Implement the Training Step\n",
    "\n",
    "Implement the combined MLM + NSP training step."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, token_ids, segment_ids, mlm_labels, nsp_labels):\n",
    "    \"\"\"\n",
    "    Perform one BERT pre-training step.\n",
    "\n",
    "    Args:\n",
    "        token_ids: (batch, seq_len) ‚Äî masked token IDs\n",
    "        segment_ids: (batch, seq_len) ‚Äî segment IDs\n",
    "        mlm_labels: (batch, seq_len) ‚Äî -100 for non-masked, original ID for masked\n",
    "        nsp_labels: (batch,) ‚Äî 1 for IsNext, 0 for NotNext\n",
    "\n",
    "    Returns:\n",
    "        total_loss, mlm_loss, nsp_loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    mlm_logits, nsp_logits, _ = model(token_ids, segment_ids)\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Compute MLM loss using F.cross_entropy\n",
    "    #         Hint: reshape mlm_logits to (batch*seq_len, vocab_size)\n",
    "    #         and mlm_labels to (batch*seq_len)\n",
    "    #         F.cross_entropy ignores labels == -100 automatically\n",
    "    #\n",
    "    # Step 2: Compute NSP loss using F.cross_entropy\n",
    "    #         nsp_logits shape: (batch, 2), nsp_labels shape: (batch,)\n",
    "    #\n",
    "    # Step 3: Total loss = mlm_loss + nsp_loss\n",
    "    # ==============================\n",
    "\n",
    "    mlm_loss = ???  # YOUR CODE HERE\n",
    "    nsp_loss = ???  # YOUR CODE HERE\n",
    "    total_loss = ???  # YOUR CODE HERE\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return total_loss.item(), mlm_loss.item(), nsp_loss.item()"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 13 Todo Training Verify\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_13_todo_training_verify.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_13_todo_training_verify"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification ‚Äî test with a single batch\n",
    "model_test = MiniBERT(vocab_size=vocab_size, d_model=64, num_heads=2, d_ff=128, num_layers=2).to(device)\n",
    "opt_test = torch.optim.Adam(model_test.parameters(), lr=1e-3)\n",
    "\n",
    "# Create a small batch\n",
    "test_tokens = torch.randint(5, vocab_size, (2, 16)).to(device)\n",
    "test_segments = torch.zeros(2, 16, dtype=torch.long).to(device)\n",
    "test_mlm_labels = torch.full((2, 16), -100, dtype=torch.long).to(device)\n",
    "test_mlm_labels[0, 3] = 10  # One masked position\n",
    "test_mlm_labels[1, 5] = 15  # One masked position\n",
    "test_nsp_labels = torch.tensor([1, 0]).to(device)\n",
    "\n",
    "total, mlm, nsp = train_step(model_test, opt_test, test_tokens, test_segments,\n",
    "                              test_mlm_labels, test_nsp_labels)\n",
    "assert total > 0, \"‚ùå Loss should be positive\"\n",
    "assert mlm > 0, \"‚ùå MLM loss should be positive\"\n",
    "assert nsp > 0, \"‚ùå NSP loss should be positive\"\n",
    "print(f\"‚úÖ Training step works! Total: {total:.3f}, MLM: {mlm:.3f}, NSP: {nsp:.3f}\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 14 Todo Nsp\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_14_todo_nsp.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_14_todo_nsp"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Implement the NSP Prediction Check\n",
    "\n",
    "Implement a function that uses our trained model to check whether sentence B follows sentence A."
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nsp(model, sent_a, sent_b, word_to_id, device, max_len=32):\n",
    "    \"\"\"\n",
    "    Predict whether sent_b follows sent_a (Next Sentence Prediction).\n",
    "\n",
    "    Args:\n",
    "        sent_a: list of words (sentence A)\n",
    "        sent_b: list of words (sentence B)\n",
    "\n",
    "    Returns:\n",
    "        is_next_prob: probability that B follows A\n",
    "        prediction: \"IsNext\" or \"NotNext\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Build token IDs: [CLS] sent_a [SEP] sent_b [SEP] [PAD]...\n",
    "    # Step 2: Build segment IDs: 0 for sent_a tokens, 1 for sent_b tokens\n",
    "    # Step 3: Forward pass through model to get nsp_logits\n",
    "    # Step 4: Apply softmax to nsp_logits to get probabilities\n",
    "    # Step 5: Return probability and prediction label\n",
    "    # ==============================\n",
    "\n",
    "    tokens, segments = ???, ???  # YOUR CODE HERE\n",
    "\n",
    "    token_tensor = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "    segment_tensor = torch.tensor([segments], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, nsp_logits, _ = model(token_tensor, segment_tensor)\n",
    "        probs = ???  # YOUR CODE HERE: softmax over nsp_logits\n",
    "\n",
    "    is_next_prob = ???  # YOUR CODE HERE: probability of IsNext (index 1)\n",
    "    prediction = ???  # YOUR CODE HERE: \"IsNext\" if prob > 0.5 else \"NotNext\"\n",
    "\n",
    "    return is_next_prob, prediction"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 15 Todo Nsp Verify\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_15_todo_nsp_verify.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_15_todo_nsp_verify"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification (run AFTER training)\n",
    "prob, pred = predict_nsp(\n",
    "    model,\n",
    "    \"the cat sat on the mat\".split(),\n",
    "    \"the cat purred on the rug\".split(),\n",
    "    word_to_id, device\n",
    ")\n",
    "assert isinstance(prob, float), \"‚ùå Should return a float probability\"\n",
    "assert pred in [\"IsNext\", \"NotNext\"], f\"‚ùå Prediction should be 'IsNext' or 'NotNext', got '{pred}'\"\n",
    "print(f\"‚úÖ NSP prediction works! Prob(IsNext) = {prob:.3f}, Prediction = {pred}\")"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 16 Training\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_16_training.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_16_training"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Mini-BERT"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_batch(nsp_pairs, word_to_id, batch_size=8, max_len=32):\n",
    "    \"\"\"Create a batch of training examples with MLM masking and NSP labels.\"\"\"\n",
    "    batch = random.sample(nsp_pairs, min(batch_size, len(nsp_pairs)))\n",
    "\n",
    "    all_tokens = []\n",
    "    all_segments = []\n",
    "    all_mlm_labels = []\n",
    "    all_nsp_labels = []\n",
    "\n",
    "    for sent_a, sent_b, nsp_label in batch:\n",
    "        tokens, segments = prepare_bert_input(sent_a, sent_b, word_to_id, max_len)\n",
    "        masked_tokens, mlm_labels = create_mlm_data(tokens, MASK_ID, vocab_size)\n",
    "\n",
    "        all_tokens.append(masked_tokens)\n",
    "        all_segments.append(segments)\n",
    "        all_mlm_labels.append(mlm_labels)\n",
    "        all_nsp_labels.append(nsp_label)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(all_tokens, dtype=torch.long).to(device),\n",
    "        torch.tensor(all_segments, dtype=torch.long).to(device),\n",
    "        torch.tensor(all_mlm_labels, dtype=torch.long).to(device),\n",
    "        torch.tensor(all_nsp_labels, dtype=torch.long).to(device),\n",
    "    )\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "mlm_losses = []\n",
    "nsp_losses = []\n",
    "total_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    tokens, segments, mlm_labels, nsp_labels = create_training_batch(\n",
    "        nsp_pairs, word_to_id, BATCH_SIZE, max_len=32\n",
    "    )\n",
    "    total, mlm, nsp = train_step(model, optimizer, tokens, segments, mlm_labels, nsp_labels)\n",
    "\n",
    "    total_losses.append(total)\n",
    "    mlm_losses.append(mlm)\n",
    "    nsp_losses.append(nsp)\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{EPOCHS} | Total: {total:.3f} | MLM: {mlm:.3f} | NSP: {nsp:.3f}\")"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 17 Training Curves\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_17_training_curves.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_17_training_curves"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "axes[0].plot(total_losses, color='steelblue', alpha=0.7)\n",
    "axes[0].set_title(\"Total Loss\", fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(mlm_losses, color='coral', alpha=0.7)\n",
    "axes[1].set_title(\"MLM Loss\", fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "axes[2].plot(nsp_losses, color='forestgreen', alpha=0.7)\n",
    "axes[2].set_title(\"NSP Loss\", fontsize=13, fontweight='bold')\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Mini-BERT Pre-training Progress\", fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 18 Final Predictions\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_18_final_predictions.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_18_final_predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üéØ Final Output: Mini-BERT Fills in the Blanks"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_masked_word(model, sentence, mask_position, word_to_id, id_to_word, top_k=5):\n",
    "    \"\"\"\n",
    "    Use our trained mini-BERT to predict a masked word.\n",
    "\n",
    "    Args:\n",
    "        sentence: string like \"the cat sat on the mat\"\n",
    "        mask_position: index of the word to mask (0-indexed, in original sentence)\n",
    "        top_k: number of predictions to show\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    words = sentence.split()\n",
    "    original_word = words[mask_position]\n",
    "\n",
    "    # Build input: [CLS] word1 word2 ... [SEP]\n",
    "    token_ids = [CLS_ID] + [word_to_id.get(w, word_to_id[\"[UNK]\"]) for w in words] + [SEP_ID]\n",
    "    # Mask the target position (+1 for [CLS])\n",
    "    token_ids[mask_position + 1] = MASK_ID\n",
    "    segment_ids = [0] * len(token_ids)\n",
    "\n",
    "    # Pad\n",
    "    max_len = 32\n",
    "    pad_len = max_len - len(token_ids)\n",
    "    token_ids += [PAD_ID] * pad_len\n",
    "    segment_ids += [0] * pad_len\n",
    "\n",
    "    token_tensor = torch.tensor([token_ids], dtype=torch.long).to(device)\n",
    "    segment_tensor = torch.tensor([segment_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mlm_logits, _, _ = model(token_tensor, segment_tensor)\n",
    "\n",
    "    # Get predictions for the masked position\n",
    "    masked_logits = mlm_logits[0, mask_position + 1]  # +1 for [CLS]\n",
    "    probs = F.softmax(masked_logits, dim=-1)\n",
    "    top_probs, top_ids = probs.topk(top_k)\n",
    "\n",
    "    return original_word, [(id_to_word[idx.item()], prob.item()) for idx, prob in zip(top_ids, top_probs)]\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    (\"the cat sat on the mat\", 0),      # Mask \"the\"\n",
    "    (\"the cat sat on the mat\", 1),      # Mask \"cat\"\n",
    "    (\"she went to the bank to deposit money\", 4),  # Mask \"bank\"\n",
    "    (\"the river bank was covered with grass\", 2),   # Mask \"bank\"\n",
    "    (\"the dog barked at the cat\", 1),   # Mask \"dog\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Mini-BERT Masked Word Predictions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence, mask_pos in test_sentences:\n",
    "    words = sentence.split()\n",
    "    masked_display = words.copy()\n",
    "    masked_display[mask_pos] = \"[MASK]\"\n",
    "\n",
    "    original, predictions = predict_masked_word(\n",
    "        model, sentence, mask_pos, word_to_id, id_to_word\n",
    "    )\n",
    "\n",
    "    print(f\"\\nInput:    {' '.join(masked_display)}\")\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Top predictions:\")\n",
    "    for word, prob in predictions:\n",
    "        marker = \"‚úÖ\" if word == original else \"  \"\n",
    "        print(f\"  {marker} {word:12s} ({prob:.3f})\")"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 19 Final Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_19_final_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_19_final_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize predictions as bar charts\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "test_cases = [\n",
    "    (\"the cat sat on the mat\", 1, \"Predict 'cat'\"),\n",
    "    (\"she went to the bank to deposit money\", 4, \"Predict 'bank' (financial)\"),\n",
    "    (\"the river bank was covered with grass\", 2, \"Predict 'bank' (river)\"),\n",
    "]\n",
    "\n",
    "for ax, (sentence, mask_pos, title) in zip(axes, test_cases):\n",
    "    original, predictions = predict_masked_word(model, sentence, mask_pos, word_to_id, id_to_word)\n",
    "    words_pred = [w for w, p in predictions[:5]]\n",
    "    probs_pred = [p for w, p in predictions[:5]]\n",
    "    colors = ['forestgreen' if w == original else 'steelblue' for w in words_pred]\n",
    "\n",
    "    ax.barh(range(len(words_pred)), probs_pred, color=colors)\n",
    "    ax.set_yticks(range(len(words_pred)))\n",
    "    ax.set_yticklabels(words_pred, fontsize=11)\n",
    "    ax.set_xlabel(\"Probability\")\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "plt.suptitle(\"Mini-BERT Predictions (green = correct)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ Congratulations! You've built and trained BERT from scratch!\")\n",
    "print(\"   Our mini-BERT learned to predict masked words using bidirectional context.\")\n",
    "print(\"   Next up: fine-tuning a real BERT model for downstream tasks.\")"
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Seg 20 Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/seg_20_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_seg_20_closing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reflection and Next Steps\n",
    "\n",
    "### ü§î Reflection Questions\n",
    "1. Why does BERT mask only 15% of tokens, not 50% or 100%? What would happen if we masked too many tokens?\n",
    "2. The 80-10-10 rule replaces some masked tokens with random words. Why does this help? (Hint: think about the mismatch between pre-training and fine-tuning.)\n",
    "3. Later research (RoBERTa) showed that NSP does not actually help much. Why do you think that might be?\n",
    "\n",
    "### üèÜ Optional Challenges\n",
    "1. **Dynamic Masking**: Instead of masking the same positions every epoch, re-mask randomly each time (this is what RoBERTa does). Does it improve performance?\n",
    "2. **Whole Word Masking**: Instead of masking individual subword tokens, mask entire words at once. Implement this variant.\n",
    "3. **Scale Up**: Increase d_model to 256 and num_layers to 6. Train for longer. Does the model get noticeably better at predicting masked words?"
   ],
   "id": "cell_31"
  }
 ]
}