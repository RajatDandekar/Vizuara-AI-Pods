{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "01_chain_of_thought_sft"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\u2705 GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "print(f\"\\n\ud83d\udce6 Python {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udd25 PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\ud83c\udfb2 Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Supervised Fine-Tuning -- Vizuara\n",
    "\n",
    "In this notebook, we will teach a small language model to produce step-by-step reasoning traces using supervised fine-tuning (SFT). By the end, you will have a model that wraps its thinking in `<think>` tags before answering math questions.\n",
    "\n",
    "**What you will build:** A fine-tuned GPT-2 model that generates chain-of-thought reasoning for grade-school math problems."
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check and setup\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on CPU \u2014 training will be slower but still works.\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "Large language models like GPT-4 and DeepSeek-R1 can solve complex math problems by \"thinking out loud\" \u2014 generating intermediate reasoning steps before the final answer. But how does a model learn to do this?\n",
    "\n",
    "The first step is **supervised fine-tuning on chain-of-thought data**. We take a base model and train it on examples where each answer includes step-by-step reasoning. The model learns the *format* of thinking: how to break problems down, how to show its work, and how to structure a logical argument.\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- How to format chain-of-thought training data\n",
    "- How the SFT loss trains on reasoning tokens\n",
    "- How to fine-tune a small model to produce reasoning traces\n",
    "- Why SFT alone is necessary but not sufficient"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "Think about how you learned math in school. Your teacher did not just give you answers \u2014 they showed you worked examples. Step by step, they demonstrated *how* to solve a problem, and then you practiced on similar problems.\n",
    "\n",
    "SFT does exactly the same thing for language models. We show the model many worked examples, and it learns to generate similar step-by-step solutions.\n",
    "\n",
    "The key idea: we wrap the reasoning in special `<think>...</think>` tags so the model knows where the \"thinking\" starts and ends.\n",
    "\n",
    "### Think About This\n",
    "Before we dive in, consider:\n",
    "- Why might a model that just predicts the answer directly fail on multi-step problems?\n",
    "- What advantage does \"thinking out loud\" provide?"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "The SFT training objective is standard next-token prediction. Given an input sequence, the model learns to predict each token given all previous tokens.\n",
    "\n",
    "The loss function is the cross-entropy loss over the entire completion sequence (including the reasoning tokens):\n",
    "\n",
    "$$\\mathcal{L}_{\\text{SFT}} = -\\sum_{t=1}^{T} \\log p_\\theta(y_t \\mid y_{<t}, x)$$\n",
    "\n",
    "where:\n",
    "- $x$ is the input prompt\n",
    "- $y_t$ is the $t$-th token in the target sequence\n",
    "- $T$ is the total number of tokens (reasoning + answer)\n",
    "- $\\theta$ represents the model parameters\n",
    "\n",
    "**Computational meaning:** For each position in the sequence, the model outputs a probability distribution over the vocabulary. We take the log probability of the correct next token and sum these up. The negative sum is our loss \u2014 lower is better."
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute this loss manually to build understanding\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simulated model probabilities for 4 tokens\n",
    "# In reality, these come from the model's softmax output\n",
    "token_probs = torch.tensor([0.8, 0.7, 0.5, 0.9])\n",
    "\n",
    "# Compute per-token log probabilities\n",
    "log_probs = torch.log(token_probs)\n",
    "print(\"Per-token log probabilities:\")\n",
    "for i, (p, lp) in enumerate(zip(token_probs, log_probs)):\n",
    "    print(f\"  Token {i+1}: p = {p:.1f}, log(p) = {lp:.3f}\")\n",
    "\n",
    "# Compute total loss\n",
    "total_loss = -log_probs.sum()\n",
    "avg_loss = total_loss / len(token_probs)\n",
    "print(f\"\\nTotal loss: {total_loss:.3f}\")\n",
    "print(f\"Average per-token loss: {avg_loss:.3f}\")\n",
    "print(f\"\\nAs the model gets better, probabilities increase and loss decreases.\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It -- Component by Component\n",
    "\n",
    "### 4.1 Loading the Base Model\n",
    "\n",
    "We will use GPT-2 as our base model. It is small enough to fine-tune on a single GPU but powerful enough to demonstrate chain-of-thought reasoning."
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# GPT-2 does not have a padding token by default\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Add special tokens for reasoning\n",
    "special_tokens = {\"additional_special_tokens\": [\"<think>\", \"</think>\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Vocabulary size: {len(tokenizer)}\")\n",
    "print(f\"<think> token ID: {tokenizer.convert_tokens_to_ids('<think>')}\")\n",
    "print(f\"</think> token ID: {tokenizer.convert_tokens_to_ids('</think>')}\")"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Creating Chain-of-Thought Training Data\n",
    "\n",
    "For training, we need examples with step-by-step reasoning. Let us create a small dataset of math problems with chain-of-thought solutions."
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-thought training examples\n",
    "cot_examples = [\n",
    "    {\n",
    "        \"prompt\": \"What is 15% of 80?\",\n",
    "        \"completion\": \"<think>\\nStep 1: 15% means 15/100 = 0.15.\\nStep 2: 0.15 * 80 = 12.\\nStep 3: Let me verify: 10% of 80 is 8, 5% of 80 is 4, so 15% = 8 + 4 = 12. Correct.\\n</think>\\nThe answer is 12.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"A store sells pencils for $2 each. If you buy 8 pencils and have a $3 coupon, how much do you pay?\",\n",
    "        \"completion\": \"<think>\\nStep 1: Each pencil costs $2. I need 8 pencils.\\nStep 2: Total before coupon: 8 * 2 = $16.\\nStep 3: Apply $3 coupon: 16 - 3 = $13.\\n</think>\\nThe answer is $13.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"If a rectangle has length 7 and width 4, what is its area?\",\n",
    "        \"completion\": \"<think>\\nStep 1: Area of a rectangle = length * width.\\nStep 2: Area = 7 * 4 = 28.\\n</think>\\nThe answer is 28.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Tom has 15 apples. He gives 3 to each of his 4 friends. How many does he have left?\",\n",
    "        \"completion\": \"<think>\\nStep 1: Tom gives away 3 apples per friend to 4 friends.\\nStep 2: Total given away: 3 * 4 = 12 apples.\\nStep 3: Remaining: 15 - 12 = 3 apples.\\n</think>\\nThe answer is 3.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What is 2^5?\",\n",
    "        \"completion\": \"<think>\\nStep 1: 2^5 means 2 multiplied by itself 5 times.\\nStep 2: 2 * 2 = 4, 4 * 2 = 8, 8 * 2 = 16, 16 * 2 = 32.\\n</think>\\nThe answer is 32.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Format for training\n",
    "def format_example(example):\n",
    "    return f\"Question: {example['prompt']}\\n{example['completion']}\"\n",
    "\n",
    "# Show one formatted example\n",
    "print(\"=== Formatted Training Example ===\")\n",
    "print(format_example(cot_examples[0]))\n",
    "print(f\"\\nTotal examples: {len(cot_examples)}\")"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tokenizing the Training Data\n",
    "\n",
    "We tokenize the full sequence (prompt + reasoning + answer) and create input-target pairs for next-token prediction."
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_examples(examples, tokenizer, max_length=256):\n",
    "    \"\"\"Tokenize chain-of-thought examples for SFT training.\"\"\"\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for ex in examples:\n",
    "        text = format_example(ex)\n",
    "        encoded = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        input_ids = encoded[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoded[\"attention_mask\"].squeeze()\n",
    "\n",
    "        # Labels are same as input_ids (shifted internally by the model)\n",
    "        # Set padding tokens to -100 so they are ignored in loss\n",
    "        labels = input_ids.clone()\n",
    "        labels[attention_mask == 0] = -100\n",
    "\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(input_ids_list),\n",
    "        \"attention_mask\": torch.stack(attention_mask_list),\n",
    "        \"labels\": torch.stack(labels_list),\n",
    "    }\n",
    "\n",
    "# Tokenize our examples\n",
    "train_data = tokenize_examples(cot_examples, tokenizer)\n",
    "print(f\"Input shape: {train_data['input_ids'].shape}\")\n",
    "print(f\"Labels shape: {train_data['labels'].shape}\")\n",
    "\n",
    "# Show the first example decoded\n",
    "decoded = tokenizer.decode(train_data[\"input_ids\"][0], skip_special_tokens=False)\n",
    "print(f\"\\nDecoded first example (first 200 chars):\\n{decoded[:200]}\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn -- TODO Exercises\n",
    "\n",
    "### TODO 1: Implement the SFT Training Loop\n",
    "\n",
    "Complete the training loop below. You need to:\n",
    "1. Move the batch to the GPU\n",
    "2. Forward pass through the model\n",
    "3. Compute the loss\n",
    "4. Backpropagate and update"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "NUM_EPOCHS = 50  # Small dataset, so we train for many epochs\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Move data to device\n",
    "    batch = {k: v.to(device) for k, v in train_data.items()}\n",
    "\n",
    "    # Forward pass \u2014 the model computes the loss internally\n",
    "    # when you pass both input_ids and labels\n",
    "    outputs = ???  # YOUR CODE HERE: call model with the batch\n",
    "\n",
    "    loss = ???  # YOUR CODE HERE: extract the loss from outputs\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    ???  # YOUR CODE HERE: backpropagate\n",
    "    ???  # YOUR CODE HERE: update weights\n",
    "    # ==============================\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {loss.item():.4f}\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: Run this cell to check your training\n",
    "assert len(losses) == NUM_EPOCHS, f\"Expected {NUM_EPOCHS} loss values, got {len(losses)}\"\n",
    "assert losses[-1] < losses[0], f\"Loss should decrease! First: {losses[0]:.4f}, Last: {losses[-1]:.4f}\"\n",
    "print(f\"Training complete!\")\n",
    "print(f\"Initial loss: {losses[0]:.4f}\")\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"Loss reduction: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%\")"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Checkpoint: Training Loss Curve"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, color='#2196F3', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('SFT Training Loss', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together\n",
    "\n",
    "Now let us test our fine-tuned model. We will give it a math problem and see if it generates a chain-of-thought before answering."
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_cot(model, tokenizer, question, max_new_tokens=200):\n",
    "    \"\"\"Generate a chain-of-thought response from the model.\"\"\"\n",
    "    prompt = f\"Question: {question}\\n\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return response\n",
    "\n",
    "# Test on training examples\n",
    "print(\"=== Testing on Training Examples ===\\n\")\n",
    "for ex in cot_examples[:2]:\n",
    "    response = generate_with_cot(model, tokenizer, ex[\"prompt\"])\n",
    "    print(f\"Q: {ex['prompt']}\")\n",
    "    print(f\"Model: {response}\")\n",
    "    print(f\"Expected answer: {ex['completion'].split('The answer is')[-1].strip()}\")\n",
    "    print(\"-\" * 60)"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Test on New Problems\n",
    "\n",
    "Test the model on problems it has not seen during training. Does it generalize?"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ TODO ============\n",
    "# Create 3 new math problems and test the model on them.\n",
    "# Observe whether the model produces <think> tags and\n",
    "# whether the reasoning is correct.\n",
    "#\n",
    "# new_questions = [\n",
    "#     \"What is 25% of 200?\",\n",
    "#     ???,\n",
    "#     ???,\n",
    "# ]\n",
    "#\n",
    "# for q in new_questions:\n",
    "#     response = generate_with_cot(model, tokenizer, q)\n",
    "#     print(f\"Q: {q}\")\n",
    "#     print(f\"Model: {response}\\n\")\n",
    "# =============================="
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Results\n",
    "\n",
    "Let us analyze what the model learned."
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the generated outputs\n",
    "print(\"=== Analysis of Model Behavior ===\\n\")\n",
    "\n",
    "test_questions = [\n",
    "    \"What is 20% of 50?\",\n",
    "    \"If you have 10 cookies and eat 3, how many are left?\",\n",
    "    \"What is 6 times 7?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    response = generate_with_cot(model, tokenizer, q)\n",
    "    has_think = \"<think>\" in response and \"</think>\" in response\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"Has <think> tags: {has_think}\")\n",
    "    print(f\"Response: {response[:300]}\")\n",
    "    print(\"-\" * 60)"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Output\n",
    "\n",
    "Our SFT-trained model can now produce chain-of-thought reasoning traces. However, notice the limitations:\n",
    "- The model learns the *format* of reasoning (using `<think>` tags)\n",
    "- But the *quality* of reasoning is limited to mimicking the training examples\n",
    "- On novel problems, the reasoning may be plausible-looking but incorrect\n",
    "\n",
    "This is exactly why we need reinforcement learning (covered in Notebook 2) \u2014 to teach the model which reasoning strategies actually lead to correct answers."
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection and Next Steps\n",
    "\n",
    "### Think About This\n",
    "1. Why does SFT alone teach format but not quality?\n",
    "2. What would happen if we trained on millions of CoT examples instead of 5?\n",
    "3. How is this similar to / different from how humans learn to solve math problems?\n",
    "\n",
    "### What Comes Next\n",
    "In Notebook 2, we will implement GRPO (Group Relative Policy Optimization) from scratch \u2014 the RL algorithm that teaches a model to reason *well*, not just to reason *plausibly*.\n",
    "\n",
    "### Key Takeaway\n",
    "SFT is the foundation of reasoning model training. It teaches the model the structure of step-by-step thinking. But structure without correctness is not enough \u2014 that is where reinforcement learning comes in."
   ],
   "id": "cell_26"
  }
 ]
}
