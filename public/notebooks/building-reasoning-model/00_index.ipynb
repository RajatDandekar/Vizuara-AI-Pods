{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Building a Reasoning Model -- Index"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Reasoning Model from Scratch -- Notebook Index\n",
    "\n",
    "Welcome to the Vizuara notebook series on building reasoning models. This series takes you from zero to a working reasoning model using reinforcement learning with verifiable rewards.\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "| # | Notebook | What You Will Build | Time |\n",
    "|---|----------|-------------------|------|\n",
    "| 1 | **Chain-of-Thought SFT** | Fine-tune GPT-2 to produce `<think>` reasoning traces | ~45 min |\n",
    "| 2 | **GRPO from Scratch** | Build Group Relative Policy Optimization step by step | ~60 min |\n",
    "| 3 | **Training End-to-End** | Combine SFT + GRPO into the full reasoning model pipeline | ~60 min |\n",
    "| 4 | **Emergent Behaviors and Distillation** | Analyze emergent reasoning patterns and distill to smaller models | ~45 min |\n",
    "\n",
    "## Prerequisites\n",
    "- Basic Python and PyTorch\n",
    "- Understanding of language models (what next-token prediction is)\n",
    "- Familiarity with gradient descent and backpropagation\n",
    "\n",
    "## How to Use\n",
    "1. Open each notebook in Google Colab (GPU recommended)\n",
    "2. Run all cells sequentially\n",
    "3. Complete the TODO exercises\n",
    "4. Read the reflection questions before moving to the next notebook\n",
    "\n",
    "## Key Concepts Covered\n",
    "- Chain-of-thought reasoning\n",
    "- Supervised fine-tuning (SFT) on reasoning data\n",
    "- Group Relative Policy Optimization (GRPO)\n",
    "- Clipped surrogate objectives\n",
    "- KL divergence penalty\n",
    "- Verifiable rewards\n",
    "- Rejection sampling and distillation\n",
    "- Emergent reasoning behaviors"
   ],
   "id": "cell_1"
  }
 ]
}