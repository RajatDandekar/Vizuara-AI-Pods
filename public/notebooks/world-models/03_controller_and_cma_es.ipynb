{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Controller + CMA-ES: Deciding with 867 Parameters ‚Äî Vizuara"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Download Narration Audio & Play Introduction\n",
    "import os as _os\n",
    "if not _os.path.exists(\"/content/narration\"):\n",
    "    !pip install -q gdown\n",
    "    import gdown\n",
    "    gdown.download(id=\"17YjRH6IoE878oNGb8X3rv81ByYlgYkJj\", output=\"/content/narration.zip\", quiet=False)\n",
    "    !unzip -q /content/narration.zip -d /content/narration\n",
    "    !rm /content/narration.zip\n",
    "    print(f\"Loaded {len(_os.listdir('/content/narration'))} narration segments\")\n",
    "else:\n",
    "    print(\"Narration audio already loaded.\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(\"/content/narration/00_intro.mp3\"))"
   ],
   "id": "narration_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Controller + CMA-ES: Deciding with 867 Parameters from First Principles\n",
    "\n",
    "*Part 3 of the Vizuara series on World Models*\n",
    "*Estimated time: 45 minutes*"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Why It Matters\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/01_why_it_matters.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_01_why_it_matters"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Does This Matter?\n",
    "\n",
    "We have built the eyes (VAE) and the memory (MDN-RNN) of our World Model agent. Now we need a brain ‚Äî something that takes in what the agent sees and remembers, and decides what to do.\n",
    "\n",
    "Here is the surprise: **the Controller is a single linear layer with only 867 parameters.**\n",
    "\n",
    "That is not a typo. In the original World Models paper, the entire decision-making logic ‚Äî the part that drives a car around a racetrack ‚Äî fits in fewer parameters than a single layer of a typical neural network. The secret is that all the complexity lives in V and M. By the time information reaches the Controller, it has already been compressed and contextualized so well that a simple linear mapping is enough.\n",
    "\n",
    "But here is the second surprise: we do not train this Controller with backpropagation. Instead, we use **CMA-ES** (Covariance Matrix Adaptation Evolution Strategy) ‚Äî a derivative-free optimization method inspired by natural selection. We literally *evolve* a population of controllers by testing them inside the learned dream.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Build a Controller from scratch\n",
    "- Implement CMA-ES (evolutionary optimization) from first principles\n",
    "- Evolve controllers on a simple control task\n",
    "- Watch reward curves climb as controllers get better over generations"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import gymnasium as gym\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Building Intuition\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/02_building_intuition.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_02_building_intuition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Intuition\n",
    "\n",
    "### Why a Linear Controller?\n",
    "\n",
    "Think about a CEO running a company. The CEO does not personally analyze every sales report, every customer email, every financial statement. Instead, they have teams that digest this information and present summarized reports. The CEO then makes decisions based on these already-processed summaries.\n",
    "\n",
    "The Controller is the CEO. The VAE and MDN-RNN are the teams. The latent code $z_t$ summarizes what the agent currently sees, and the LSTM hidden state $h_t$ summarizes everything the agent has experienced. Given these two compressed inputs, the Controller just needs to pick an action ‚Äî and a simple linear mapping is enough.\n",
    "\n",
    "### Why Evolution Instead of Backpropagation?\n",
    "\n",
    "There are two reasons the original paper uses CMA-ES instead of gradient descent:\n",
    "\n",
    "1. **The reward signal is sparse and non-differentiable.** The Controller is optimized for total episode reward, which depends on the entire trajectory. You cannot easily compute gradients through hundreds of time steps of dream rollouts.\n",
    "\n",
    "2. **The Controller has very few parameters.** CMA-ES scales well to problems with up to a few thousand parameters. With only 867 parameters, it is a perfect fit.\n",
    "\n",
    "### ü§î Think About This\n",
    "\n",
    "If you had to choose between (a) a deep neural network with 1 million parameters trained with gradient descent, or (b) a single linear layer with 867 parameters trained with evolution ‚Äî which would you guess performs better for a car racing game?\n",
    "\n",
    "Surprisingly, the answer is (b). The key insight is that all the intelligence is in the representation, not the decision function. A good representation makes the decision trivial."
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Mathematics\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/03_mathematics.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_03_mathematics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Mathematics\n",
    "\n",
    "### The Controller Equation\n",
    "\n",
    "The controller is a single linear layer:\n",
    "\n",
    "$$a_t = \\tanh(W_c \\cdot [z_t ; h_t] + b_c)$$\n",
    "\n",
    "This equation says: concatenate the latent state $z_t$ (32 dims) and the LSTM hidden state $h_t$ (256 dims) into a single 288-dimensional vector. Multiply by a weight matrix $W_c$ and add a bias $b_c$. Apply tanh to squash outputs to $[-1, 1]$.\n",
    "\n",
    "Computationally: for CarRacing with 3 action dimensions (steering, gas, brake):\n",
    "- $W_c$ has shape $(3, 288)$ ‚Üí 864 parameters\n",
    "- $b_c$ has shape $(3,)$ ‚Üí 3 parameters\n",
    "- **Total: 867 parameters**\n",
    "\n",
    "### CMA-ES: Evolution in Parameter Space\n",
    "\n",
    "CMA-ES maintains a multivariate Gaussian distribution over controller parameters:\n",
    "\n",
    "$$\\theta \\sim \\mathcal{N}(m, \\sigma^2 C)$$\n",
    "\n",
    "Where:\n",
    "- $m$ is the **mean** of the distribution (the current \"best guess\" for the optimal parameters)\n",
    "- $\\sigma$ is the **step size** (how far to explore)\n",
    "- $C$ is the **covariance matrix** (the shape of the search distribution)\n",
    "\n",
    "Each generation:\n",
    "1. **Sample** $\\lambda$ candidate solutions from $\\mathcal{N}(m, \\sigma^2 C)$\n",
    "2. **Evaluate** each candidate (run it in the environment, measure total reward)\n",
    "3. **Rank** candidates by reward\n",
    "4. **Update** $m$ toward the best candidates (weighted mean of top performers)\n",
    "5. **Update** $\\sigma$ and $C$ to adapt the search distribution\n",
    "\n",
    "Computationally: think of it as \"natural selection for neural network weights.\" Each candidate is a complete set of Controller parameters. The fittest survive and shape the next generation."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Controller Code\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/04_controller_code.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_04_controller_code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Build It ‚Äî Component by Component\n",
    "\n",
    "### 4.1 The Controller"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear controller: takes concatenated [z_t, h_t] and outputs an action.\n",
    "    This is the simplest possible decision-maker.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, action_dim)\n",
    "\n",
    "    def forward(self, z, h):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z: latent state, shape (latent_dim,) or (batch, latent_dim)\n",
    "            h: hidden state, shape (hidden_dim,) or (batch, hidden_dim)\n",
    "        Returns:\n",
    "            action: shape (action_dim,) or (batch, action_dim), values in [-1, 1]\n",
    "        \"\"\"\n",
    "        x = torch.cat([z, h], dim=-1)\n",
    "        return torch.tanh(self.fc(x))\n",
    "\n",
    "    def get_num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "    def set_params(self, flat_params):\n",
    "        \"\"\"Set all parameters from a flat numpy array.\"\"\"\n",
    "        idx = 0\n",
    "        for p in self.parameters():\n",
    "            n = p.numel()\n",
    "            p.data = torch.tensor(\n",
    "                flat_params[idx:idx+n], dtype=torch.float32\n",
    "            ).reshape(p.shape)\n",
    "            idx += n\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"Get all parameters as a flat numpy array.\"\"\"\n",
    "        return np.concatenate([p.data.cpu().numpy().flatten()\n",
    "                              for p in self.parameters()])\n",
    "\n",
    "# Example: World Models scale (32 + 256 = 288 input, 3 actions)\n",
    "controller = Controller(input_dim=288, action_dim=3)\n",
    "print(f\"Controller parameters: {controller.get_num_params()}\")\n",
    "print(f\"  Weight shape: {controller.fc.weight.shape}\")\n",
    "print(f\"  Bias shape: {controller.fc.bias.shape}\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Controller Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/05_controller_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_05_controller_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize the controller's simplicity\n",
    "fig, ax = plt.subplots(figsize=(14, 3))\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 3)\n",
    "ax.axis('off')\n",
    "\n",
    "# z_t box\n",
    "rect = plt.Rectangle((0.5, 1.0), 2, 1, facecolor='#2196F3', alpha=0.7, edgecolor='black')\n",
    "ax.add_patch(rect)\n",
    "ax.text(1.5, 1.5, 'z_t\\n(32 dim)', ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "# h_t box\n",
    "rect = plt.Rectangle((0.5, 0), 2, 0.8, facecolor='#FF9800', alpha=0.7, edgecolor='black')\n",
    "ax.add_patch(rect)\n",
    "ax.text(1.5, 0.4, 'h_t (256 dim)', ha='center', va='center', fontsize=9, color='white', fontweight='bold')\n",
    "\n",
    "# Concat\n",
    "ax.annotate('', xy=(4.0, 1.2), xytext=(2.7, 1.5),\n",
    "            arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "ax.annotate('', xy=(4.0, 1.0), xytext=(2.7, 0.4),\n",
    "            arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "\n",
    "# Concat box\n",
    "rect = plt.Rectangle((4, 0.5), 2.5, 1.2, facecolor='#9C27B0', alpha=0.7, edgecolor='black')\n",
    "ax.add_patch(rect)\n",
    "ax.text(5.25, 1.1, 'Concatenate\\n(288 dim)', ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "# Arrow to linear\n",
    "ax.annotate('', xy=(7.5, 1.1), xytext=(6.7, 1.1),\n",
    "            arrowprops=dict(arrowstyle='->', lw=2))\n",
    "\n",
    "# Linear box\n",
    "rect = plt.Rectangle((7.5, 0.6), 2.5, 1, facecolor='#4CAF50', alpha=0.7, edgecolor='black')\n",
    "ax.add_patch(rect)\n",
    "ax.text(8.75, 1.1, 'Linear + tanh\\n867 params', ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "# Arrow to action\n",
    "ax.annotate('', xy=(11, 1.1), xytext=(10.2, 1.1),\n",
    "            arrowprops=dict(arrowstyle='->', lw=2))\n",
    "\n",
    "# Action box\n",
    "rect = plt.Rectangle((11, 0.7), 2, 0.8, facecolor='#E91E63', alpha=0.7, edgecolor='black')\n",
    "ax.add_patch(rect)\n",
    "ax.text(12, 1.1, 'Action a_t\\n(3 dim)', ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "plt.title('The Controller: Just One Linear Layer!', fontsize=14, pad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Cmaes Implementation\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/06_cmaes_implementation.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_06_cmaes_implementation"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 CMA-ES from Scratch\n",
    "\n",
    "Now let us implement the evolutionary strategy. We will build a simplified but fully functional CMA-ES."
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCMAES:\n",
    "    \"\"\"\n",
    "    Simplified CMA-ES (Covariance Matrix Adaptation Evolution Strategy).\n",
    "\n",
    "    This is a derivative-free optimizer inspired by natural selection:\n",
    "    1. Sample a population of candidate solutions\n",
    "    2. Evaluate each on the task\n",
    "    3. Update the search distribution toward the best candidates\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_params, population_size=64, sigma_init=0.5, elite_ratio=0.25):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_params: dimensionality of the search space\n",
    "            population_size: number of candidates per generation\n",
    "            sigma_init: initial step size (exploration radius)\n",
    "            elite_ratio: fraction of top performers to keep\n",
    "        \"\"\"\n",
    "        self.num_params = num_params\n",
    "        self.pop_size = population_size\n",
    "        self.sigma = sigma_init\n",
    "        self.elite_size = max(1, int(population_size * elite_ratio))\n",
    "\n",
    "        # The mean of the search distribution (our \"best guess\")\n",
    "        self.mean = np.zeros(num_params)\n",
    "\n",
    "        # Track history\n",
    "        self.best_rewards = []\n",
    "        self.mean_rewards = []\n",
    "\n",
    "    def sample_population(self):\n",
    "        \"\"\"Sample a population of candidate parameter vectors.\"\"\"\n",
    "        noise = np.random.randn(self.pop_size, self.num_params)\n",
    "        population = self.mean + self.sigma * noise\n",
    "        return population\n",
    "\n",
    "    def update(self, population, rewards):\n",
    "        \"\"\"\n",
    "        Update the search distribution based on rewards.\n",
    "\n",
    "        Args:\n",
    "            population: array of shape (pop_size, num_params)\n",
    "            rewards: array of shape (pop_size,) ‚Äî higher is better\n",
    "        \"\"\"\n",
    "        # Rank by reward (descending)\n",
    "        ranked_idx = np.argsort(rewards)[::-1]\n",
    "        elite_idx = ranked_idx[:self.elite_size]\n",
    "\n",
    "        # Update mean toward the elite (weighted by rank)\n",
    "        weights = np.log(self.elite_size + 0.5) - np.log(np.arange(1, self.elite_size + 1))\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        self.mean = np.sum(\n",
    "            weights[:, np.newaxis] * population[elite_idx], axis=0\n",
    "        )\n",
    "\n",
    "        # Adapt sigma based on improvement\n",
    "        self.best_rewards.append(rewards[ranked_idx[0]])\n",
    "        self.mean_rewards.append(np.mean(rewards))\n",
    "\n",
    "    def get_best(self):\n",
    "        \"\"\"Return the current best estimate (the mean).\"\"\"\n",
    "        return self.mean.copy()\n",
    "\n",
    "# Test\n",
    "cmaes = SimpleCMAES(num_params=10, population_size=20)\n",
    "pop = cmaes.sample_population()\n",
    "print(f\"Population shape: {pop.shape}\")\n",
    "print(f\"Each individual is a {pop.shape[1]}-dimensional parameter vector\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo1 Fitness\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/07_todo1_fitness.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_07_todo1_fitness"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 The Fitness Evaluation\n",
    "\n",
    "In the full World Model, we evaluate controllers inside the *dream*. For now, let us use a real environment ‚Äî CartPole ‚Äî to demonstrate the evolution process. CartPole is a classic control task where you balance a pole on a cart.\n",
    "\n",
    "## 5. üîß Your Turn: Implement the Fitness Evaluation\n",
    "\n",
    "The fitness function runs the controller in the environment and measures how well it performs."
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_controller(controller, env_name='CartPole-v1', n_episodes=3, max_steps=500):\n",
    "    \"\"\"\n",
    "    Evaluate a controller on an environment.\n",
    "    Returns the average total reward across episodes.\n",
    "\n",
    "    Args:\n",
    "        controller: Controller module with forward(z, h) -> action\n",
    "        env_name: Gymnasium environment name\n",
    "        n_episodes: Number of episodes to average over\n",
    "        max_steps: Maximum steps per episode\n",
    "\n",
    "    Returns:\n",
    "        Average total reward across episodes\n",
    "    \"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    total_rewards = []\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # For each episode:\n",
    "    #   Step 1: Reset the environment: obs, _ = env.reset()\n",
    "    #   Step 2: Loop for max_steps:\n",
    "    #     a) Convert obs to a tensor\n",
    "    #     b) Use obs as z, and zeros as h (dummy hidden state):\n",
    "    #        z = obs_tensor\n",
    "    #        h = torch.zeros(controller.fc.in_features - len(obs))\n",
    "    #     c) Get action from controller (with torch.no_grad()):\n",
    "    #        action_continuous = controller(z, h)\n",
    "    #     d) CartPole has discrete actions ‚Äî convert:\n",
    "    #        action = 1 if action_continuous[0].item() > 0 else 0\n",
    "    #     e) Step the environment: obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    #     f) Accumulate reward\n",
    "    #     g) Break if terminated or truncated\n",
    "    #   Step 3: Append episode reward to total_rewards\n",
    "    # ==============================\n",
    "\n",
    "    ???  # YOUR CODE HERE\n",
    "\n",
    "    env.close()\n",
    "    return np.mean(total_rewards)"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo1 Followup\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/08_todo1_followup.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_08_todo1_followup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification\n",
    "test_controller = Controller(input_dim=4 + 12, action_dim=1)  # 4 obs + 12 dummy hidden\n",
    "reward = evaluate_controller(test_controller)\n",
    "assert isinstance(reward, (int, float, np.floating)), \"‚ùå Should return a number\"\n",
    "assert reward >= 0, \"‚ùå Reward should be non-negative\"\n",
    "print(f\"‚úÖ evaluate_controller works!\")\n",
    "print(f\"Random controller reward: {reward:.1f}\")\n",
    "print(f\"(CartPole max is 500 ‚Äî random gets around 20-50)\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Todo2 Evolution Loop\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/09_todo2_evolution_loop.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_09_todo2_evolution_loop"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üîß Your Turn: Implement the Evolution Loop\n",
    "\n",
    "Now it is your turn. Put the pieces together ‚Äî sample controllers, evaluate them, update the distribution."
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_controllers(input_dim, action_dim, n_generations=50, pop_size=32):\n",
    "    \"\"\"\n",
    "    Evolve controllers using CMA-ES on CartPole.\n",
    "\n",
    "    Args:\n",
    "        input_dim: input dimension for the controller\n",
    "        action_dim: action dimension\n",
    "        n_generations: number of evolutionary generations\n",
    "        pop_size: population size\n",
    "\n",
    "    Returns:\n",
    "        best_controller: the evolved controller\n",
    "        cmaes: the CMA-ES instance (for plotting history)\n",
    "    \"\"\"\n",
    "    # Create a template controller to know the number of parameters\n",
    "    template = Controller(input_dim, action_dim)\n",
    "    num_params = template.get_num_params()\n",
    "    print(f\"Evolving {num_params} parameters over {n_generations} generations\")\n",
    "    print(f\"Population size: {pop_size}\")\n",
    "\n",
    "    # ============ TODO ============\n",
    "    # Step 1: Initialize CMA-ES with the right num_params and pop_size\n",
    "    #         cmaes = SimpleCMAES(num_params=..., population_size=..., sigma_init=0.5)\n",
    "    #\n",
    "    # Step 2: For each generation:\n",
    "    #   a) Sample a population: pop = cmaes.sample_population()\n",
    "    #   b) Evaluate each individual:\n",
    "    #      - Create a Controller(input_dim, action_dim)\n",
    "    #      - Set its parameters: controller.set_params(pop[i])\n",
    "    #      - Evaluate: reward = evaluate_controller(controller)\n",
    "    #   c) Update CMA-ES: cmaes.update(pop, rewards)\n",
    "    #   d) Print progress every 10 generations\n",
    "    #\n",
    "    # Step 3: After evolution, create the best controller using cmaes.get_best()\n",
    "    # ==============================\n",
    "\n",
    "    cmaes = ???     # YOUR CODE HERE\n",
    "\n",
    "    for gen in range(n_generations):\n",
    "        ???  # YOUR CODE HERE\n",
    "\n",
    "    # Create and return the best controller\n",
    "    best_controller = Controller(input_dim, action_dim)\n",
    "    best_controller.set_params(cmaes.get_best())\n",
    "\n",
    "    return best_controller, cmaes"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Evolution Verification\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/10_evolution_verification.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_10_evolution_verification"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verification: Run the evolution (this takes ~2 minutes)\n",
    "print(\"Starting evolution on CartPole...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_controller, cmaes = evolve_controllers(\n",
    "    input_dim=4 + 12,  # 4 obs dims + 12 dummy hidden dims\n",
    "    action_dim=1,\n",
    "    n_generations=50,\n",
    "    pop_size=32\n",
    ")\n",
    "\n",
    "# Test the evolved controller\n",
    "final_reward = evaluate_controller(best_controller, n_episodes=10)\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"Final evolved controller reward: {final_reward:.1f} / 500\")\n",
    "assert final_reward > 100, f\"‚ùå Controller should achieve > 100 reward, got {final_reward:.1f}\"\n",
    "print(f\"‚úÖ Controller evolved successfully!\")\n",
    "\n",
    "if final_reward > 400:\n",
    "    print(\"üéâ Excellent! Near-optimal controller!\")\n",
    "elif final_reward > 200:\n",
    "    print(\"üëç Good! Try more generations for better results.\")"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Evolution Viz\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/11_evolution_viz.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_11_evolution_viz"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing the Evolution"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Reward curves over generations\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "gens = range(1, len(cmaes.best_rewards) + 1)\n",
    "\n",
    "ax1.plot(gens, cmaes.best_rewards, 'b-', linewidth=2, label='Best in generation')\n",
    "ax1.plot(gens, cmaes.mean_rewards, 'r--', linewidth=2, alpha=0.7, label='Mean of generation')\n",
    "ax1.axhline(y=500, color='green', linestyle=':', alpha=0.5, label='Max possible (500)')\n",
    "ax1.set_xlabel('Generation', fontsize=12)\n",
    "ax1.set_ylabel('Reward', fontsize=12)\n",
    "ax1.set_title('Evolution Progress', fontsize=14)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Improvement rate\n",
    "improvements = [cmaes.best_rewards[i] - cmaes.best_rewards[max(0, i-1)]\n",
    "                for i in range(len(cmaes.best_rewards))]\n",
    "ax2.bar(gens, improvements, color=['green' if x > 0 else 'red' for x in improvements], alpha=0.7)\n",
    "ax2.set_xlabel('Generation', fontsize=12)\n",
    "ax2.set_ylabel('Reward Improvement', fontsize=12)\n",
    "ax2.set_title('Per-Generation Improvement', fontsize=14)\n",
    "ax2.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('CMA-ES Evolution: From Random to Skilled', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Watching Controller Play\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/12_watching_controller_play.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_12_watching_controller_play"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watching the Evolved Controller Play"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize a few episodes\n",
    "def visualize_episode(controller, env_name='CartPole-v1', max_steps=500):\n",
    "    \"\"\"Record an episode and plot the observations over time.\"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    positions = []\n",
    "    angles = []\n",
    "    actions_taken = []\n",
    "    rewards = []\n",
    "\n",
    "    total_reward = 0\n",
    "    for step in range(max_steps):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32)\n",
    "        z = obs_tensor\n",
    "        h = torch.zeros(controller.fc.in_features - len(obs))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_continuous = controller(z, h)\n",
    "        action = 1 if action_continuous[0].item() > 0 else 0\n",
    "\n",
    "        positions.append(obs[0])\n",
    "        angles.append(obs[2])\n",
    "        actions_taken.append(action)\n",
    "\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        rewards.append(total_reward)\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "    return positions, angles, actions_taken, rewards\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Run 4 episodes\n",
    "for i in range(4):\n",
    "    pos, ang, acts, rews = visualize_episode(best_controller)\n",
    "\n",
    "    row, col = i // 2, i % 2\n",
    "    ax = axes[row, col]\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    ax.plot(pos, 'b-', alpha=0.7, label='Cart Position')\n",
    "    ax.plot(ang, 'r-', alpha=0.7, label='Pole Angle')\n",
    "    ax2.step(range(len(acts)), acts, 'g-', alpha=0.3, label='Action')\n",
    "\n",
    "    ax.set_xlabel('Step', fontsize=10)\n",
    "    ax.set_ylabel('Position / Angle', fontsize=10, color='blue')\n",
    "    ax2.set_ylabel('Action', fontsize=10, color='green')\n",
    "    ax.set_title(f'Episode {i+1}: {rews[-1]:.0f} reward', fontsize=12)\n",
    "    ax.legend(loc='upper left', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Evolved Controller Balancing CartPole', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Comparison\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/13_comparison.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_13_comparison"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing Evolution vs Random"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Compare evolved vs random controller performance\n",
    "random_rewards = []\n",
    "evolved_rewards = []\n",
    "\n",
    "for _ in range(20):\n",
    "    # Random controller\n",
    "    rand_ctrl = Controller(input_dim=4 + 12, action_dim=1)\n",
    "    random_rewards.append(evaluate_controller(rand_ctrl, n_episodes=1))\n",
    "\n",
    "    # Evolved controller\n",
    "    evolved_rewards.append(evaluate_controller(best_controller, n_episodes=1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "positions = [1, 2]\n",
    "bp = ax.boxplot([random_rewards, evolved_rewards], positions=positions,\n",
    "                widths=0.5, patch_artist=True)\n",
    "\n",
    "bp['boxes'][0].set_facecolor('#FF6B6B')\n",
    "bp['boxes'][1].set_facecolor('#4CAF50')\n",
    "\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(['Random Controller', 'Evolved Controller'], fontsize=12)\n",
    "ax.set_ylabel('Episode Reward', fontsize=12)\n",
    "ax.set_title('Random vs Evolved Controller (20 episodes each)', fontsize=14)\n",
    "ax.axhline(y=500, color='gold', linestyle='--', alpha=0.5, label='Maximum possible')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Random controller:  {np.mean(random_rewards):.1f} ¬± {np.std(random_rewards):.1f}\")\n",
    "print(f\"Evolved controller: {np.mean(evolved_rewards):.1f} ¬± {np.std(evolved_rewards):.1f}\")"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Final Animation\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/14_final_animation.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_14_final_animation"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. üéØ Final Output: The Full CMA-ES Evolution Animation"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä A comprehensive view: parameter distribution evolving over time\n",
    "# We will re-run a quick evolution and track parameter distributions\n",
    "\n",
    "mini_controller = Controller(input_dim=4 + 12, action_dim=1)\n",
    "num_params = mini_controller.get_num_params()\n",
    "\n",
    "cmaes_viz = SimpleCMAES(num_params=num_params, population_size=40, sigma_init=1.0)\n",
    "param_history = []  # Track population parameters at each generation\n",
    "reward_history = []\n",
    "\n",
    "for gen in range(30):\n",
    "    pop = cmaes_viz.sample_population()\n",
    "    param_history.append(pop.copy())\n",
    "\n",
    "    rewards = np.zeros(len(pop))\n",
    "    for i in range(len(pop)):\n",
    "        ctrl = Controller(input_dim=4 + 12, action_dim=1)\n",
    "        ctrl.set_params(pop[i])\n",
    "        rewards[i] = evaluate_controller(ctrl, n_episodes=1)\n",
    "\n",
    "    reward_history.append(rewards.copy())\n",
    "    cmaes_viz.update(pop, rewards)\n",
    "\n",
    "# Visualize: parameter distributions narrowing over time\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "snapshot_gens = [0, 5, 10, 15, 20, 29]\n",
    "for ax, gen in zip(axes.flatten(), snapshot_gens):\n",
    "    # Plot first 2 parameters of each individual\n",
    "    pop = param_history[gen]\n",
    "    rewards = reward_history[gen]\n",
    "\n",
    "    scatter = ax.scatter(pop[:, 0], pop[:, 1], c=rewards, cmap='RdYlGn',\n",
    "                        s=50, alpha=0.7, edgecolors='black', linewidths=0.5)\n",
    "    ax.set_title(f'Generation {gen+1}\\nBest reward: {rewards.max():.0f}', fontsize=11)\n",
    "    ax.set_xlabel('Parameter 1', fontsize=10)\n",
    "    ax.set_ylabel('Parameter 2', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax, label='Reward')\n",
    "\n",
    "plt.suptitle('üéØ CMA-ES Evolution: Population Converges Toward High-Reward Regions',\n",
    "             fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéâ Watch how the population converges! Early generations explore widely,\")\n",
    "print(\"   later generations cluster around the best parameter values.\")\n",
    "print(\"   This is natural selection for neural network weights!\")"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "narration"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéß Listen: Closing\n",
    "from IPython.display import Audio, display\n",
    "import os as _os\n",
    "_f = \"/content/narration/15_closing.mp3\"\n",
    "if _os.path.exists(_f):\n",
    "    display(Audio(_f))\n",
    "else:\n",
    "    print(\"Run the first cell to download narration audio.\")"
   ],
   "id": "narration_15_closing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Reflection and Next Steps\n",
    "\n",
    "### ü§î Reflection Questions\n",
    "1. Why can a linear controller with 867 parameters outperform deep networks with millions of parameters? What is doing the \"heavy lifting\"?\n",
    "2. What happens to CMA-ES if the number of parameters is 1 million instead of 867? Why does this matter for the World Model design?\n",
    "3. In the original paper, the Controller is evaluated inside the *dream* (the learned world model), not the real environment. What are the advantages and risks of this?\n",
    "\n",
    "### üèÜ Optional Challenges\n",
    "1. **Sigma adaptation**: Implement adaptive step size ‚Äî start with large sigma and decay it as the population converges.\n",
    "2. **Full covariance**: Our CMA-ES uses isotropic (diagonal) covariance. Implement full covariance matrix adaptation for better search.\n",
    "3. **LunarLander**: Try evolving a controller on LunarLander-v2 (8-dim observation, 4 discrete actions). Does it work?\n",
    "\n",
    "### What is Next?\n",
    "\n",
    "We have all three components: V (VAE), M (MDN-RNN), and C (Controller + CMA-ES). In the final notebook, we will wire them all together into a complete World Model pipeline ‚Äî collect data, train V and M, then evolve C inside the learned dream. The agent will learn to drive by practicing in its own imagination!"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "chatbot"
    ],
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üí¨ AI Teaching Assistant ‚Äî Click ‚ñ∂ to start\n",
    "#@markdown This AI chatbot reads your notebook and can answer questions about any concept, code, or exercise.\n",
    "\n",
    "import json as _json\n",
    "import requests as _requests\n",
    "from google.colab import output as _output\n",
    "from IPython.display import display, HTML as _HTML, Markdown as _Markdown\n",
    "\n",
    "# --- Read notebook content for context ---\n",
    "def _get_notebook_context():\n",
    "    try:\n",
    "        from google.colab import _message\n",
    "        nb = _message.blocking_request(\"get_ipynb\", request=\"\", timeout_sec=10)\n",
    "        cells = nb.get(\"ipynb\", {}).get(\"cells\", [])\n",
    "        parts = []\n",
    "        for cell in cells:\n",
    "            src = \"\".join(cell.get(\"source\", []))\n",
    "            tags = cell.get(\"metadata\", {}).get(\"tags\", [])\n",
    "            if \"chatbot\" in tags:\n",
    "                continue\n",
    "            if src.strip():\n",
    "                ct = cell.get(\"cell_type\", \"unknown\")\n",
    "                parts.append(f\"[{ct.upper()}]\\n{src}\")\n",
    "        return \"\\n\\n---\\n\\n\".join(parts)\n",
    "    except Exception:\n",
    "        return \"Notebook content unavailable.\"\n",
    "\n",
    "_NOTEBOOK_CONTEXT = _get_notebook_context()\n",
    "_CHAT_HISTORY = []\n",
    "_API_URL = \"https://course-creator-brown.vercel.app/api/chat\"\n",
    "\n",
    "def _notebook_chat(question):\n",
    "    global _CHAT_HISTORY\n",
    "    try:\n",
    "        resp = _requests.post(_API_URL, json={\n",
    "            'question': question,\n",
    "            'context': _NOTEBOOK_CONTEXT[:100000],\n",
    "            'history': _CHAT_HISTORY[-10:],\n",
    "        }, timeout=60)\n",
    "        data = resp.json()\n",
    "        answer = data.get('answer', 'Sorry, I could not generate a response.')\n",
    "        _CHAT_HISTORY.append({'role': 'user', 'content': question})\n",
    "        _CHAT_HISTORY.append({'role': 'assistant', 'content': answer})\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f'Error connecting to teaching assistant: {str(e)}'\n",
    "\n",
    "_output.register_callback('notebook_chat', _notebook_chat)\n",
    "\n",
    "def ask(question):\n",
    "    \"\"\"Ask the AI teaching assistant a question about this notebook.\"\"\"\n",
    "    answer = _notebook_chat(question)\n",
    "    display(_Markdown(answer))\n",
    "\n",
    "print(\"\\u2705 AI Teaching Assistant is ready!\")\n",
    "print(\"\\U0001f4a1 Use the chat below, or call ask(\\'your question\\') in any cell.\")\n",
    "\n",
    "# --- Display chat widget ---\n",
    "display(_HTML('''<style>\n  .vc-wrap{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;max-width:100%;border-radius:16px;overflow:hidden;box-shadow:0 4px 24px rgba(0,0,0,.12);background:#fff;border:1px solid #e5e7eb}\n  .vc-hdr{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:16px 20px;display:flex;align-items:center;gap:12px}\n  .vc-avatar{width:42px;height:42px;background:rgba(255,255,255,.2);border-radius:50%;display:flex;align-items:center;justify-content:center;font-size:22px}\n  .vc-hdr h3{font-size:16px;font-weight:600;margin:0}\n  .vc-hdr p{font-size:12px;opacity:.85;margin:2px 0 0}\n  .vc-msgs{height:420px;overflow-y:auto;padding:16px;background:#f8f9fb;display:flex;flex-direction:column;gap:10px}\n  .vc-msg{display:flex;flex-direction:column;animation:vc-fade .25s ease}\n  .vc-msg.user{align-items:flex-end}\n  .vc-msg.bot{align-items:flex-start}\n  .vc-bbl{max-width:85%;padding:10px 14px;border-radius:16px;font-size:14px;line-height:1.55;word-wrap:break-word}\n  .vc-msg.user .vc-bbl{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border-bottom-right-radius:4px}\n  .vc-msg.bot .vc-bbl{background:#fff;color:#1a1a2e;border:1px solid #e8e8e8;border-bottom-left-radius:4px}\n  .vc-bbl code{background:rgba(0,0,0,.07);padding:2px 6px;border-radius:4px;font-size:13px;font-family:'Fira Code',monospace}\n  .vc-bbl pre{background:#1e1e2e;color:#cdd6f4;padding:12px;border-radius:8px;overflow-x:auto;margin:8px 0;font-size:13px}\n  .vc-bbl pre code{background:none;padding:0;color:inherit}\n  .vc-bbl h3,.vc-bbl h4{margin:10px 0 4px;font-size:15px}\n  .vc-bbl ul,.vc-bbl ol{margin:4px 0;padding-left:20px}\n  .vc-bbl li{margin:2px 0}\n  .vc-chips{display:flex;flex-wrap:wrap;gap:8px;padding:0 16px 12px;background:#f8f9fb}\n  .vc-chip{background:#fff;border:1px solid #d1d5db;border-radius:20px;padding:6px 14px;font-size:12px;cursor:pointer;transition:all .15s;color:#4b5563}\n  .vc-chip:hover{border-color:#667eea;color:#667eea;background:#f0f0ff}\n  .vc-input{display:flex;padding:12px 16px;background:#fff;border-top:1px solid #eee;gap:8px}\n  .vc-input input{flex:1;padding:10px 16px;border:2px solid #e8e8e8;border-radius:24px;font-size:14px;outline:none;transition:border-color .2s}\n  .vc-input input:focus{border-color:#667eea}\n  .vc-input button{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border:none;border-radius:50%;width:42px;height:42px;cursor:pointer;display:flex;align-items:center;justify-content:center;font-size:18px;transition:transform .1s}\n  .vc-input button:hover{transform:scale(1.05)}\n  .vc-input button:disabled{opacity:.5;cursor:not-allowed;transform:none}\n  .vc-typing{display:flex;gap:5px;padding:4px 0}\n  .vc-typing span{width:8px;height:8px;background:#667eea;border-radius:50%;animation:vc-bounce 1.4s infinite ease-in-out}\n  .vc-typing span:nth-child(2){animation-delay:.2s}\n  .vc-typing span:nth-child(3){animation-delay:.4s}\n  @keyframes vc-bounce{0%,80%,100%{transform:scale(0)}40%{transform:scale(1)}}\n  @keyframes vc-fade{from{opacity:0;transform:translateY(8px)}to{opacity:1;transform:translateY(0)}}\n  .vc-note{text-align:center;font-size:11px;color:#9ca3af;padding:8px 16px 12px;background:#fff}\n</style>\n<div class=\"vc-wrap\">\n  <div class=\"vc-hdr\">\n    <div class=\"vc-avatar\">&#129302;</div>\n    <div>\n      <h3>Vizuara Teaching Assistant</h3>\n      <p>Ask me anything about this notebook</p>\n    </div>\n  </div>\n  <div class=\"vc-msgs\" id=\"vcMsgs\">\n    <div class=\"vc-msg bot\">\n      <div class=\"vc-bbl\">&#128075; Hi! I've read through this entire notebook. Ask me about any concept, code block, or exercise &mdash; I'm here to help you learn!</div>\n    </div>\n  </div>\n  <div class=\"vc-chips\" id=\"vcChips\">\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Explain the main concept</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Help with the TODO exercise</span>\n    <span class=\"vc-chip\" onclick=\"vcAsk(this.textContent)\">Summarize what I learned</span>\n  </div>\n  <div class=\"vc-input\">\n    <input type=\"text\" id=\"vcIn\" placeholder=\"Ask about concepts, code, exercises...\" />\n    <button id=\"vcSend\" onclick=\"vcSendMsg()\">&#10148;</button>\n  </div>\n  <div class=\"vc-note\">AI-generated &middot; Verify important information &middot; <a href=\"#\" onclick=\"vcClear();return false\" style=\"color:#667eea\">Clear chat</a></div>\n</div>\n<script>\n(function(){\n  var msgs=document.getElementById('vcMsgs'),inp=document.getElementById('vcIn'),\n      btn=document.getElementById('vcSend'),chips=document.getElementById('vcChips');\n\n  function esc(s){var d=document.createElement('div');d.textContent=s;return d.innerHTML}\n\n  function md(t){\n    return t\n      .replace(/```(\\w*)\\n([\\s\\S]*?)```/g,function(_,l,c){return '<pre><code>'+esc(c)+'</code></pre>'})\n      .replace(/`([^`]+)`/g,'<code>$1</code>')\n      .replace(/\\*\\*([^*]+)\\*\\*/g,'<strong>$1</strong>')\n      .replace(/\\*([^*]+)\\*/g,'<em>$1</em>')\n      .replace(/^#### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^### (.+)$/gm,'<h4>$1</h4>')\n      .replace(/^## (.+)$/gm,'<h3>$1</h3>')\n      .replace(/^\\d+\\. (.+)$/gm,'<li>$1</li>')\n      .replace(/^- (.+)$/gm,'<li>$1</li>')\n      .replace(/\\n\\n/g,'<br><br>')\n      .replace(/\\n/g,'<br>');\n  }\n\n  function addMsg(text,isUser){\n    var m=document.createElement('div');m.className='vc-msg '+(isUser?'user':'bot');\n    var b=document.createElement('div');b.className='vc-bbl';\n    b.innerHTML=isUser?esc(text):md(text);\n    m.appendChild(b);msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function showTyping(){\n    var m=document.createElement('div');m.className='vc-msg bot';m.id='vcTyping';\n    m.innerHTML='<div class=\"vc-bbl\"><div class=\"vc-typing\"><span></span><span></span><span></span></div></div>';\n    msgs.appendChild(m);msgs.scrollTop=msgs.scrollHeight;\n  }\n\n  function hideTyping(){var e=document.getElementById('vcTyping');if(e)e.remove()}\n\n  window.vcSendMsg=function(){\n    var q=inp.value.trim();if(!q)return;\n    inp.value='';chips.style.display='none';\n    addMsg(q,true);showTyping();btn.disabled=true;\n    google.colab.kernel.invokeFunction('notebook_chat',[q],{})\n      .then(function(r){\n        hideTyping();\n        var a=r.data['application/json'];\n        addMsg(typeof a==='string'?a:JSON.stringify(a),false);\n      })\n      .catch(function(){\n        hideTyping();\n        addMsg('Sorry, I encountered an error. Please check your internet connection and try again.',false);\n      })\n      .finally(function(){btn.disabled=false;inp.focus()});\n  };\n\n  window.vcAsk=function(q){inp.value=q;vcSendMsg()};\n  window.vcClear=function(){\n    msgs.innerHTML='<div class=\"vc-msg bot\"><div class=\"vc-bbl\">&#128075; Chat cleared. Ask me anything!</div></div>';\n    chips.style.display='flex';\n  };\n\n  inp.addEventListener('keypress',function(e){if(e.key==='Enter')vcSendMsg()});\n  inp.focus();\n})();\n</script>'''))"
   ],
   "id": "vizuara_chatbot"
  }
 ]
}