{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Wafer Defect Detection with VAEs \u2014 Implementation Notebook"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\u2705 GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "print(f\"\\n\ud83d\udce6 Python {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udd25 PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\ud83c\udfb2 Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Wafer Defect Detection with Variational Autoencoders\n",
    "## Implementation Notebook\n",
    "\n",
    "Welcome to the implementation notebook for the NovaSilicon wafer defect detection case study. In this notebook, you will build a Convolutional Variational Autoencoder (VAE) for unsupervised anomaly detection in semiconductor wafer inspection.\n",
    "\n",
    "**Business Context:** NovaSilicon, a semiconductor manufacturer producing safety-critical automotive chips, faces a $109M annual cost from inspection inadequacies. Their current rule-based inspection system suffers from throughput bottlenecks, inconsistent human inspectors (78% agreement rate), and an 11-day lag in detecting novel defect types. The VAE approach learns what \"normal\" wafers look like, then flags anything that deviates -- enabling detection of previously unseen defect types without labeled defect data.\n",
    "\n",
    "**What you will build:**\n",
    "- A data pipeline for anomaly detection using FashionMNIST as a proxy dataset\n",
    "- Exploratory data analysis to understand normal vs. anomalous patterns\n",
    "- A PCA baseline for anomaly detection (linear autoencoder)\n",
    "- A Convolutional VAE from scratch with encoder, decoder, and reparameterization\n",
    "- A training pipeline with KL annealing and cosine learning rate scheduling\n",
    "- A full evaluation pipeline with AUROC, AUPRC, and ROC curves\n",
    "- Error analysis with reconstruction heatmaps\n",
    "- Deployment benchmarking with TorchScript export\n",
    "\n",
    "**Prerequisites:** Familiarity with PyTorch, convolutional neural networks, and the VAE mathematical framework. Read Sections 1-2 of the accompanying case study document before starting.\n",
    "\n",
    "**Runtime:** This notebook is designed to run on Google Colab with a T4 GPU. Total runtime is approximately 15-20 minutes.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Data Acquisition Strategy\n",
    "\n",
    "We use FashionMNIST as a proxy dataset for wafer anomaly detection. Class 0 (T-shirt/Top) serves as the \"normal\" class representing defect-free wafer images, while all other classes serve as \"anomalies\" representing defective wafers with various defect types.\n",
    "\n",
    "This proxy is valid because anomaly detection methods are data-agnostic: we train exclusively on the normal class and evaluate the model's ability to distinguish normal from anomalous at test time. The principles transfer directly to real wafer imagery.\n",
    "\n",
    "**Mapping to the NovaSilicon scenario:**\n",
    "- T-shirt/Top (class 0) = defect-free wafer images\n",
    "- All other classes = various defect types (scratches, particles, pattern shifts, etc.)\n",
    "- Training set: normal images only (matching NovaSilicon's abundant normal data)\n",
    "- Test set: mix of normal and anomalous (matching production inspection)"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision matplotlib scikit-learn tqdm"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 128  # 128x128 for fast training on Colab\n",
    "NORMAL_CLASS = 0  # FashionMNIST class 0 (T-shirt/Top) = \"normal\" wafer\n",
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 64  # Latent space dimensionality\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "KL_ANNEAL_EPOCHS = 10  # Linearly anneal beta from 0 to 1 over this many epochs\n",
    "\n",
    "# FashionMNIST class names (for reference)\n",
    "FASHION_CLASSES = [\n",
    "    'T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "print(f\"Normal class: {FASHION_CLASSES[NORMAL_CLASS]} (proxy for defect-free wafer)\")\n",
    "print(f\"Anomaly classes: {[c for i, c in enumerate(FASHION_CLASSES) if i != NORMAL_CLASS]}\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the dataset\n",
    "# Base transform: resize to 128x128, convert to tensor, normalize to [0, 1]\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),  # Converts to [0, 1] range\n",
    "])\n",
    "\n",
    "# Download FashionMNIST\n",
    "train_full = datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=base_transform\n",
    ")\n",
    "test_full = datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=base_transform\n",
    ")\n",
    "\n",
    "print(f\"Full training set: {len(train_full)} images\")\n",
    "print(f\"Full test set: {len(test_full)} images\")"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into normal (training) and anomaly (testing)\n",
    "# Training: ONLY normal images (class 0)\n",
    "train_normal_indices = [i for i, (_, label) in enumerate(train_full) if label == NORMAL_CLASS]\n",
    "\n",
    "# Test set: balanced mix of normal and anomalous\n",
    "test_normal_indices = [i for i, (_, label) in enumerate(test_full) if label == NORMAL_CLASS]\n",
    "test_anomaly_indices = [i for i, (_, label) in enumerate(test_full) if label != NORMAL_CLASS]\n",
    "\n",
    "# Subsample anomalies to create a realistic imbalance (more normal than anomalous in test)\n",
    "np.random.seed(42)\n",
    "test_anomaly_subset = np.random.choice(test_anomaly_indices, size=400, replace=False).tolist()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Subset(train_full, train_normal_indices)\n",
    "\n",
    "# Split training into train/val (80/20)\n",
    "n_train = int(0.8 * len(train_dataset))\n",
    "n_val = len(train_dataset) - n_train\n",
    "train_split, val_split = torch.utils.data.random_split(\n",
    "    train_dataset, [n_train, n_val],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Test dataset with labels: 0 = normal, 1 = anomaly\n",
    "test_indices = test_normal_indices + test_anomaly_subset\n",
    "test_labels = [0] * len(test_normal_indices) + [1] * len(test_anomaly_subset)\n",
    "test_dataset = Subset(test_full, test_indices)\n",
    "\n",
    "print(f\"Training set (normal only): {len(train_split)} images\")\n",
    "print(f\"Validation set (normal only): {len(val_split)} images\")\n",
    "print(f\"Test set: {len(test_normal_indices)} normal + {len(test_anomaly_subset)} anomaly = {len(test_indices)} total\")"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_split, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_split, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=2, pin_memory=True)\n",
    "\n",
    "# Verify shapes\n",
    "sample_batch, _ = next(iter(train_loader))\n",
    "print(f\"Batch shape: {sample_batch.shape}\")\n",
    "print(f\"Pixel range: [{sample_batch.min():.3f}, {sample_batch.max():.3f}]\")\n",
    "print(f\"Training batches per epoch: {len(train_loader)}\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data Augmentation Pipeline\n",
    "\n",
    "In a real wafer inspection system, certain augmentations are physically meaningful while others are not. Horizontal and vertical flips are valid because wafer images have no canonical orientation on the inspection microscope. Small rotations are valid for the same reason. Gaussian noise simulates sensor noise variations across inspection stations. However, color jitter is NOT appropriate because intensity variations in grayscale wafer images carry physical meaning (e.g., film thickness variations)."
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_transform(img_size=128):\n",
    "    \"\"\"\n",
    "    Create an augmented transform pipeline for training wafer images.\n",
    "\n",
    "    Implement the following augmentation pipeline:\n",
    "    1. Resize to img_size x img_size\n",
    "    2. RandomHorizontalFlip with p=0.5\n",
    "    3. RandomVerticalFlip with p=0.5\n",
    "    4. RandomRotation up to 15 degrees\n",
    "    5. Add Gaussian noise (implement as a custom transform)\n",
    "    6. ToTensor (converts to [0, 1])\n",
    "\n",
    "    Hints:\n",
    "    - For Gaussian noise, create a class that adds N(0, sigma) noise\n",
    "      and clamps the result to [0, 1]. Use sigma=0.02.\n",
    "    - Do NOT use ColorJitter -- intensity in grayscale wafer images\n",
    "      carries physical meaning (film thickness).\n",
    "    - RandomRotation with fill=0 for black borders (or use expand=False).\n",
    "\n",
    "    Args:\n",
    "        img_size: Target image size (default 128)\n",
    "\n",
    "    Returns:\n",
    "        augmented_transform: transforms.Compose pipeline\n",
    "    \"\"\"\n",
    "    # TODO: Implement the GaussianNoise custom transform class\n",
    "    # class GaussianNoise:\n",
    "    #     def __init__(self, sigma=0.02):\n",
    "    #         ...\n",
    "    #     def __call__(self, tensor):\n",
    "    #         ...  # Add noise and clamp to [0, 1]\n",
    "\n",
    "    # TODO: Compose the augmentation pipeline\n",
    "    augmented_transform = None  # Your code here\n",
    "\n",
    "    return augmented_transform\n",
    "\n",
    "# Verification\n",
    "aug_transform = create_augmented_transform()\n",
    "assert aug_transform is not None, \"Augmented transform not implemented\"\n",
    "print(\"Augmented transform created successfully.\")"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for reflection:** Why is it important NOT to use augmented data for the validation and test sets? How would augmentation during evaluation affect our anomaly detection metrics?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Exploratory Data Analysis\n",
    "\n",
    "Before building any model, we must understand the data distributions. This is especially important for anomaly detection: we need to confirm that the normal class has consistent visual patterns and that anomalies are visually distinct."
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a grid of normal training images\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "fig.suptitle('Normal Training Images (Defect-Free Wafer Proxy)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, _ = train_split[i]\n",
    "    ax.imshow(img.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomalous test images (various \"defect types\")\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "fig.suptitle('Anomalous Test Images (Defective Wafer Proxy)', fontsize=14, fontweight='bold')\n",
    "\n",
    "anomaly_only_indices = [i for i, lbl in enumerate(test_labels) if lbl == 1]\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = anomaly_only_indices[i]\n",
    "    img, original_label = test_dataset[idx]\n",
    "    ax.imshow(img.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(FASHION_CLASSES[original_label], fontsize=7)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel intensity distributions: normal vs anomalous\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Collect pixel values from normal images\n",
    "normal_pixels = []\n",
    "for i in range(min(200, len(train_split))):\n",
    "    img, _ = train_split[i]\n",
    "    normal_pixels.append(img.numpy().flatten())\n",
    "normal_pixels = np.concatenate(normal_pixels)\n",
    "\n",
    "# Collect pixel values from anomalous images\n",
    "anomaly_pixels = []\n",
    "for i in anomaly_only_indices[:200]:\n",
    "    img, _ = test_dataset[i]\n",
    "    anomaly_pixels.append(img.numpy().flatten())\n",
    "anomaly_pixels = np.concatenate(anomaly_pixels)\n",
    "\n",
    "axes[0].hist(normal_pixels, bins=50, alpha=0.7, color='steelblue', density=True, label='Normal')\n",
    "axes[0].hist(anomaly_pixels, bins=50, alpha=0.7, color='crimson', density=True, label='Anomaly')\n",
    "axes[0].set_xlabel('Pixel Intensity')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Pixel Intensity Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Mean and std images\n",
    "all_normal_imgs = torch.stack([train_split[i][0] for i in range(min(500, len(train_split)))])\n",
    "mean_img = all_normal_imgs.mean(dim=0).squeeze()\n",
    "std_img = all_normal_imgs.std(dim=0).squeeze()\n",
    "\n",
    "axes[1].imshow(mean_img, cmap='gray')\n",
    "axes[1].set_title('Mean Normal Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Standard deviation image (shows which regions vary most)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "im = ax.imshow(std_img, cmap='hot')\n",
    "ax.set_title('Pixel Standard Deviation (Normal Images)')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Normal pixel mean: {normal_pixels.mean():.4f}, std: {normal_pixels.std():.4f}\")\n",
    "print(f\"Anomaly pixel mean: {anomaly_pixels.mean():.4f}, std: {anomaly_pixels.std():.4f}\")"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: EDA Analysis Questions"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eda_questions():\n",
    "    \"\"\"\n",
    "    Answer the following questions based on your EDA above.\n",
    "    Replace each None with a string containing your answer (2-3 sentences each).\n",
    "\n",
    "    Questions:\n",
    "    1. What is the dominant visual pattern in the normal images?\n",
    "       Consider: texture, shape, intensity distribution.\n",
    "\n",
    "    2. How do the anomalous images differ visually from normal ones?\n",
    "       Consider: structural differences, intensity patterns, shape variations.\n",
    "\n",
    "    3. Are the differences localized (small regions) or global (entire image)?\n",
    "       Consider: where in the image the differences are most apparent.\n",
    "\n",
    "    4. Based on the pixel distributions alone, could simple thresholding on\n",
    "       mean pixel intensity detect anomalies? Why or why not?\n",
    "       Consider: overlap between normal and anomaly distributions.\n",
    "\n",
    "    Return your answers as a dictionary.\n",
    "    \"\"\"\n",
    "    answers = {\n",
    "        \"q1_dominant_pattern\": None,  # Your answer here\n",
    "        \"q2_anomaly_differences\": None,  # Your answer here\n",
    "        \"q3_localized_or_global\": None,  # Your answer here\n",
    "        \"q4_simple_thresholding\": None,  # Your answer here\n",
    "    }\n",
    "    return answers\n",
    "\n",
    "# Verification\n",
    "eda_answers = answer_eda_questions()\n",
    "for key, value in eda_answers.items():\n",
    "    assert value is not None, f\"Please answer {key}\"\n",
    "    assert len(value) > 30, f\"Answer for {key} is too short. Provide 2-3 sentences.\"\n",
    "print(\"All EDA questions answered.\")\n",
    "for key, value in eda_answers.items():\n",
    "    print(f\"\\n{key}:\\n  {value}\")"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 PCA Baseline\n",
    "\n",
    "Before building the VAE, we establish a performance floor with PCA. PCA can be viewed as a linear autoencoder: it projects data into a low-dimensional subspace and reconstructs it. The reconstruction error serves as an anomaly score because PCA captures the dominant modes of variation in normal images, and anomalies deviate from these modes.\n",
    "\n",
    "This is the approach NovaSilicon's current rule-based system implicitly approximates with hand-crafted features. Beating PCA with the VAE demonstrates the value of nonlinear feature learning."
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten training images for PCA\n",
    "print(\"Preparing data for PCA...\")\n",
    "train_flat = []\n",
    "for i in range(len(train_split)):\n",
    "    img, _ = train_split[i]\n",
    "    train_flat.append(img.numpy().flatten())\n",
    "train_flat = np.array(train_flat)\n",
    "\n",
    "# Flatten test images\n",
    "test_flat = []\n",
    "for i in range(len(test_dataset)):\n",
    "    img, _ = test_dataset[i]\n",
    "    test_flat.append(img.numpy().flatten())\n",
    "test_flat = np.array(test_flat)\n",
    "\n",
    "test_labels_arr = np.array(test_labels)\n",
    "\n",
    "print(f\"Training matrix: {train_flat.shape}\")\n",
    "print(f\"Test matrix: {test_flat.shape}\")\n",
    "print(f\"Feature dimension: {train_flat.shape[1]} (= {IMG_SIZE}x{IMG_SIZE})\")"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: PCA Anomaly Detection Baseline"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_anomaly_detection(train_data, test_data, test_labels, k_values=[10, 50, 100, 200]):\n",
    "    \"\"\"\n",
    "    Implement PCA-based anomaly detection for multiple values of k (number of components).\n",
    "\n",
    "    For each k in k_values:\n",
    "    1. Fit PCA with k components on train_data (normal images only)\n",
    "    2. Transform test_data into the k-dimensional PCA space\n",
    "    3. Reconstruct the test_data by inverse-transforming back to the original space\n",
    "    4. Compute per-image MSE between original and reconstructed test images\n",
    "    5. Use the MSE as the anomaly score\n",
    "    6. Compute AUROC using sklearn.metrics.roc_auc_score(test_labels, anomaly_scores)\n",
    "\n",
    "    Hints:\n",
    "    - Use sklearn.decomposition.PCA(n_components=k)\n",
    "    - pca.fit(train_data) to fit on normal data only\n",
    "    - pca.transform(test_data) to project test data\n",
    "    - pca.inverse_transform(projected) to reconstruct\n",
    "    - MSE = np.mean((original - reconstructed) ** 2, axis=1) gives per-image scores\n",
    "\n",
    "    Args:\n",
    "        train_data: np.array of shape (n_train, d) -- flattened normal images\n",
    "        test_data: np.array of shape (n_test, d) -- flattened test images\n",
    "        test_labels: np.array of shape (n_test,) -- 0 for normal, 1 for anomaly\n",
    "        k_values: list of integers -- number of PCA components to try\n",
    "\n",
    "    Returns:\n",
    "        results: dict mapping k -> {'auroc': float, 'scores': np.array, 'pca': fitted PCA object}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        # TODO: Step 1 - Fit PCA with k components on train_data\n",
    "\n",
    "        # TODO: Step 2 - Transform and reconstruct test_data\n",
    "\n",
    "        # TODO: Step 3 - Compute per-image MSE as anomaly score\n",
    "\n",
    "        # TODO: Step 4 - Compute AUROC\n",
    "\n",
    "        # results[k] = {'auroc': auroc, 'scores': scores, 'pca': pca}\n",
    "        pass\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run PCA baseline\n",
    "pca_results = pca_anomaly_detection(train_flat, test_flat, test_labels_arr)\n",
    "\n",
    "# Print results\n",
    "print(\"PCA Baseline Results:\")\n",
    "print(\"-\" * 40)\n",
    "for k, res in sorted(pca_results.items()):\n",
    "    print(f\"  k={k:4d} components: AUROC = {res['auroc']:.4f}\")"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: PCA results should exist and AUROC should be reasonable\n",
    "assert len(pca_results) > 0, \"PCA results dictionary is empty -- implement pca_anomaly_detection()\"\n",
    "for k, res in pca_results.items():\n",
    "    assert 'auroc' in res, f\"Missing 'auroc' key for k={k}\"\n",
    "    assert 0.5 <= res['auroc'] <= 1.0, f\"AUROC for k={k} is {res['auroc']:.4f} -- should be between 0.5 and 1.0\"\n",
    "    assert 'scores' in res, f\"Missing 'scores' key for k={k}\"\n",
    "print(\"PCA baseline verification passed.\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all PCA configurations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800', '#F44336']\n",
    "for i, (k, res) in enumerate(sorted(pca_results.items())):\n",
    "    fpr, tpr, _ = roc_curve(test_labels_arr, res['scores'])\n",
    "    axes[0].plot(fpr, tpr, color=colors[i % len(colors)],\n",
    "                 label=f'k={k} (AUROC={res[\"auroc\"]:.3f})', linewidth=2)\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('PCA Baseline: ROC Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar chart of AUROC vs k\n",
    "k_vals = sorted(pca_results.keys())\n",
    "aurocs = [pca_results[k]['auroc'] for k in k_vals]\n",
    "axes[1].bar([str(k) for k in k_vals], aurocs, color='steelblue', alpha=0.8)\n",
    "axes[1].set_xlabel('Number of PCA Components (k)')\n",
    "axes[1].set_ylabel('AUROC')\n",
    "axes[1].set_title('PCA Baseline: AUROC vs Components')\n",
    "axes[1].set_ylim(0.5, 1.0)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, (k, a) in enumerate(zip(k_vals, aurocs)):\n",
    "    axes[1].text(i, a + 0.01, f'{a:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Store best PCA result for later comparison\n",
    "best_k = max(pca_results, key=lambda k: pca_results[k]['auroc'])\n",
    "pca_best_auroc = pca_results[best_k]['auroc']\n",
    "print(f\"\\nBest PCA baseline: k={best_k}, AUROC={pca_best_auroc:.4f}\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.4 Convolutional VAE Model\n",
    "\n",
    "Now we build the core model: a Convolutional VAE. The architecture uses strided convolutions for downsampling in the encoder and transposed convolutions for upsampling in the decoder.\n",
    "\n",
    "**Key design decisions for anomaly detection:**\n",
    "- LeakyReLU prevents dead neurons, ensuring the encoder produces gradients for all input patterns (including anomalous ones at test time).\n",
    "- BatchNorm stabilizes training with higher learning rates.\n",
    "- Sigmoid output ensures pixel values are in [0, 1], matching our input normalization.\n",
    "- The latent dimension (64) balances reconstruction quality against latent space regularity.\n",
    "\n",
    "### Encoder Architecture\n",
    "\n",
    "The encoder compresses a 128x128 grayscale image down to a latent vector through four convolutional blocks. Each block halves the spatial dimensions via stride-2 convolution.\n",
    "\n",
    "| Layer | Output Shape | Description |\n",
    "|-------|-------------|-------------|\n",
    "| Input | (1, 128, 128) | Grayscale image |\n",
    "| Conv Block 1 | (32, 64, 64) | Conv2d(1, 32, 4, stride=2, padding=1) + BN + LeakyReLU |\n",
    "| Conv Block 2 | (64, 32, 32) | Conv2d(32, 64, 4, stride=2, padding=1) + BN + LeakyReLU |\n",
    "| Conv Block 3 | (128, 16, 16) | Conv2d(64, 128, 4, stride=2, padding=1) + BN + LeakyReLU |\n",
    "| Conv Block 4 | (256, 8, 8) | Conv2d(128, 256, 4, stride=2, padding=1) + BN + LeakyReLU |\n",
    "| Flatten | (16384,) | 256 * 8 * 8 |\n",
    "| Linear (mu) | (64,) | Mean of latent distribution |\n",
    "| Linear (logvar) | (64,) | Log-variance of latent distribution |\n",
    "\n",
    "### TODO: Implement the Encoder"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional encoder for the VAE.\n",
    "\n",
    "    Takes a (1, 128, 128) grayscale image and produces mu and logvar\n",
    "    vectors of dimension latent_dim.\n",
    "\n",
    "    Architecture:\n",
    "    - 4 convolutional blocks: Conv2d -> BatchNorm2d -> LeakyReLU(0.2)\n",
    "    - Each conv uses kernel_size=4, stride=2, padding=1 (halves spatial dims)\n",
    "    - Channel progression: 1 -> 32 -> 64 -> 128 -> 256\n",
    "    - Flatten the output of the last conv block\n",
    "    - Two separate Linear layers: one for mu, one for logvar\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Convolutional layers (these are provided)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Flattened dimension: 256 * 8 * 8 = 16384\n",
    "        self.flat_dim = 256 * 8 * 8\n",
    "\n",
    "        # Linear heads for mu and logvar\n",
    "        self.fc_mu = nn.Linear(self.flat_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.flat_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the encoder.\n",
    "\n",
    "        TODO: Implement this method.\n",
    "\n",
    "        Steps:\n",
    "        1. Pass x through conv1 -> bn1 -> LeakyReLU(0.2)\n",
    "        2. Pass through conv2 -> bn2 -> LeakyReLU(0.2)\n",
    "        3. Pass through conv3 -> bn3 -> LeakyReLU(0.2)\n",
    "        4. Pass through conv4 -> bn4 -> LeakyReLU(0.2)\n",
    "        5. Flatten the output (use x.view(x.size(0), -1))\n",
    "        6. Compute mu = self.fc_mu(flattened)\n",
    "        7. Compute logvar = self.fc_logvar(flattened)\n",
    "        8. Return (mu, logvar)\n",
    "\n",
    "        Hints:\n",
    "        - Use F.leaky_relu(x, 0.2) for the activation\n",
    "        - The batch dimension (dim 0) must be preserved throughout\n",
    "        - After step 4, the shape should be (batch, 256, 8, 8)\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, 1, 128, 128)\n",
    "\n",
    "        Returns:\n",
    "            mu: Mean tensor of shape (batch, latent_dim)\n",
    "            logvar: Log-variance tensor of shape (batch, latent_dim)\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass\n",
    "        raise NotImplementedError(\"Implement ConvEncoder.forward()\")"
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: test encoder output shapes\n",
    "encoder = ConvEncoder(latent_dim=LATENT_DIM).to(device)\n",
    "test_input = torch.randn(2, 1, IMG_SIZE, IMG_SIZE).to(device)\n",
    "try:\n",
    "    mu, logvar = encoder(test_input)\n",
    "    assert mu.shape == (2, LATENT_DIM), f\"mu shape is {mu.shape}, expected (2, {LATENT_DIM})\"\n",
    "    assert logvar.shape == (2, LATENT_DIM), f\"logvar shape is {logvar.shape}, expected (2, {LATENT_DIM})\"\n",
    "    print(f\"Encoder output shapes: mu={mu.shape}, logvar={logvar.shape}\")\n",
    "    print(\"Encoder verification PASSED.\")\n",
    "except NotImplementedError:\n",
    "    print(\"Encoder forward() not yet implemented. Complete the TODO above.\")"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Architecture\n",
    "\n",
    "The decoder mirrors the encoder, using transposed convolutions to upsample from the latent vector back to a full-resolution image. The final sigmoid activation ensures output pixels are in [0, 1]."
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional decoder for the VAE.\n",
    "\n",
    "    Takes a latent vector of dimension latent_dim and produces\n",
    "    a reconstructed image of shape (1, 128, 128).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.flat_dim = 256 * 8 * 8\n",
    "\n",
    "        # Project from latent space to spatial feature map\n",
    "        self.fc = nn.Linear(latent_dim, self.flat_dim)\n",
    "\n",
    "        # Transposed convolutions (mirror of encoder)\n",
    "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the decoder.\n",
    "\n",
    "        Args:\n",
    "            z: Latent vector of shape (batch, latent_dim)\n",
    "\n",
    "        Returns:\n",
    "            x_recon: Reconstructed image of shape (batch, 1, 128, 128)\n",
    "        \"\"\"\n",
    "        x = self.fc(z)\n",
    "        x = x.view(x.size(0), 256, 8, 8)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.deconv1(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.deconv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.deconv3(x)), 0.2)\n",
    "        x = torch.sigmoid(self.deconv4(x))  # Output in [0, 1]\n",
    "\n",
    "        return x"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify decoder\n",
    "decoder = ConvDecoder(latent_dim=LATENT_DIM).to(device)\n",
    "z_test = torch.randn(2, LATENT_DIM).to(device)\n",
    "recon_test = decoder(z_test)\n",
    "assert recon_test.shape == (2, 1, IMG_SIZE, IMG_SIZE), f\"Decoder output shape: {recon_test.shape}\"\n",
    "assert recon_test.min() >= 0 and recon_test.max() <= 1, \"Decoder output out of [0, 1] range\"\n",
    "print(f\"Decoder output shape: {recon_test.shape}\")\n",
    "print(f\"Decoder output range: [{recon_test.min():.4f}, {recon_test.max():.4f}]\")\n",
    "print(\"Decoder verification PASSED.\")"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Reparameterization Trick and Full VAE\n",
    "\n",
    "The reparameterization trick is the key insight that makes VAE training possible. Instead of sampling $z \\sim \\mathcal{N}(\\mu, \\sigma^2)$ directly (which is not differentiable), we reparameterize as:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)$$\n",
    "\n",
    "This moves the stochasticity to $\\epsilon$, which does not depend on the model parameters, making the entire computation differentiable with respect to $\\mu$ and $\\sigma$."
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Variational Autoencoder for anomaly detection.\n",
    "\n",
    "    Combines ConvEncoder and ConvDecoder with the reparameterization trick.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = ConvEncoder(latent_dim)\n",
    "        self.decoder = ConvDecoder(latent_dim)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick: sample z from q(z|x) = N(mu, sigma^2).\n",
    "\n",
    "        TODO: Implement this method.\n",
    "\n",
    "        Steps:\n",
    "        1. Compute std = exp(0.5 * logvar)\n",
    "           (logvar = log(sigma^2), so 0.5 * logvar = log(sigma), and exp gives sigma)\n",
    "        2. Sample epsilon from N(0, I) with the same shape as std\n",
    "           (use torch.randn_like(std))\n",
    "        3. Compute z = mu + std * epsilon\n",
    "        4. Return z\n",
    "\n",
    "        Hints:\n",
    "        - torch.randn_like(std) creates a tensor of the same shape as std,\n",
    "          filled with samples from N(0, 1)\n",
    "        - During evaluation (model.eval()), we can still use this function --\n",
    "          the stochasticity helps provide a distribution of anomaly scores\n",
    "\n",
    "        Args:\n",
    "            mu: Mean of the latent distribution, shape (batch, latent_dim)\n",
    "            logvar: Log-variance of the latent distribution, shape (batch, latent_dim)\n",
    "\n",
    "        Returns:\n",
    "            z: Sampled latent vector, shape (batch, latent_dim)\n",
    "        \"\"\"\n",
    "        # TODO: Implement reparameterization trick\n",
    "        raise NotImplementedError(\"Implement ConvVAE.reparameterize()\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Full forward pass: encode -> reparameterize -> decode.\n",
    "\n",
    "        Args:\n",
    "            x: Input image, shape (batch, 1, 128, 128)\n",
    "\n",
    "        Returns:\n",
    "            x_recon: Reconstructed image, shape (batch, 1, 128, 128)\n",
    "            mu: Latent mean, shape (batch, latent_dim)\n",
    "            logvar: Latent log-variance, shape (batch, latent_dim)\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: full forward pass\n",
    "model = ConvVAE(latent_dim=LATENT_DIM).to(device)\n",
    "test_input = torch.randn(2, 1, IMG_SIZE, IMG_SIZE).to(device)\n",
    "try:\n",
    "    x_recon, mu, logvar = model(test_input)\n",
    "    assert x_recon.shape == test_input.shape, f\"Reconstruction shape mismatch: {x_recon.shape}\"\n",
    "    assert mu.shape == (2, LATENT_DIM), f\"mu shape: {mu.shape}\"\n",
    "    assert logvar.shape == (2, LATENT_DIM), f\"logvar shape: {logvar.shape}\"\n",
    "    print(f\"VAE forward pass: input={test_input.shape} -> recon={x_recon.shape}\")\n",
    "    print(f\"Latent space: mu={mu.shape}, logvar={logvar.shape}\")\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {n_params:,} ({n_params/1e6:.2f}M)\")\n",
    "    print(\"VAE verification PASSED.\")\n",
    "except NotImplementedError as e:\n",
    "    print(f\"Not yet implemented: {e}\")\n",
    "    print(\"Complete the TODOs in ConvEncoder.forward() and ConvVAE.reparameterize()\")"
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Loss Function\n",
    "\n",
    "The VAE loss has two terms:\n",
    "\n",
    "1. **Reconstruction loss** (BCE): measures how well the model reconstructs the input image. We use binary cross-entropy because pixel values are in [0, 1].\n",
    "\n",
    "$$\\mathcal{L}_{\\text{recon}} = -\\sum_{i=1}^{D} [x_i \\log \\hat{x}_i + (1 - x_i) \\log(1 - \\hat{x}_i)]$$\n",
    "\n",
    "2. **KL divergence**: regularizes the latent space to be close to a standard normal prior.\n",
    "\n",
    "$$\\mathcal{L}_{\\text{KL}} = -\\frac{1}{2} \\sum_{j=1}^{J} (1 + \\log \\sigma_j^2 - \\mu_j^2 - \\sigma_j^2)$$\n",
    "\n",
    "The total loss with KL annealing:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{recon}} + \\beta \\cdot \\mathcal{L}_{\\text{KL}}$$"
   ],
   "id": "cell_31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_recon, x, mu, logvar, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the VAE loss: reconstruction (BCE) + beta * KL divergence.\n",
    "\n",
    "    Args:\n",
    "        x_recon: Reconstructed image, shape (batch, 1, H, W)\n",
    "        x: Original image, shape (batch, 1, H, W)\n",
    "        mu: Latent mean, shape (batch, latent_dim)\n",
    "        logvar: Latent log-variance, shape (batch, latent_dim)\n",
    "        beta: KL weight (for KL annealing)\n",
    "\n",
    "    Returns:\n",
    "        total_loss: Scalar, the combined loss\n",
    "        recon_loss: Scalar, the reconstruction loss (for logging)\n",
    "        kl_loss: Scalar, the KL divergence (for logging)\n",
    "    \"\"\"\n",
    "    # Reconstruction loss: BCE summed over pixels, averaged over batch\n",
    "    recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum') / x.size(0)\n",
    "\n",
    "    # KL divergence: closed-form for Gaussian\n",
    "    # -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "\n",
    "    total_loss = recon_loss + beta * kl_loss\n",
    "\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "# Quick test\n",
    "x_dummy = torch.rand(4, 1, IMG_SIZE, IMG_SIZE).to(device)\n",
    "x_recon_dummy = torch.rand(4, 1, IMG_SIZE, IMG_SIZE).to(device)\n",
    "mu_dummy = torch.randn(4, LATENT_DIM).to(device)\n",
    "logvar_dummy = torch.randn(4, LATENT_DIM).to(device)\n",
    "\n",
    "total, recon, kl = vae_loss(x_recon_dummy, x_dummy, mu_dummy, logvar_dummy, beta=0.5)\n",
    "print(f\"Loss test: total={total.item():.2f}, recon={recon.item():.2f}, kl={kl.item():.2f}\")"
   ],
   "id": "cell_32"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.5 Training\n",
    "\n",
    "We train the VAE with three important techniques:\n",
    "\n",
    "1. **KL Annealing:** $\\beta$ linearly increases from 0 to 1 over the first 10 epochs. This prevents posterior collapse -- a failure mode where the KL term dominates early training and the model learns to ignore the latent space entirely.\n",
    "\n",
    "2. **Cosine Annealing LR:** The learning rate follows a cosine schedule from 1e-3 down to 1e-5, providing smooth decay without the sharp drops of step schedules.\n",
    "\n",
    "3. **Gradient Clipping:** Clips gradient norms to 1.0 to prevent training instability from large gradients.\n",
    "\n",
    "### TODO: Implement the Training Loop"
   ],
   "id": "cell_33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, val_loader, num_epochs=30, lr=1e-3,\n",
    "              weight_decay=1e-5, kl_anneal_epochs=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train the VAE with KL annealing and cosine LR schedule.\n",
    "\n",
    "    TODO: Implement this function.\n",
    "\n",
    "    Steps for each epoch:\n",
    "    1. Compute beta for KL annealing:\n",
    "       beta = min(1.0, epoch / kl_anneal_epochs)\n",
    "    2. For each batch in train_loader:\n",
    "       a. Move batch to device\n",
    "       b. Forward pass through model: x_recon, mu, logvar = model(x)\n",
    "       c. Compute loss: total, recon, kl = vae_loss(x_recon, x, mu, logvar, beta)\n",
    "       d. Backward pass and optimizer step\n",
    "       e. Clip gradients: torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "       f. Accumulate losses for logging\n",
    "    3. Evaluate on val_loader (no gradients)\n",
    "    4. Step the LR scheduler\n",
    "    5. Log all metrics\n",
    "\n",
    "    Hints:\n",
    "    - Use torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    - Use torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "    - IMPORTANT: Call optimizer.zero_grad() BEFORE the forward pass\n",
    "    - IMPORTANT: Call torch.nn.utils.clip_grad_norm_ AFTER loss.backward()\n",
    "      but BEFORE optimizer.step()\n",
    "    - Use model.train() for training and model.eval() for validation\n",
    "    - Wrap the training loop with tqdm for progress tracking\n",
    "\n",
    "    Args:\n",
    "        model: ConvVAE model\n",
    "        train_loader: DataLoader with normal training images\n",
    "        val_loader: DataLoader with normal validation images\n",
    "        num_epochs: Number of training epochs\n",
    "        lr: Initial learning rate\n",
    "        weight_decay: AdamW weight decay\n",
    "        kl_anneal_epochs: Number of epochs to anneal beta from 0 to 1\n",
    "        device: 'cuda' or 'cpu'\n",
    "\n",
    "    Returns:\n",
    "        history: dict with keys 'train_total', 'train_recon', 'train_kl',\n",
    "                 'val_total', 'val_recon', 'val_kl', each mapping to a list\n",
    "                 of per-epoch values\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_total': [], 'train_recon': [], 'train_kl': [],\n",
    "        'val_total': [], 'val_recon': [], 'val_kl': [],\n",
    "    }\n",
    "\n",
    "    # TODO: Create optimizer (AdamW)\n",
    "\n",
    "    # TODO: Create LR scheduler (CosineAnnealingLR)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # TODO: Compute beta for KL annealing\n",
    "\n",
    "        # TODO: Training loop\n",
    "        # model.train()\n",
    "        # for batch in train_loader:\n",
    "        #     ...\n",
    "\n",
    "        # TODO: Validation loop\n",
    "        # model.eval()\n",
    "        # with torch.no_grad():\n",
    "        #     ...\n",
    "\n",
    "        # TODO: Step scheduler\n",
    "\n",
    "        # TODO: Log metrics to history\n",
    "\n",
    "        # TODO: Print epoch summary (every 5 epochs)\n",
    "        pass\n",
    "\n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "model = ConvVAE(latent_dim=LATENT_DIM).to(device)\n",
    "print(f\"Training ConvVAE for {NUM_EPOCHS} epochs...\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "history = train_vae(\n",
    "    model, train_loader, val_loader,\n",
    "    num_epochs=NUM_EPOCHS, lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY, kl_anneal_epochs=KL_ANNEAL_EPOCHS,\n",
    "    device=device\n",
    ")"
   ],
   "id": "cell_34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: training should have produced loss histories\n",
    "assert len(history['train_total']) == NUM_EPOCHS, \\\n",
    "    f\"Expected {NUM_EPOCHS} training loss values, got {len(history['train_total'])}\"\n",
    "assert history['train_total'][-1] < history['train_total'][0], \\\n",
    "    \"Training loss did not decrease -- check your training loop\"\n",
    "print(f\"Final training loss: {history['train_total'][-1]:.2f}\")\n",
    "print(f\"Final validation loss: {history['val_total'][-1]:.2f}\")\n",
    "print(\"Training verification PASSED.\")"
   ],
   "id": "cell_35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs_range = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Total loss\n",
    "axes[0].plot(epochs_range, history['train_total'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(epochs_range, history['val_total'], 'r--', label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[0].set_title('Total Loss (Recon + beta * KL)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[1].plot(epochs_range, history['train_recon'], 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(epochs_range, history['val_recon'], 'r--', label='Validation', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Reconstruction Loss (BCE)')\n",
    "axes[1].set_title('Reconstruction Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# KL divergence\n",
    "axes[2].plot(epochs_range, history['train_kl'], 'b-', label='Train', linewidth=2)\n",
    "axes[2].plot(epochs_range, history['val_kl'], 'r--', label='Validation', linewidth=2)\n",
    "# Overlay the beta schedule\n",
    "beta_schedule = [min(1.0, e / KL_ANNEAL_EPOCHS) for e in range(NUM_EPOCHS)]\n",
    "ax2 = axes[2].twinx()\n",
    "ax2.plot(epochs_range, beta_schedule, 'g:', label='Beta (KL weight)', linewidth=2, alpha=0.7)\n",
    "ax2.set_ylabel('Beta', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "ax2.set_ylim(0, 1.1)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('KL Divergence')\n",
    "axes[2].set_title('KL Divergence + Beta Schedule')\n",
    "axes[2].legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('VAE Training Curves', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions on validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_batch, _ = next(iter(val_loader))\n",
    "    val_batch = val_batch.to(device)\n",
    "    recon_batch, _, _ = model(val_batch)\n",
    "\n",
    "n_show = 8\n",
    "fig, axes = plt.subplots(2, n_show, figsize=(2 * n_show, 4))\n",
    "fig.suptitle('Validation Reconstructions: Original (top) vs Reconstructed (bottom)',\n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "for i in range(n_show):\n",
    "    axes[0, i].imshow(val_batch[i].cpu().squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(recon_batch[i].cpu().squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Original', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Reconstructed', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_37"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.6 Evaluation\n",
    "\n",
    "Now we evaluate the trained VAE as an anomaly detector. The core idea: the VAE was trained only on normal images, so it reconstructs normal images well (low reconstruction error) but fails to reconstruct anomalous images (high reconstruction error). The reconstruction error is our anomaly score.\n",
    "\n",
    "### TODO: Implement the Evaluation Pipeline"
   ],
   "id": "cell_38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_scores(model, data_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Compute anomaly scores for all images in the data loader.\n",
    "\n",
    "    The anomaly score for each image is the mean squared error (MSE)\n",
    "    between the original and reconstructed image.\n",
    "\n",
    "    TODO: Implement this function.\n",
    "\n",
    "    Steps:\n",
    "    1. Set model to eval mode\n",
    "    2. For each batch:\n",
    "       a. Forward pass to get reconstructions\n",
    "       b. Compute per-image MSE: mean over all pixels of (x - x_recon)^2\n",
    "       c. Store the score for each image\n",
    "    3. Return all scores as a numpy array\n",
    "\n",
    "    Hints:\n",
    "    - Use torch.no_grad() to disable gradient computation\n",
    "    - MSE per image: ((x - x_recon) ** 2).mean(dim=[1, 2, 3])\n",
    "      This averages over channels (1), height (2), and width (3)\n",
    "    - Convert to numpy with .cpu().numpy()\n",
    "\n",
    "    Args:\n",
    "        model: Trained ConvVAE model\n",
    "        data_loader: DataLoader with test images\n",
    "        device: 'cuda' or 'cpu'\n",
    "\n",
    "    Returns:\n",
    "        scores: np.array of shape (n_images,) with anomaly scores\n",
    "    \"\"\"\n",
    "    # TODO: Implement anomaly score computation\n",
    "    raise NotImplementedError(\"Implement compute_anomaly_scores()\")\n",
    "\n",
    "# Compute anomaly scores\n",
    "print(\"Computing anomaly scores on test set...\")\n",
    "anomaly_scores = compute_anomaly_scores(model, test_loader, device)\n",
    "test_labels_arr = np.array(test_labels)\n",
    "\n",
    "normal_scores = anomaly_scores[test_labels_arr == 0]\n",
    "anomaly_scores_only = anomaly_scores[test_labels_arr == 1]\n",
    "\n",
    "print(f\"Normal scores: mean={normal_scores.mean():.6f}, std={normal_scores.std():.6f}\")\n",
    "print(f\"Anomaly scores: mean={anomaly_scores_only.mean():.6f}, std={anomaly_scores_only.std():.6f}\")"
   ],
   "id": "cell_39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert anomaly_scores is not None, \"Anomaly scores not computed\"\n",
    "assert len(anomaly_scores) == len(test_labels), \\\n",
    "    f\"Score count ({len(anomaly_scores)}) != label count ({len(test_labels)})\"\n",
    "assert anomaly_scores_only.mean() > normal_scores.mean(), \\\n",
    "    \"Anomaly scores should be higher than normal scores on average\"\n",
    "print(\"Anomaly score computation verification PASSED.\")"
   ],
   "id": "cell_40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics\n",
    "vae_auroc = roc_auc_score(test_labels_arr, anomaly_scores)\n",
    "precision, recall, _ = precision_recall_curve(test_labels_arr, anomaly_scores)\n",
    "vae_auprc = auc(recall, precision)\n",
    "\n",
    "# FPR and TPR for ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels_arr, anomaly_scores)\n",
    "\n",
    "# Find operating point at FPR = 5%\n",
    "fpr_5_idx = np.argmin(np.abs(fpr - 0.05))\n",
    "tpr_at_fpr5 = tpr[fpr_5_idx]\n",
    "threshold_at_fpr5 = thresholds[fpr_5_idx]\n",
    "fnr_at_fpr5 = 1 - tpr_at_fpr5\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"VAE Anomaly Detection Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"AUROC:                    {vae_auroc:.4f}\")\n",
    "print(f\"AUPRC:                    {vae_auprc:.4f}\")\n",
    "print(f\"TPR at FPR=5%:            {tpr_at_fpr5:.4f}\")\n",
    "print(f\"FNR at FPR=5%:            {fnr_at_fpr5:.4f}\")\n",
    "print(f\"Threshold at FPR=5%:      {threshold_at_fpr5:.6f}\")\n",
    "print(f\"PCA best AUROC:           {pca_best_auroc:.4f}\")\n",
    "print(f\"VAE improvement over PCA: {vae_auroc - pca_best_auroc:+.4f}\")"
   ],
   "id": "cell_41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Anomaly score distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Score distribution histogram\n",
    "axes[0].hist(normal_scores, bins=50, alpha=0.7, color='steelblue', label='Normal', density=True)\n",
    "axes[0].hist(anomaly_scores_only, bins=50, alpha=0.7, color='crimson', label='Anomaly', density=True)\n",
    "axes[0].axvline(threshold_at_fpr5, color='green', linestyle='--', linewidth=2,\n",
    "                label=f'Threshold (FPR=5%)')\n",
    "axes[0].set_xlabel('Anomaly Score (MSE)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Anomaly Score Distributions')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC curve\n",
    "axes[1].plot(fpr, tpr, 'b-', linewidth=2, label=f'VAE (AUROC={vae_auroc:.3f})')\n",
    "# Add PCA baseline\n",
    "best_pca_scores = pca_results[best_k]['scores']\n",
    "pca_fpr, pca_tpr, _ = roc_curve(test_labels_arr, best_pca_scores)\n",
    "axes[1].plot(pca_fpr, pca_tpr, 'r--', linewidth=2, label=f'PCA k={best_k} (AUROC={pca_best_auroc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "# Mark FPR=5% operating point\n",
    "axes[1].plot(fpr[fpr_5_idx], tpr[fpr_5_idx], 'go', markersize=12,\n",
    "             label=f'FPR=5% (TPR={tpr_at_fpr5:.3f})')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve: VAE vs PCA Baseline')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall curve\n",
    "axes[2].plot(recall, precision, 'b-', linewidth=2, label=f'VAE (AUPRC={vae_auprc:.3f})')\n",
    "axes[2].set_xlabel('Recall')\n",
    "axes[2].set_ylabel('Precision')\n",
    "axes[2].set_title('Precision-Recall Curve')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('VAE Anomaly Detection Performance', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_42"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.7 Error Analysis\n",
    "\n",
    "Understanding where the model fails is critical for production deployment. False negatives (missed defects) are far more costly than false positives (false alarms) in safety-critical semiconductor inspection."
   ],
   "id": "cell_43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify predictions at the FPR=5% threshold\n",
    "predictions = (anomaly_scores >= threshold_at_fpr5).astype(int)\n",
    "\n",
    "# Find error cases\n",
    "false_negatives = np.where((test_labels_arr == 1) & (predictions == 0))[0]\n",
    "false_positives = np.where((test_labels_arr == 0) & (predictions == 1))[0]\n",
    "true_positives = np.where((test_labels_arr == 1) & (predictions == 1))[0]\n",
    "true_negatives = np.where((test_labels_arr == 0) & (predictions == 0))[0]\n",
    "\n",
    "print(f\"Confusion Matrix at FPR=5% threshold:\")\n",
    "print(f\"  True Negatives  (correct normal):  {len(true_negatives)}\")\n",
    "print(f\"  True Positives  (caught defects):  {len(true_positives)}\")\n",
    "print(f\"  False Positives (false alarms):    {len(false_positives)}\")\n",
    "print(f\"  False Negatives (missed defects):  {len(false_negatives)}\")"
   ],
   "id": "cell_44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize false negatives: defective images the model MISSED\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n_show = min(5, len(false_negatives))\n",
    "    if n_show > 0:\n",
    "        fig, axes = plt.subplots(3, n_show, figsize=(3 * n_show, 9))\n",
    "        fig.suptitle('False Negatives: Defects the Model Missed', fontsize=13, fontweight='bold')\n",
    "\n",
    "        for i in range(n_show):\n",
    "            idx = false_negatives[i]\n",
    "            img, original_label = test_dataset[idx]\n",
    "            img_tensor = img.unsqueeze(0).to(device)\n",
    "            recon, _, _ = model(img_tensor)\n",
    "\n",
    "            original = img.squeeze().cpu().numpy()\n",
    "            reconstructed = recon.squeeze().cpu().numpy()\n",
    "            heatmap = (original - reconstructed) ** 2\n",
    "\n",
    "            axes[0, i].imshow(original, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[0, i].set_title(f'Original\\n({FASHION_CLASSES[original_label]})', fontsize=9)\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "            axes[1, i].imshow(reconstructed, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[1, i].set_title(f'Reconstructed\\nScore: {anomaly_scores[idx]:.5f}', fontsize=9)\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "            im = axes[2, i].imshow(heatmap, cmap='hot', vmin=0)\n",
    "            axes[2, i].set_title('Error Heatmap', fontsize=9)\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "        axes[0, 0].set_ylabel('Original', fontsize=10)\n",
    "        axes[1, 0].set_ylabel('Reconstruction', fontsize=10)\n",
    "        axes[2, 0].set_ylabel('Error Heatmap', fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No false negatives at this threshold -- the model caught all anomalies.\")"
   ],
   "id": "cell_45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize false positives: normal images the model incorrectly flagged\n",
    "with torch.no_grad():\n",
    "    n_show = min(5, len(false_positives))\n",
    "    if n_show > 0:\n",
    "        fig, axes = plt.subplots(3, n_show, figsize=(3 * n_show, 9))\n",
    "        fig.suptitle('False Positives: Normal Images Incorrectly Flagged', fontsize=13, fontweight='bold')\n",
    "\n",
    "        for i in range(n_show):\n",
    "            idx = false_positives[i]\n",
    "            img, _ = test_dataset[idx]\n",
    "            img_tensor = img.unsqueeze(0).to(device)\n",
    "            recon, _, _ = model(img_tensor)\n",
    "\n",
    "            original = img.squeeze().cpu().numpy()\n",
    "            reconstructed = recon.squeeze().cpu().numpy()\n",
    "            heatmap = (original - reconstructed) ** 2\n",
    "\n",
    "            axes[0, i].imshow(original, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[0, i].set_title('Original\\n(Normal)', fontsize=9)\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "            axes[1, i].imshow(reconstructed, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[1, i].set_title(f'Reconstructed\\nScore: {anomaly_scores[idx]:.5f}', fontsize=9)\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "            im = axes[2, i].imshow(heatmap, cmap='hot', vmin=0)\n",
    "            axes[2, i].set_title('Error Heatmap', fontsize=9)\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "        axes[0, 0].set_ylabel('Original', fontsize=10)\n",
    "        axes[1, 0].set_ylabel('Reconstruction', fontsize=10)\n",
    "        axes[2, 0].set_ylabel('Error Heatmap', fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No false positives at this threshold.\")"
   ],
   "id": "cell_46"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Error Analysis and Failure Mode Categorization"
   ],
   "id": "cell_47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_failure_modes(false_negatives, false_positives, anomaly_scores,\n",
    "                             test_dataset, test_labels, fashion_classes):\n",
    "    \"\"\"\n",
    "    Analyze and categorize the model's failure modes.\n",
    "\n",
    "    TODO: Implement this function.\n",
    "\n",
    "    Steps:\n",
    "    1. For false negatives (missed defects):\n",
    "       a. Group by the original FashionMNIST class label\n",
    "       b. Count how many missed detections come from each \"defect type\"\n",
    "       c. Identify the top 3 hardest defect types to detect\n",
    "\n",
    "    2. For false positives (false alarms):\n",
    "       a. Compute the anomaly score for each false positive\n",
    "       b. Identify common patterns (e.g., are these images at the boundary\n",
    "          of the normal distribution?)\n",
    "\n",
    "    3. Propose one concrete mitigation for each of the top 3 failure modes.\n",
    "       Mitigations could include:\n",
    "       - Data augmentation strategies\n",
    "       - Architecture modifications (e.g., attention mechanisms)\n",
    "       - Ensemble methods (e.g., multiple VAEs with different latent dims)\n",
    "       - Post-processing (e.g., multi-scale anomaly scoring)\n",
    "\n",
    "    Hints:\n",
    "    - Use a dictionary to count false negatives by original class\n",
    "    - The \"hardest\" defect type is the one with the highest miss rate\n",
    "    - Consider: WHY does the model reconstruct some anomalies well?\n",
    "      Is the anomaly visually similar to the normal class?\n",
    "\n",
    "    Args:\n",
    "        false_negatives: np.array of indices of missed defects\n",
    "        false_positives: np.array of indices of false alarms\n",
    "        anomaly_scores: np.array of all anomaly scores\n",
    "        test_dataset: The test Dataset object\n",
    "        test_labels: np.array of test labels (0=normal, 1=anomaly)\n",
    "        fashion_classes: List of class names\n",
    "\n",
    "    Returns:\n",
    "        analysis: dict with keys:\n",
    "          - 'fn_by_class': dict mapping class_name -> count of false negatives\n",
    "          - 'top_3_failure_modes': list of 3 strings describing failure modes\n",
    "          - 'mitigations': list of 3 strings with proposed mitigations\n",
    "    \"\"\"\n",
    "    # TODO: Implement failure mode analysis\n",
    "    analysis = {\n",
    "        'fn_by_class': None,\n",
    "        'top_3_failure_modes': None,\n",
    "        'mitigations': None,\n",
    "    }\n",
    "    return analysis\n",
    "\n",
    "# Run analysis\n",
    "analysis = categorize_failure_modes(\n",
    "    false_negatives, false_positives, anomaly_scores,\n",
    "    test_dataset, test_labels_arr, FASHION_CLASSES\n",
    ")\n",
    "\n",
    "# Print results\n",
    "if analysis['fn_by_class'] is not None:\n",
    "    print(\"False Negatives by Defect Type:\")\n",
    "    for cls, count in sorted(analysis['fn_by_class'].items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {cls:20s}: {count}\")\n",
    "\n",
    "    print(\"\\nTop 3 Failure Modes:\")\n",
    "    for i, mode in enumerate(analysis['top_3_failure_modes'], 1):\n",
    "        print(f\"  {i}. {mode}\")\n",
    "\n",
    "    print(\"\\nProposed Mitigations:\")\n",
    "    for i, mit in enumerate(analysis['mitigations'], 1):\n",
    "        print(f\"  {i}. {mit}\")\n",
    "else:\n",
    "    print(\"Complete the categorize_failure_modes() TODO above.\")"
   ],
   "id": "cell_48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert analysis['fn_by_class'] is not None, \"Failure mode analysis not implemented\"\n",
    "assert analysis['top_3_failure_modes'] is not None, \"Top 3 failure modes not identified\"\n",
    "assert len(analysis['top_3_failure_modes']) == 3, \"Exactly 3 failure modes required\"\n",
    "assert analysis['mitigations'] is not None, \"Mitigations not proposed\"\n",
    "assert len(analysis['mitigations']) == 3, \"Exactly 3 mitigations required\"\n",
    "print(\"Error analysis verification PASSED.\")"
   ],
   "id": "cell_49"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.8 Deployment Considerations\n",
    "\n",
    "For NovaSilicon's production deployment, the model must meet strict latency requirements (< 50ms per image on a T4 GPU) and be exportable to a format suitable for serving with NVIDIA Triton or TorchServe.\n",
    "\n",
    "### TODO: Benchmark and Export the Model"
   ],
   "id": "cell_50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(model, img_size=128, device='cuda', n_warmup=10, n_runs=100):\n",
    "    \"\"\"\n",
    "    Benchmark the model's inference latency.\n",
    "\n",
    "    TODO: Implement this function.\n",
    "\n",
    "    Steps:\n",
    "    1. Create a dummy input tensor of shape (1, 1, img_size, img_size)\n",
    "    2. Run n_warmup forward passes to warm up the GPU\n",
    "    3. Time n_runs forward passes (use time.time() or torch.cuda.Event)\n",
    "    4. Report mean and P99 latency\n",
    "    5. Also benchmark batch inference for batch_sizes = [1, 8, 32, 64]\n",
    "\n",
    "    Hints:\n",
    "    - Use torch.cuda.synchronize() before timing to ensure GPU operations complete\n",
    "    - For P99 latency: sort the times, take the 99th percentile\n",
    "      P99 index = int(0.99 * n_runs)\n",
    "    - Use model.eval() and torch.no_grad()\n",
    "    - For batch benchmarking, create tensors of shape (batch_size, 1, img_size, img_size)\n",
    "\n",
    "    Args:\n",
    "        model: Trained ConvVAE model\n",
    "        img_size: Input image size\n",
    "        device: 'cuda' or 'cpu'\n",
    "        n_warmup: Number of warmup iterations\n",
    "        n_runs: Number of timed iterations\n",
    "\n",
    "    Returns:\n",
    "        results: dict with:\n",
    "          - 'single_mean_ms': Mean latency for single image\n",
    "          - 'single_p99_ms': P99 latency for single image\n",
    "          - 'batch_results': dict mapping batch_size -> mean latency per image in ms\n",
    "    \"\"\"\n",
    "    # TODO: Implement benchmarking\n",
    "    results = {\n",
    "        'single_mean_ms': None,\n",
    "        'single_p99_ms': None,\n",
    "        'batch_results': None,\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"Benchmarking inference latency...\")\n",
    "bench_results = benchmark_inference(model, img_size=IMG_SIZE, device=device)\n",
    "\n",
    "if bench_results['single_mean_ms'] is not None:\n",
    "    print(f\"\\nSingle Image Inference:\")\n",
    "    print(f\"  Mean latency: {bench_results['single_mean_ms']:.2f} ms\")\n",
    "    print(f\"  P99  latency: {bench_results['single_p99_ms']:.2f} ms\")\n",
    "    meets_requirement = bench_results['single_mean_ms'] < 50\n",
    "    print(f\"  Meets 50ms requirement: {'YES' if meets_requirement else 'NO'}\")\n",
    "\n",
    "    if bench_results['batch_results'] is not None:\n",
    "        print(f\"\\nBatch Inference (per-image latency):\")\n",
    "        for bs, lat in sorted(bench_results['batch_results'].items()):\n",
    "            print(f\"  Batch size {bs:3d}: {lat:.2f} ms/image\")\n",
    "else:\n",
    "    print(\"Complete the benchmark_inference() TODO above.\")"
   ],
   "id": "cell_51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TorchScript\n",
    "print(\"Exporting model to TorchScript...\")\n",
    "model.eval()\n",
    "model_cpu = model.cpu()\n",
    "\n",
    "try:\n",
    "    # TorchScript export via tracing\n",
    "    dummy_input = torch.randn(1, 1, IMG_SIZE, IMG_SIZE)\n",
    "    traced_model = torch.jit.trace(model_cpu, dummy_input)\n",
    "\n",
    "    # Save the traced model\n",
    "    torchscript_path = \"vae_wafer_detector.pt\"\n",
    "    traced_model.save(torchscript_path)\n",
    "\n",
    "    # Verify: load and compare outputs\n",
    "    loaded_model = torch.jit.load(torchscript_path)\n",
    "    with torch.no_grad():\n",
    "        original_out, _, _ = model_cpu(dummy_input)\n",
    "        loaded_out, _, _ = loaded_model(dummy_input)\n",
    "\n",
    "    max_diff = (original_out - loaded_out).abs().max().item()\n",
    "    print(f\"TorchScript model saved to: {torchscript_path}\")\n",
    "    print(f\"Max output difference (original vs loaded): {max_diff:.8f}\")\n",
    "    assert max_diff < 1e-5, \"TorchScript output differs from original\"\n",
    "    print(\"TorchScript export verification PASSED.\")\n",
    "except Exception as e:\n",
    "    print(f\"TorchScript export failed: {e}\")\n",
    "    print(\"This may happen if the model uses operations not supported by TorchScript.\")\n",
    "    print(\"In production, consider using torch.onnx.export() as an alternative.\")\n",
    "\n",
    "# Move model back to device for any subsequent use\n",
    "model = model.to(device)"
   ],
   "id": "cell_52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model size and memory analysis\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "model_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 * 1024)\n",
    "\n",
    "print(\"Model Summary:\")\n",
    "print(f\"  Total parameters:     {n_params:,}\")\n",
    "print(f\"  Model size (params):  {model_size_mb:.2f} MB\")\n",
    "\n",
    "if os.path.exists(torchscript_path):\n",
    "    disk_size_mb = os.path.getsize(torchscript_path) / (1024 * 1024)\n",
    "    print(f\"  TorchScript on disk:  {disk_size_mb:.2f} MB\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    dummy = torch.randn(1, 1, IMG_SIZE, IMG_SIZE).to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy)\n",
    "    peak_mem_mb = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "    print(f\"  Peak GPU memory:      {peak_mem_mb:.2f} MB\")\n",
    "    print(f\"  Meets 15M param budget: {'YES' if n_params < 15_000_000 else 'NO'}\")"
   ],
   "id": "cell_53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification for benchmarking\n",
    "assert bench_results['single_mean_ms'] is not None, \"Benchmarking not implemented\"\n",
    "assert bench_results['batch_results'] is not None, \"Batch benchmarking not implemented\"\n",
    "print(\"Deployment benchmarking verification PASSED.\")"
   ],
   "id": "cell_54"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.9 Ethical and Regulatory Analysis\n",
    "\n",
    "Even in industrial manufacturing, deploying ML systems carries ethical responsibilities. NovaSilicon's chips power safety-critical automotive applications, making the ethical implications of inspection failures particularly severe.\n",
    "\n",
    "### TODO: Ethical Impact Assessment"
   ],
   "id": "cell_55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethical_impact_assessment():\n",
    "    \"\"\"\n",
    "    Write a 300-500 word ethical impact assessment for deploying the VAE-based\n",
    "    wafer inspection system at NovaSilicon.\n",
    "\n",
    "    TODO: Return a string (300-500 words) addressing ALL FOUR of the following:\n",
    "\n",
    "    1. FAILURE MODE IMPACT: If the model misses a defect in a safety-critical\n",
    "       automotive chip, what are the downstream consequences? How does the model's\n",
    "       false negative rate compare to human inspectors (22% disagreement rate)?\n",
    "       Propose a mitigation (e.g., human-in-the-loop for borderline cases).\n",
    "\n",
    "    2. AUTOMATION BIAS: Will human inspectors over-rely on the model and reduce\n",
    "       their own vigilance? How can the system be designed to prevent this?\n",
    "       Consider: Should the model's confidence score be shown to inspectors?\n",
    "       What if inspectors always agree with the model?\n",
    "\n",
    "    3. WORKER DISPLACEMENT: If the model automates 80% of inspections, what\n",
    "       happens to the 28 human inspectors? What is a responsible transition plan?\n",
    "       Consider: Retraining, new roles (model monitoring, edge case review),\n",
    "       phased deployment.\n",
    "\n",
    "    4. REGULATORY COMPLIANCE: What documentation is required under ISO 9001\n",
    "       and automotive quality standards (IATF 16949) to deploy an ML-based\n",
    "       inspection system? Consider: Model validation protocols, change management,\n",
    "       traceability, periodic recertification.\n",
    "\n",
    "    Requirements:\n",
    "    - Address all 4 points\n",
    "    - 300-500 words total\n",
    "    - Professional tone\n",
    "    - At least one concrete mitigation per risk\n",
    "    - Acknowledge both benefits and risks\n",
    "\n",
    "    Returns:\n",
    "        assessment: str, the ethical impact assessment (300-500 words)\n",
    "    \"\"\"\n",
    "    # TODO: Write your ethical impact assessment\n",
    "    assessment = None  # Replace with your assessment string\n",
    "    return assessment\n",
    "\n",
    "# Verification\n",
    "assessment = ethical_impact_assessment()\n",
    "assert assessment is not None, \"Ethical impact assessment not written\"\n",
    "word_count = len(assessment.split())\n",
    "assert 250 <= word_count <= 600, f\"Assessment is {word_count} words -- target 300-500\"\n",
    "print(f\"Ethical impact assessment: {word_count} words\")\n",
    "print(\"=\" * 60)\n",
    "print(assessment)\n",
    "print(\"=\" * 60)\n",
    "print(\"Ethical analysis verification PASSED.\")"
   ],
   "id": "cell_56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "In this notebook, you built a complete anomaly detection pipeline for semiconductor wafer inspection:\n",
    "\n",
    "1. **Data Pipeline:** Prepared a proxy anomaly detection dataset with normal-only training and mixed normal/anomalous testing.\n",
    "\n",
    "2. **PCA Baseline:** Established a performance floor using linear reconstruction error as an anomaly score.\n",
    "\n",
    "3. **Convolutional VAE:** Implemented a VAE from scratch with:\n",
    "   - Convolutional encoder with BatchNorm and LeakyReLU\n",
    "   - Reparameterization trick for differentiable sampling\n",
    "   - Transposed convolutional decoder with sigmoid output\n",
    "   - Combined BCE reconstruction + KL divergence loss\n",
    "\n",
    "4. **Training:** Trained with KL annealing, cosine LR schedule, and gradient clipping.\n",
    "\n",
    "5. **Evaluation:** Computed AUROC, AUPRC, and ROC curves. Compared to PCA baseline.\n",
    "\n",
    "6. **Error Analysis:** Identified failure modes and proposed mitigations.\n",
    "\n",
    "7. **Deployment:** Benchmarked latency, exported to TorchScript, and analyzed model size.\n",
    "\n",
    "8. **Ethics:** Assessed the societal impact of deploying this system in safety-critical manufacturing.\n",
    "\n",
    "**Key takeaway:** The VAE's ability to detect anomalies without labeled defect data makes it ideal for manufacturing inspection, where defect types are diverse and evolving. The reconstruction-based approach provides interpretable outputs (heatmaps) that human inspectors can use to understand and verify the model's decisions.\n",
    "\n",
    "**Next steps:** Read Section 4 of the case study document for the full production system design, including the three-tier decision engine (PASS / REVIEW / REJECT), the human-in-the-loop workflow, the monitoring and retraining pipeline, and the NVIDIA Triton serving infrastructure."
   ],
   "id": "cell_57"
  }
 ]
}