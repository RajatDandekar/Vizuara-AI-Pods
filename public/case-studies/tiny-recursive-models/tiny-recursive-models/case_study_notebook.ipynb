{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Edge-Deployed Wafer Defect Classification Using Recursive Reasoning ‚Äî Implementation Notebook"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(f\"\\nüì¶ Python {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"üé≤ Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Edge-Deployed Wafer Defect Pattern Classification Using Recursive Reasoning\n",
    "## Implementation Notebook\n",
    "\n",
    "This notebook implements a Tiny Recursive Model (TRM) for classifying wafer map defect patterns in semiconductor manufacturing. You will build the full pipeline from data loading through model evaluation, implementing key components yourself.\n",
    "\n",
    "**Context**: SilicaAI needs a model with <10M parameters that achieves >93% accuracy on 9-class wafer defect classification, running on edge hardware (NVIDIA Jetson Orin Nano) with <50ms inference latency. The TRM architecture uses recursive reasoning ‚Äî applying a tiny 2-layer network repeatedly ‚Äî to achieve the computational depth of a 42-layer model with only 7M parameters.\n",
    "\n",
    "**Dataset**: WM-811K wafer bin map dataset (811K real wafer maps from semiconductor production).\n",
    "\n",
    "**What you will build**:\n",
    "1. Data preprocessing pipeline with augmentation\n",
    "2. Spatial feature analysis and rule-based baseline\n",
    "3. CNN baseline for comparison\n",
    "4. Full TRM architecture with rotary position embeddings, deep supervision, and adaptive halting\n",
    "5. Training loop with EMA and class-weighted loss\n",
    "6. Comprehensive evaluation and error analysis\n",
    "7. Latency profiling for edge deployment\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Data Acquisition and Preprocessing\n",
    "\n",
    "We use the WM-811K wafer map dataset, which contains 811,457 wafer bin maps from real semiconductor production lines. Each map is a 2D grid of die outcomes labeled with one of 9 defect pattern classes."
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "chatbot"
    ]
   },
   "source": [
    "# ü§ñ AI Teaching Assistant\n",
    "\n",
    "Need help with this notebook? Open the **AI Teaching Assistant** ‚Äî it has already read this entire notebook and can help with concepts, code, and exercises.\n",
    "\n",
    "**[üëâ Open AI Teaching Assistant](https://course-creator-brown.vercel.app/courses/tiny-recursive-models/practice/0/assistant)**\n",
    "\n",
    "*Tip: Open it in a separate tab and work through this notebook side-by-side.*\n"
   ],
   "id": "vizuara_chatbot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mount Google Drive if running in Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load WM-811K dataset\n",
    "# Download from: https://www.kaggle.com/datasets/qingyi/wm811k-wafer-map\n",
    "# Upload the pickle file to your Google Drive\n",
    "DATA_PATH = \"/content/drive/MyDrive/datasets/wm811k.pkl\"  # Update with your path\n",
    "\n",
    "df = pd.read_pickle(DATA_PATH)\n",
    "print(f\"Total wafer maps: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['failureType'].value_counts())"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing constants and class mapping\n",
    "GRID_SIZE = 26  # Fixed grid size for all wafer maps\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "CLASS_MAP = {\n",
    "    'none': 0, 'Center': 1, 'Donut': 2, 'Edge-Loc': 3,\n",
    "    'Edge-Ring': 4, 'Loc': 5, 'Near-full': 6, 'Random': 7, 'Scratch': 8\n",
    "}\n",
    "\n",
    "INV_CLASS_MAP = {v: k for k, v in CLASS_MAP.items()}\n",
    "\n",
    "def preprocess_wafer_map(wafer_map, target_size=GRID_SIZE):\n",
    "    \"\"\"\n",
    "    Resize a variable-size wafer map to fixed dimensions.\n",
    "\n",
    "    Args:\n",
    "        wafer_map: 2D numpy array with values {0: pass, 1: fail, 2: out-of-wafer}\n",
    "        target_size: Target grid dimension (square)\n",
    "\n",
    "    Returns:\n",
    "        Resized wafer map of shape (target_size, target_size)\n",
    "    \"\"\"\n",
    "    from skimage.transform import resize\n",
    "    resized = resize(wafer_map.astype(float), (target_size, target_size),\n",
    "                     order=0, preserve_range=True, anti_aliasing=False)\n",
    "    return resized.astype(np.int32)\n",
    "\n",
    "def flatten_to_sequence(wafer_map):\n",
    "    \"\"\"Flatten 2D grid to 1D sequence for TRM input.\"\"\"\n",
    "    return wafer_map.reshape(-1)  # (676,)"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all wafer maps\n",
    "print(\"Preprocessing wafer maps...\")\n",
    "processed_maps = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    wm = row['waferMap']\n",
    "    label_str = row['failureType']\n",
    "\n",
    "    if not isinstance(wm, np.ndarray) or wm.size == 0:\n",
    "        continue\n",
    "    if label_str not in CLASS_MAP and not pd.isna(label_str):\n",
    "        continue\n",
    "\n",
    "    label = CLASS_MAP.get(label_str, 0)  # Map NaN to 'none' (class 0)\n",
    "    processed = preprocess_wafer_map(wm, GRID_SIZE)\n",
    "    processed_maps.append(processed)\n",
    "    labels.append(label)\n",
    "\n",
    "processed_maps = np.array(processed_maps)\n",
    "labels = np.array(labels)\n",
    "print(f\"Processed {len(processed_maps)} wafer maps\")\n",
    "print(f\"Shape: {processed_maps.shape}\")\n",
    "print(f\"Label distribution: {dict(Counter(labels))}\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data Augmentation Pipeline\n",
    "\n",
    "Wafer maps have rotational symmetry (the wafer is circular), so geometric augmentations are label-preserving. Implement augmentation to address class imbalance and improve generalization."
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_wafer_map(wafer_map, label):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to a wafer map.\n",
    "\n",
    "    Wafer maps have rotational symmetry (the wafer is circular), so rotations\n",
    "    and reflections are label-preserving for most defect types. However, some\n",
    "    augmentations must respect the defect pattern semantics:\n",
    "\n",
    "    - Rotations (90, 180, 270 degrees): SAFE for all classes\n",
    "    - Horizontal/vertical flip: SAFE for all classes (symmetric wafer)\n",
    "    - Random noise injection (flip 1-2% of passing die to failing):\n",
    "      SAFE, simulates real measurement noise\n",
    "    - DO NOT apply translations or crops -- defect location relative to wafer\n",
    "      center is diagnostic\n",
    "\n",
    "    Args:\n",
    "        wafer_map: np.array of shape (26, 26), values in {0, 1, 2}\n",
    "        label: int, class label (0-8)\n",
    "\n",
    "    Returns:\n",
    "        augmented_map: np.array of shape (26, 26)\n",
    "\n",
    "    Hints:\n",
    "        1. Use np.rot90 for rotations (k parameter controls number of 90-degree rotations)\n",
    "        2. Use np.flipud and np.fliplr for reflections\n",
    "        3. For noise injection, only flip die that are within the wafer boundary (value != 2)\n",
    "        4. Randomly choose ONE augmentation per call (not all at once)\n",
    "        5. Return the original map with probability 0.3 (not every sample needs augmentation)\n",
    "    \"\"\"\n",
    "    # TODO: Implement augmentation pipeline\n",
    "    # Step 1: With 30% probability, return original (no augmentation)\n",
    "    # Step 2: Randomly select one augmentation type\n",
    "    # Step 3: Apply the selected augmentation\n",
    "    # Step 4: Ensure out-of-wafer mask (value 2) is preserved after augmentation\n",
    "    raise NotImplementedError(\"Implement wafer map augmentation\")"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification cell for augmentation\n",
    "def verify_augmentation():\n",
    "    \"\"\"Test that augmentation preserves key properties.\"\"\"\n",
    "    test_map = np.random.choice([0, 1, 2], size=(26, 26), p=[0.7, 0.2, 0.1])\n",
    "    boundary_mask = test_map == 2\n",
    "\n",
    "    augmented = augment_wafer_map(test_map.copy(), label=1)\n",
    "\n",
    "    assert augmented.shape == (26, 26), f\"Shape changed: {augmented.shape}\"\n",
    "    assert set(np.unique(augmented)).issubset({0, 1, 2}), \"Invalid values introduced\"\n",
    "    original_die_count = np.sum(test_map != 2)\n",
    "    augmented_die_count = np.sum(augmented != 2)\n",
    "    assert abs(original_die_count - augmented_die_count) <= original_die_count * 0.05, \\\n",
    "        \"Too many die added/removed\"\n",
    "    print(\"All augmentation checks passed!\")\n",
    "\n",
    "verify_augmentation()"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "- Why is translation NOT a safe augmentation for wafer maps, even though it is commonly used for natural images?\n",
    "- How would you handle augmentation differently for the \"Scratch\" class vs the \"Center\" class?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Exploratory Data Analysis\n",
    "\n",
    "Understanding the data distribution and spatial patterns before building models."
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution analysis\n",
    "label_counts = Counter(labels)\n",
    "classes = [INV_CLASS_MAP[i] for i in range(NUM_CLASSES)]\n",
    "counts = [label_counts.get(i, 0) for i in range(NUM_CLASSES)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear scale\n",
    "axes[0].bar(classes, counts, color='steelblue')\n",
    "axes[0].set_xlabel('Defect Pattern')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution in WM-811K')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Log scale to see minority classes\n",
    "axes[1].bar(classes, counts, color='steelblue')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Defect Pattern')\n",
    "axes[1].set_ylabel('Count (log scale)')\n",
    "axes[1].set_title('Class Distribution (Log Scale)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nImbalance ratio (max/min): {max(counts)/max(min(c for c in counts if c > 0),1):.1f}x\")"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example wafer maps from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "axes[-1].axis('off')  # Remove extra subplot\n",
    "\n",
    "cmap = plt.cm.colors.ListedColormap(['white', 'red', 'lightgray'])\n",
    "\n",
    "for class_id in range(NUM_CLASSES):\n",
    "    mask = labels == class_id\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "    sample_idx = np.where(mask)[0][0]\n",
    "    sample = processed_maps[sample_idx]\n",
    "\n",
    "    ax = axes[class_id]\n",
    "    ax.imshow(sample, cmap=cmap, interpolation='nearest', vmin=0, vmax=2)\n",
    "    ax.set_title(f'{INV_CLASS_MAP[class_id]} (n={mask.sum():,})')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Example Wafer Maps by Defect Class', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Spatial Feature Analysis"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spatial_features(wafer_map):\n",
    "    \"\"\"\n",
    "    Compute spatial statistics that characterize defect patterns.\n",
    "\n",
    "    These features will help you understand WHY certain patterns are\n",
    "    challenging to distinguish, and will serve as the basis for the\n",
    "    rule-based baseline.\n",
    "\n",
    "    Args:\n",
    "        wafer_map: np.array of shape (H, W), values in {0, 1, 2}\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "            - 'defect_ratio': fraction of in-wafer die that are defective\n",
    "            - 'radial_profile': np.array of shape (13,) -- average defect rate\n",
    "              at each radial distance from center (13 bins for 26x26 grid)\n",
    "            - 'angular_profile': np.array of shape (8,) -- average defect rate\n",
    "              in each 45-degree angular sector\n",
    "            - 'centroid_distance': distance of defect centroid from wafer center,\n",
    "              normalized by wafer radius\n",
    "            - 'spatial_entropy': Shannon entropy of the 2D defect distribution\n",
    "              (higher = more spread out, lower = more concentrated)\n",
    "\n",
    "    Hints:\n",
    "        1. Compute wafer center as the centroid of all in-wafer die (value != 2)\n",
    "        2. For radial profile, compute distance of each die from center, bin into 13 equal-width bins\n",
    "        3. For angular profile, compute angle of each die from center using np.arctan2, bin into 8 sectors\n",
    "        4. Centroid of defects = mean (row, col) of all defective die (value == 1)\n",
    "        5. For spatial entropy, divide the grid into 4x4 blocks, compute defect rate per block,\n",
    "           then compute entropy over the block-level distribution\n",
    "    \"\"\"\n",
    "    # TODO: Implement spatial feature computation\n",
    "    raise NotImplementedError(\"Implement spatial feature computation\")"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification cell for spatial features\n",
    "def verify_spatial_features():\n",
    "    \"\"\"Test spatial feature computation on a known pattern.\"\"\"\n",
    "    # Create a center-defect pattern: defects concentrated in the middle\n",
    "    test_map = np.full((26, 26), 0)\n",
    "    test_map[:3, :] = 2  # Top rows out-of-wafer\n",
    "    test_map[-3:, :] = 2  # Bottom rows out-of-wafer\n",
    "    test_map[11:15, 11:15] = 1  # Center cluster of defects\n",
    "\n",
    "    features = compute_spatial_features(test_map)\n",
    "\n",
    "    assert 'defect_ratio' in features, \"Missing 'defect_ratio'\"\n",
    "    assert 'radial_profile' in features, \"Missing 'radial_profile'\"\n",
    "    assert features['radial_profile'].shape == (13,), f\"Wrong radial shape: {features['radial_profile'].shape}\"\n",
    "    assert features['angular_profile'].shape == (8,), f\"Wrong angular shape: {features['angular_profile'].shape}\"\n",
    "    assert features['centroid_distance'] < 0.3, \"Center defect should have small centroid distance\"\n",
    "    print(f\"Defect ratio: {features['defect_ratio']:.3f}\")\n",
    "    print(f\"Centroid distance: {features['centroid_distance']:.3f}\")\n",
    "    print(\"All spatial feature checks passed!\")\n",
    "\n",
    "verify_spatial_features()"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. Which defect patterns have the most similar radial profiles? What additional features would help distinguish them?\n",
    "2. The class distribution is heavily imbalanced. What strategies could address this during training? How might class weighting interact with the TRM's deep supervision?\n",
    "3. Why is spatial entropy useful for distinguishing \"random\" defects from structured patterns like \"scratch\" or \"edge-ring\"?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 Baseline Approach\n",
    "\n",
    "Establish performance bounds with a rule-based baseline and a simple CNN."
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train/val/test splits\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    processed_maps, labels, test_size=0.3, random_state=42, stratify=labels\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Rule-Based Baseline"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rule_based_baseline(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Build a decision tree classifier over spatial features as the rule-based baseline.\n",
    "\n",
    "    This represents the traditional approach used in semiconductor fabs:\n",
    "    compute handcrafted spatial statistics, then apply a simple classifier.\n",
    "\n",
    "    Args:\n",
    "        X_train: np.array of shape (N_train, 26, 26) -- wafer maps\n",
    "        y_train: np.array of shape (N_train,) -- class labels\n",
    "        X_test: np.array of shape (N_test, 26, 26) -- wafer maps\n",
    "        y_test: np.array of shape (N_test,) -- class labels\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "            - 'accuracy': float, overall accuracy on test set\n",
    "            - 'macro_f1': float, macro-averaged F1\n",
    "            - 'predictions': np.array of test set predictions\n",
    "            - 'model': the fitted DecisionTreeClassifier\n",
    "\n",
    "    Steps:\n",
    "        1. Compute spatial features for all training and test wafer maps\n",
    "           using compute_spatial_features()\n",
    "        2. Stack features into feature matrices\n",
    "        3. Fit a DecisionTreeClassifier with max_depth=10 on training features\n",
    "        4. Predict on test set\n",
    "        5. Compute overall accuracy and macro F1\n",
    "        6. Print the classification report\n",
    "\n",
    "    Hint: Use sklearn.metrics.classification_report with output_dict=True for per-class F1\n",
    "    \"\"\"\n",
    "    # TODO: Implement rule-based baseline\n",
    "    raise NotImplementedError(\"Implement rule-based baseline\")"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: CNN Baseline"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_baseline(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                       num_epochs=20, batch_size=128):\n",
    "    \"\"\"\n",
    "    Build a simple CNN baseline for wafer map classification.\n",
    "\n",
    "    Architecture: 3 conv layers (32, 64, 128 filters) with BatchNorm and MaxPool,\n",
    "    followed by a global average pool and linear classifier.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "        X_test, y_test: Test data and labels\n",
    "        num_epochs: Number of training epochs\n",
    "        batch_size: Batch size\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "            - 'accuracy': float, test accuracy\n",
    "            - 'macro_f1': float, test macro F1\n",
    "            - 'model': trained CNN model\n",
    "            - 'param_count': int, number of parameters\n",
    "\n",
    "    Steps:\n",
    "        1. Define a CNN with 3 conv blocks: Conv2d -> BatchNorm -> ReLU -> MaxPool\n",
    "        2. Add global average pooling and a linear layer for 9-class output\n",
    "        3. Use CrossEntropyLoss with class weights (inverse frequency) to handle imbalance\n",
    "        4. Train with Adam optimizer, lr=1e-3, for num_epochs\n",
    "        5. Evaluate on test set\n",
    "\n",
    "    Hints:\n",
    "        - Input shape: (batch, 1, 26, 26) -- single channel wafer map\n",
    "        - Conv filter sizes: 3x3 with padding=1\n",
    "        - MaxPool: 2x2\n",
    "        - After 3 pooling steps, spatial dim is 26->13->6->3, so GAP output is (batch, 128)\n",
    "        - Total params should be ~150K (far smaller than SilicaAI's 45M cloud model)\n",
    "    \"\"\"\n",
    "    # TODO: Implement CNN baseline\n",
    "    raise NotImplementedError(\"Implement CNN baseline\")"
   ],
   "id": "cell_21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baselines\n",
    "def compare_baselines(rule_results, cnn_results):\n",
    "    \"\"\"Print a comparison table of baseline results.\"\"\"\n",
    "    print(f\"\\n{'Method':<25} {'Accuracy':>10} {'Macro F1':>10} {'Params':>12}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Rule-based (DTree)':<25} {rule_results['accuracy']:>10.3f} {rule_results['macro_f1']:>10.3f} {'N/A':>12}\")\n",
    "    print(f\"{'CNN (3-layer)':<25} {cnn_results['accuracy']:>10.3f} {cnn_results['macro_f1']:>10.3f} {cnn_results['param_count']:>12,}\")\n",
    "    print(f\"\\n{'Target (TRM)':<25} {'>0.93':>10} {'>0.90':>10} {'<10M':>12}\")"
   ],
   "id": "cell_22"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. What classes does the rule-based baseline struggle with most? Why?\n",
    "2. How does the CNN baseline's accuracy compare to SilicaAI's cloud model (89%)? What accounts for the difference?\n",
    "3. If you were to improve the CNN baseline without changing the architecture, what training strategies would you try?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Model Design: Tiny Recursive Model\n",
    "\n",
    "Now we implement the core TRM architecture adapted for wafer defect classification."
   ],
   "id": "cell_23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ],
   "id": "cell_24"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Blocks: RMSNorm and SwiGLU"
   ],
   "id": "cell_25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    \"\"\"Root Mean Square Layer Normalization.\n",
    "\n",
    "    Simpler and faster than LayerNorm -- normalizes by the RMS of activations\n",
    "    without centering (no mean subtraction). Used in LLaMA, Gemini, and TRM.\n",
    "\n",
    "    RMSNorm(x) = x / RMS(x) * gamma\n",
    "    where RMS(x) = sqrt(mean(x^2) + eps)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
    "        return x / rms * self.weight\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU activation: a gated activation used in modern transformers.\n",
    "\n",
    "    SwiGLU(x) = (xW1) * swish(xW2)\n",
    "    where swish(z) = z * sigmoid(z)\n",
    "\n",
    "    The gating mechanism allows the network to learn which features to pass\n",
    "    through, providing more expressiveness than simple ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        hidden_dim = hidden_dim or dim * 4\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w3(F.silu(self.w1(x)) * self.w2(x))"
   ],
   "id": "cell_26"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: 2D Rotary Position Embeddings"
   ],
   "id": "cell_27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionEmbedding2D(nn.Module):\n",
    "    \"\"\"\n",
    "    2D Rotary Position Embeddings for grid-structured data.\n",
    "\n",
    "    Standard rotary embeddings encode 1D position. For wafer maps, we need\n",
    "    2D position encoding because defect patterns are defined by their (row, col)\n",
    "    location relative to the wafer center.\n",
    "\n",
    "    The key idea: split the embedding dimension in half. The first half encodes\n",
    "    the row position, the second half encodes the column position. Each half\n",
    "    uses standard rotary embeddings.\n",
    "\n",
    "    Args:\n",
    "        dim: Embedding dimension (must be divisible by 4 for 2D)\n",
    "        grid_size: Size of the square grid (26 for our wafer maps)\n",
    "\n",
    "    Forward args:\n",
    "        x: Tensor of shape (batch, seq_len, dim) where seq_len = grid_size^2\n",
    "\n",
    "    Returns:\n",
    "        Tensor of same shape with positional information encoded\n",
    "\n",
    "    Implementation steps:\n",
    "        1. In __init__:\n",
    "           a. Precompute frequency bases: theta_i = 1 / (10000^(2i/d)) for i in [0, d/4)\n",
    "           b. Precompute row and column indices for each position in the flattened grid\n",
    "           c. Precompute sin and cos tables for row and column positions\n",
    "\n",
    "        2. In forward:\n",
    "           a. Split x into 4 chunks along the last dimension: [x_r1, x_r2, x_c1, x_c2]\n",
    "           b. Apply rotation to row components:\n",
    "              x_r1' = x_r1 * cos(row_pos) - x_r2 * sin(row_pos)\n",
    "              x_r2' = x_r1 * sin(row_pos) + x_r2 * cos(row_pos)\n",
    "           c. Apply rotation to col components similarly\n",
    "           d. Concatenate [x_r1', x_r2', x_c1', x_c2'] and return\n",
    "\n",
    "    Hints:\n",
    "        - Use torch.arange and integer division/modulo to get (row, col) from flat index\n",
    "        - Register sin/cos tables as buffers (self.register_buffer) so they move to GPU automatically\n",
    "        - The frequency base formula: freqs = 1.0 / (10000.0 ** (torch.arange(0, dim//4, 2).float() / (dim//4)))\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, grid_size=GRID_SIZE):\n",
    "        super().__init__()\n",
    "        # TODO: Implement initialization\n",
    "        # Step 1: Compute frequency bases\n",
    "        # Step 2: Compute row/col position indices for flattened grid\n",
    "        # Step 3: Compute and register sin/cos buffers\n",
    "        raise NotImplementedError(\"Implement 2D rotary position embeddings\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        # Step 1: Split x into 4 chunks\n",
    "        # Step 2: Apply rotary transformation to row and col components\n",
    "        # Step 3: Concatenate and return\n",
    "        raise NotImplementedError(\"Implement rotary forward pass\")"
   ],
   "id": "cell_28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification for rotary embeddings\n",
    "def verify_rotary():\n",
    "    \"\"\"Test that rotary embeddings preserve norms and encode position.\"\"\"\n",
    "    rope = RotaryPositionEmbedding2D(dim=128, grid_size=26)\n",
    "    x = torch.randn(2, 676, 128)\n",
    "    y = rope(x)\n",
    "\n",
    "    assert y.shape == x.shape, f\"Shape mismatch: {y.shape} vs {x.shape}\"\n",
    "    # Rotary embeddings should approximately preserve norms\n",
    "    x_norms = torch.norm(x, dim=-1)\n",
    "    y_norms = torch.norm(y, dim=-1)\n",
    "    assert torch.allclose(x_norms, y_norms, atol=1e-4), \"Norms not preserved\"\n",
    "    print(\"Rotary embedding checks passed!\")\n",
    "\n",
    "verify_rotary()"
   ],
   "id": "cell_29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: TRM Block (Single Recursion Step)"
   ],
   "id": "cell_30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRMBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single Tiny Recursive Model block -- one layer of the 2-layer network.\n",
    "\n",
    "    This block processes three inputs (x, y, z) and produces updated (y, z).\n",
    "    It uses the attention variant since our wafer maps (676 tokens) have\n",
    "    seq_len >> hidden_dim.\n",
    "\n",
    "    Architecture per block:\n",
    "        1. Concatenate inputs: cat([x, y, z]) along feature dim -> project to dim\n",
    "        2. RMSNorm\n",
    "        3. Self-attention with rotary position embeddings\n",
    "        4. Residual connection\n",
    "        5. RMSNorm\n",
    "        6. SwiGLU feedforward\n",
    "        7. Residual connection\n",
    "        8. Project to output (y_update, z_update)\n",
    "\n",
    "    Args:\n",
    "        dim: Hidden dimension (128)\n",
    "        num_heads: Number of attention heads (8)\n",
    "        grid_size: Grid size for position embeddings (26)\n",
    "\n",
    "    Forward args:\n",
    "        x: Input wafer map embedding, shape (batch, seq_len, dim)\n",
    "        y: Current solution state, shape (batch, seq_len, dim)\n",
    "        z: Current reasoning state, shape (batch, seq_len, dim)\n",
    "\n",
    "    Returns:\n",
    "        y_new: Updated solution state, shape (batch, seq_len, dim)\n",
    "        z_new: Updated reasoning state, shape (batch, seq_len, dim)\n",
    "\n",
    "    Implementation hints:\n",
    "        1. Input combination: concatenate [x, y, z] along feature dim -> (batch, seq_len, 3*dim)\n",
    "           then project to dim with a linear layer\n",
    "        2. For self-attention: implement manually with Q, K, V projections\n",
    "           (nn.Linear(dim, dim) for each), apply rotary embeddings to Q and K,\n",
    "           then compute scaled dot-product attention\n",
    "        3. The residual connection adds the combined input to the attention output\n",
    "        4. Output projection: one linear layer from dim -> 2*dim, then split into y_update and z_update\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=128, num_heads=8, grid_size=GRID_SIZE):\n",
    "        super().__init__()\n",
    "        # TODO: Implement initialization\n",
    "        # Define: input projection (3*dim -> dim), RMSNorm layers,\n",
    "        # Q/K/V projections, SwiGLU feedforward, output projection (dim -> 2*dim),\n",
    "        # rotary embeddings\n",
    "        raise NotImplementedError(\"Implement TRMBlock.__init__\")\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        # TODO: Implement forward pass\n",
    "        # Step 1: Combine inputs: h = project(cat([x, y, z], dim=-1))\n",
    "        # Step 2: norm1 -> attention (with rotary) -> residual\n",
    "        # Step 3: norm2 -> SwiGLU -> residual\n",
    "        # Step 4: Project to y_new, z_new = split(output_proj(h), dim=-1)\n",
    "        raise NotImplementedError(\"Implement TRMBlock.forward\")"
   ],
   "id": "cell_31"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Full TRM with Recursion and Deep Supervision"
   ],
   "id": "cell_32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyRecursiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Full Tiny Recursive Model for wafer defect classification.\n",
    "\n",
    "    Architecture:\n",
    "        - Input embedding: maps wafer map tokens (0, 1, 2) to dim-dimensional vectors\n",
    "        - 2 TRMBlock layers (the core recursive unit)\n",
    "        - Classification head: pools sequence -> 9-class logits\n",
    "        - Halting head: pools sequence -> scalar halt probability\n",
    "\n",
    "    Recursion:\n",
    "        - T supervision steps, n recursion iterations per step\n",
    "        - At each supervision step: run n iterations, then compute loss\n",
    "        - Deep supervision: loss is computed at each of the T steps\n",
    "\n",
    "    Args:\n",
    "        dim: Hidden dimension (128)\n",
    "        num_heads: Attention heads (8)\n",
    "        num_layers: Layers in recursive unit (2)\n",
    "        num_classes: Output classes (9)\n",
    "        grid_size: Wafer grid size (26)\n",
    "        T: Number of supervision steps (3)\n",
    "        n: Recursion iterations per supervision step (6)\n",
    "\n",
    "    Forward args:\n",
    "        wafer_map: LongTensor of shape (batch, seq_len) with values in {0, 1, 2}\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'logits': list of T tensors, each shape (batch, num_classes)\n",
    "            - 'halt_probs': list of T tensors, each shape (batch, 1)\n",
    "            - 'final_logits': tensor of shape (batch, num_classes) -- last supervision step\n",
    "\n",
    "    Implementation steps:\n",
    "        1. __init__:\n",
    "           a. Embedding layer: nn.Embedding(3, dim) for input tokens\n",
    "           b. Stack of num_layers TRMBlock modules\n",
    "           c. Classification head: LayerNorm -> Linear(dim, num_classes)\n",
    "           d. Halting head: LayerNorm -> Linear(dim, 1) -> Sigmoid\n",
    "\n",
    "        2. forward:\n",
    "           a. Embed input: x = embedding(wafer_map)  # (batch, seq_len, dim)\n",
    "           b. Initialize y = zeros(batch, seq_len, dim), z = zeros(batch, seq_len, dim)\n",
    "           c. For each supervision step t in [1, T]:\n",
    "               i.   For each recursion iteration i in [1, n]:\n",
    "                       For each layer in self.layers:\n",
    "                           y, z = layer(x, y, z)\n",
    "               ii.  Compute logits_t = cls_head(y.mean(dim=1))\n",
    "               iii. Compute halt_t = halt_head(y.mean(dim=1))\n",
    "               iv.  Append to output lists\n",
    "           d. Return dict with all outputs\n",
    "\n",
    "        3. IMPORTANT: during training, gradients flow through ALL recursion\n",
    "           iterations within each supervision step (full backprop, not 1-step\n",
    "           approximation). This is the key insight that gives +30.9% accuracy.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=128, num_heads=8, num_layers=2, num_classes=NUM_CLASSES,\n",
    "                 grid_size=GRID_SIZE, T=3, n=6):\n",
    "        super().__init__()\n",
    "        # TODO: Implement initialization\n",
    "        raise NotImplementedError(\"Implement TinyRecursiveModel.__init__\")\n",
    "\n",
    "    def forward(self, wafer_map):\n",
    "        # TODO: Implement forward pass with recursion and deep supervision\n",
    "        raise NotImplementedError(\"Implement TinyRecursiveModel.forward\")"
   ],
   "id": "cell_33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification for TRM\n",
    "def verify_trm():\n",
    "    \"\"\"Test TRM architecture basics.\"\"\"\n",
    "    model = TinyRecursiveModel(dim=128, num_heads=8, num_layers=2,\n",
    "                                num_classes=9, grid_size=26, T=3, n=6)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Count parameters\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {param_count:,}\")\n",
    "    assert param_count < 20_000_000, f\"Too many parameters: {param_count:,}\"\n",
    "\n",
    "    # Test forward pass\n",
    "    dummy_input = torch.randint(0, 3, (4, 676)).to(DEVICE)  # batch of 4\n",
    "    output = model(dummy_input)\n",
    "\n",
    "    assert 'logits' in output, \"Missing 'logits' in output\"\n",
    "    assert len(output['logits']) == 3, f\"Expected 3 supervision steps, got {len(output['logits'])}\"\n",
    "    assert output['logits'][0].shape == (4, 9), f\"Wrong logits shape: {output['logits'][0].shape}\"\n",
    "    assert output['halt_probs'][0].shape == (4, 1), f\"Wrong halt shape: {output['halt_probs'][0].shape}\"\n",
    "    assert 0 <= output['halt_probs'][0].min() <= output['halt_probs'][0].max() <= 1, \"Halt probs out of range\"\n",
    "\n",
    "    print(f\"Model parameters: {param_count:,} (target: <10M)\")\n",
    "    print(f\"Output logits shape per step: {output['logits'][0].shape}\")\n",
    "    print(f\"Number of supervision steps: {len(output['logits'])}\")\n",
    "    print(\"All TRM checks passed!\")\n",
    "\n",
    "verify_trm()"
   ],
   "id": "cell_34"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. Why do we initialize y and z to zeros rather than random values? What would happen if we used random initialization?\n",
    "2. The effective depth is 42 layers (3 x 7 x 2). A standard 42-layer transformer would have 42x more parameters. What is the tradeoff? In what situations might the standard transformer outperform TRM despite having more parameters?\n",
    "3. Why does the halting head use sigmoid (outputting a probability) rather than outputting a discrete stop/continue decision?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 Training Strategy"
   ],
   "id": "cell_35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ],
   "id": "cell_36"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why AdamW?** The loss landscape of recursive models is complex -- per-parameter learning rates navigate it more effectively than a single global rate (SGD). Weight decay decoupling is critical when using parameter sharing.\n",
    "\n",
    "**Why cosine schedule?** Provides smooth decay that avoids abrupt drops. Important because the deep supervision signal evolves during training.\n",
    "\n",
    "**EMA (Exponential Moving Average):** Maintains a shadow copy of weights for evaluation stability. Critical for small datasets (+7.5% accuracy in ablations)."
   ],
   "id": "cell_37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    \"\"\"Exponential Moving Average of model parameters.\"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = (\n",
    "                    self.decay * self.shadow[name] + (1 - self.decay) * param.data\n",
    "                )\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        \"\"\"Replace model params with EMA params for evaluation.\"\"\"\n",
    "        self.backup = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        \"\"\"Restore original params after evaluation.\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]"
   ],
   "id": "cell_38"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Deep Supervision Loss"
   ],
   "id": "cell_39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trm_loss(output, targets, class_weights):\n",
    "    \"\"\"\n",
    "    Compute the TRM loss with deep supervision.\n",
    "\n",
    "    The loss is the sum of prediction loss + halting loss across all T\n",
    "    supervision steps.\n",
    "\n",
    "    Args:\n",
    "        output: dict from TinyRecursiveModel.forward() with 'logits' and 'halt_probs'\n",
    "        targets: LongTensor of shape (batch,) with true class labels (0-8)\n",
    "        class_weights: FloatTensor of shape (num_classes,) for weighted cross-entropy\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'total_loss': scalar, the combined loss\n",
    "            - 'pred_losses': list of T prediction losses\n",
    "            - 'halt_losses': list of T halting losses\n",
    "            - 'per_step_accuracy': list of T accuracy values (for logging)\n",
    "\n",
    "    Steps:\n",
    "        1. For each supervision step t:\n",
    "           a. Compute weighted cross-entropy: CE(logits[t], targets, weight=class_weights)\n",
    "           b. Compute per-sample correctness: q = (argmax(logits[t]) == targets).float()\n",
    "           c. Compute halting loss: BCE(halt_probs[t].squeeze(), q)\n",
    "           d. Step loss = CE + BCE\n",
    "        2. Total loss = sum of all step losses\n",
    "        3. Compute per-step accuracy for logging\n",
    "\n",
    "    Hints:\n",
    "        - Use F.cross_entropy with the weight parameter for class-weighted CE\n",
    "        - Use F.binary_cross_entropy for halting loss (halt_probs already has sigmoid applied)\n",
    "        - Detach q when computing BCE -- we do not want gradients flowing through the correctness check\n",
    "    \"\"\"\n",
    "    # TODO: Implement loss computation\n",
    "    raise NotImplementedError(\"Implement TRM loss with deep supervision\")"
   ],
   "id": "cell_40"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Training Loop"
   ],
   "id": "cell_41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, class_weights, ema, device):\n",
    "    \"\"\"\n",
    "    Train the TRM for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: TinyRecursiveModel instance\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: AdamW optimizer\n",
    "        class_weights: Tensor of class weights for imbalanced data\n",
    "        ema: EMA instance\n",
    "        device: torch device\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'avg_loss': float, average total loss over epoch\n",
    "            - 'avg_accuracy': float, average accuracy (final supervision step)\n",
    "            - 'per_step_accuracies': list of T floats, average accuracy per step\n",
    "\n",
    "    Steps:\n",
    "        1. Set model to train mode\n",
    "        2. For each batch:\n",
    "           a. Move data to device\n",
    "           b. Forward pass through model\n",
    "           c. Compute loss via compute_trm_loss\n",
    "           d. Backward pass and optimizer step\n",
    "           e. Update EMA weights\n",
    "           f. Log running metrics\n",
    "        3. Return epoch-level metrics\n",
    "\n",
    "    Important:\n",
    "        - Use torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "          to prevent gradient explosion through the deep recursion chain\n",
    "        - Zero gradients BEFORE the forward pass, not after\n",
    "    \"\"\"\n",
    "    # TODO: Implement training loop\n",
    "    raise NotImplementedError(\"Implement training loop\")"
   ],
   "id": "cell_42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, class_weights, device):\n",
    "    \"\"\"\n",
    "    Evaluate the TRM on a test/validation set.\n",
    "\n",
    "    Args:\n",
    "        model: TinyRecursiveModel instance (should use EMA weights)\n",
    "        test_loader: DataLoader for evaluation data\n",
    "        class_weights: Tensor of class weights\n",
    "        device: torch device\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'accuracy': float, overall accuracy\n",
    "            - 'macro_f1': float, macro-averaged F1 score\n",
    "            - 'per_class_f1': dict mapping class_name -> f1\n",
    "            - 'avg_loss': float, average loss\n",
    "            - 'confusion_matrix': np.array of shape (9, 9)\n",
    "            - 'per_step_accuracies': list of T accuracies\n",
    "\n",
    "    Steps:\n",
    "        1. Set model to eval mode, use torch.no_grad()\n",
    "        2. Collect all predictions and targets\n",
    "        3. Compute metrics using sklearn\n",
    "    \"\"\"\n",
    "    # TODO: Implement evaluation\n",
    "    raise NotImplementedError(\"Implement evaluation\")"
   ],
   "id": "cell_43"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ],
   "id": "cell_44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Flatten wafer maps to sequences\n",
    "X_train_flat = X_train.reshape(len(X_train), -1)  # (N, 676)\n",
    "X_val_flat = X_val.reshape(len(X_val), -1)\n",
    "X_test_flat = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train_flat, dtype=torch.long),\n",
    "    torch.tensor(y_train, dtype=torch.long)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(X_val_flat, dtype=torch.long),\n",
    "    torch.tensor(y_val, dtype=torch.long)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test_flat, dtype=torch.long),\n",
    "    torch.tensor(y_test, dtype=torch.long)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ],
   "id": "cell_45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training\n",
    "model = TinyRecursiveModel(dim=128, num_heads=8, num_layers=2,\n",
    "                            num_classes=NUM_CLASSES, grid_size=GRID_SIZE, T=3, n=6)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {param_count:,}\")\n",
    "\n",
    "# Compute class weights from training set\n",
    "train_class_counts = np.bincount(y_train, minlength=NUM_CLASSES)\n",
    "class_weights = torch.tensor(\n",
    "    1.0 / (train_class_counts + 1e-6), dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "class_weights = class_weights / class_weights.sum() * NUM_CLASSES\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCHS = 50\n",
    "best_f1 = 0.0\n",
    "best_state = None\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'val_accuracy': [], 'val_f1': []}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_metrics = train_one_epoch(model, train_loader, optimizer,\n",
    "                                     class_weights, ema, DEVICE)\n",
    "    scheduler.step()\n",
    "\n",
    "    ema.apply_shadow()\n",
    "    val_metrics = evaluate(model, val_loader, class_weights, DEVICE)\n",
    "    ema.restore()\n",
    "\n",
    "    history['train_loss'].append(train_metrics['avg_loss'])\n",
    "    history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "    history['val_f1'].append(val_metrics['macro_f1'])\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_metrics['avg_loss']:.4f} | \"\n",
    "          f\"Val Acc: {val_metrics['accuracy']:.4f} | \"\n",
    "          f\"Val F1: {val_metrics['macro_f1']:.4f} | \"\n",
    "          f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    if val_metrics['macro_f1'] > best_f1:\n",
    "        best_f1 = val_metrics['macro_f1']\n",
    "        best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= 10:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nBest validation F1: {best_f1:.4f}\")\n",
    "model.load_state_dict(best_state)"
   ],
   "id": "cell_46"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. Why do we clip gradients to max_norm=1.0? What would happen without gradient clipping in a model that unrolls 18 recursion steps?\n",
    "2. The EMA decay is set to 0.999. What would happen if we set it to 0.9 (faster EMA) or 0.9999 (slower EMA)? When is each appropriate?\n",
    "3. Deep supervision computes the loss at 3 intermediate points. Could we use different learning rates or loss weights for each supervision step? What would be the motivation?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.6 Evaluation\n",
    "\n",
    "Quantitative evaluation of the trained TRM against both baselines."
   ],
   "id": "cell_47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test evaluation with EMA weights\n",
    "ema.apply_shadow()\n",
    "test_metrics = evaluate(model, test_loader, class_weights, DEVICE)\n",
    "ema.restore()\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"  Overall Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Macro F1:         {test_metrics['macro_f1']:.4f}\")\n",
    "print(f\"\\nPer-class F1:\")\n",
    "for cls_name, f1_val in test_metrics['per_class_f1'].items():\n",
    "    print(f\"  {cls_name:<15} {f1_val:.4f}\")"
   ],
   "id": "cell_48"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Evaluation Visualizations"
   ],
   "id": "cell_49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_results(test_metrics, history):\n",
    "    \"\"\"\n",
    "    Generate comprehensive evaluation plots.\n",
    "\n",
    "    Create a 2x2 figure with:\n",
    "        1. Confusion matrix heatmap (top-left)\n",
    "        2. Per-class F1 bar chart (top-right)\n",
    "        3. Training curves: loss and val accuracy over epochs (bottom-left)\n",
    "        4. Per-supervision-step accuracy (bottom-right) -- showing how accuracy\n",
    "           improves from step 1 to step 3\n",
    "\n",
    "    Args:\n",
    "        test_metrics: dict from evaluate() for TRM\n",
    "        history: dict with training history\n",
    "\n",
    "    Hints:\n",
    "        - Use plt.imshow for confusion matrix with 'Blues' colormap\n",
    "        - Annotate each cell of confusion matrix with the count\n",
    "        - Use twin axes (ax.twinx()) for overlaying loss and accuracy\n",
    "        - Annotate the per-step accuracy plot with the improvement from step 1 to step 3\n",
    "    \"\"\"\n",
    "    # TODO: Implement evaluation plots\n",
    "    raise NotImplementedError(\"Implement evaluation visualizations\")\n",
    "\n",
    "plot_evaluation_results(test_metrics, history)"
   ],
   "id": "cell_50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment readiness check\n",
    "def check_targets(test_metrics):\n",
    "    \"\"\"Verify model meets deployment requirements.\"\"\"\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    checks = {\n",
    "        'Accuracy > 93%': test_metrics['accuracy'] > 0.93,\n",
    "        'Macro F1 > 0.90': test_metrics['macro_f1'] > 0.90,\n",
    "        f'Params < 10M ({param_count:,})': param_count < 10_000_000,\n",
    "    }\n",
    "    print(\"\\nDeployment Readiness Check:\")\n",
    "    all_passed = True\n",
    "    for check, passed in checks.items():\n",
    "        status = \"PASS\" if passed else \"FAIL\"\n",
    "        print(f\"  [{status}] {check}\")\n",
    "        if not passed:\n",
    "            all_passed = False\n",
    "\n",
    "    if all_passed:\n",
    "        print(\"\\nModel meets all deployment criteria!\")\n",
    "    else:\n",
    "        print(\"\\nModel does NOT meet all criteria. Review failure modes and iterate.\")\n",
    "\n",
    "check_targets(test_metrics)"
   ],
   "id": "cell_51"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. Which classes have the lowest F1 scores? Examine the confusion matrix -- which classes are most commonly confused? Does this make physical sense given the defect patterns?\n",
    "2. How much does accuracy improve from supervision step 1 to step 3? What does this tell you about the value of recursive reasoning for this task?\n",
    "3. If you could add one more evaluation metric relevant to the business problem, what would it be and why?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.7 Error Analysis\n",
    "\n",
    "Systematic investigation of failure modes to guide improvements."
   ],
   "id": "cell_52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_errors(model, test_loader, device):\n",
    "    \"\"\"Collect all misclassified wafer maps with predictions and confidences.\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for wafer_maps, batch_labels in test_loader:\n",
    "            wafer_maps, batch_labels = wafer_maps.to(device), batch_labels.to(device)\n",
    "            output = model(wafer_maps)\n",
    "            probs = F.softmax(output['final_logits'], dim=-1)\n",
    "            preds = probs.argmax(dim=-1)\n",
    "\n",
    "            mask = preds != batch_labels\n",
    "            for j in range(mask.sum()):\n",
    "                idx = mask.nonzero()[j].item()\n",
    "                errors.append({\n",
    "                    'wafer_map': wafer_maps[idx].cpu(),\n",
    "                    'true_label': batch_labels[idx].item(),\n",
    "                    'pred_label': preds[idx].item(),\n",
    "                    'confidence': probs[idx, preds[idx]].item(),\n",
    "                    'true_prob': probs[idx, batch_labels[idx]].item(),\n",
    "                    'all_probs': probs[idx].cpu().numpy()\n",
    "                })\n",
    "    return errors\n",
    "\n",
    "errors = collect_errors(model, test_loader, DEVICE)\n",
    "print(f\"Total errors: {len(errors)}\")"
   ],
   "id": "cell_53"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Error Categorization"
   ],
   "id": "cell_54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_errors(errors):\n",
    "    \"\"\"\n",
    "    Categorize misclassifications into failure modes.\n",
    "\n",
    "    Args:\n",
    "        errors: list of dicts from collect_errors()\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'high_confidence_errors': list of errors where confidence > 0.8\n",
    "            - 'confusion_pairs': dict mapping (true, pred) -> count\n",
    "            - 'boundary_errors': list of errors where true and pred are \"neighboring\" classes\n",
    "\n",
    "    Additionally, print:\n",
    "        - Top 3 most common confusion pairs\n",
    "        - Average confidence on correct vs incorrect predictions\n",
    "        - Percentage of high-confidence errors\n",
    "\n",
    "    Hints:\n",
    "        1. \"Neighboring\" classes: (center, donut), (edge-loc, edge-ring),\n",
    "           (loc, random), (near-full, random)\n",
    "        2. Sort confusion pairs by count to find the top 3\n",
    "    \"\"\"\n",
    "    # TODO: Implement error categorization\n",
    "    raise NotImplementedError(\"Implement error categorization\")\n",
    "\n",
    "error_categories = categorize_errors(errors)"
   ],
   "id": "cell_55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_errors(errors, n=6):\n",
    "    \"\"\"\n",
    "    Visualize the most informative error cases.\n",
    "\n",
    "    Show the top-n errors by confidence (high-confidence misclassifications),\n",
    "    with each subplot showing:\n",
    "    - The wafer map (reshaped to 26x26)\n",
    "    - True label and predicted label\n",
    "    - Confidence bar chart over all 9 classes\n",
    "\n",
    "    Args:\n",
    "        errors: list of error dicts\n",
    "        n: number of errors to visualize\n",
    "    \"\"\"\n",
    "    # TODO: Implement error visualization\n",
    "    raise NotImplementedError(\"Implement error visualization\")\n",
    "\n",
    "visualize_top_errors(errors, n=6)"
   ],
   "id": "cell_56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. Identify the top 3 failure modes. For each, propose a specific intervention -- could it be addressed by architecture changes, data augmentation, or post-processing?\n",
    "2. Are high-confidence errors clustered in specific classes? What does this imply for the halting mechanism?\n",
    "3. How could the error analysis inform the deployment strategy? For example, should certain predictions be automatically flagged for human review?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.8 Latency Profiling and Deployment"
   ],
   "id": "cell_57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def profile_inference_latency(model, device, num_samples=1000, warmup=50):\n",
    "    \"\"\"Profile inference latency on the current device.\"\"\"\n",
    "    model.eval()\n",
    "    dummy_input = torch.randint(0, 3, (1, 676)).to(device)\n",
    "\n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "    # Profile\n",
    "    latencies = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            start = time.perf_counter()\n",
    "            _ = model(dummy_input)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            latencies.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "    print(f\"Inference Latency Profile ({device}):\")\n",
    "    print(f\"  p50:  {np.percentile(latencies, 50):.2f} ms\")\n",
    "    print(f\"  p90:  {np.percentile(latencies, 90):.2f} ms\")\n",
    "    print(f\"  p99:  {np.percentile(latencies, 99):.2f} ms\")\n",
    "    print(f\"  mean: {np.mean(latencies):.2f} ms\")\n",
    "    return latencies\n",
    "\n",
    "latencies = profile_inference_latency(model, DEVICE)"
   ],
   "id": "cell_58"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Adaptive Inference with Early Halting"
   ],
   "id": "cell_59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_with_halting(model, wafer_map, halt_threshold=0.9, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Run inference with adaptive halting -- stop recursing when the model\n",
    "    is confident it has the right answer.\n",
    "\n",
    "    Args:\n",
    "        model: TinyRecursiveModel instance\n",
    "        wafer_map: LongTensor of shape (1, 676) -- single wafer map\n",
    "        halt_threshold: float, stop when halt probability exceeds this\n",
    "        device: torch device\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'prediction': int, predicted class\n",
    "            - 'confidence': float, prediction confidence\n",
    "            - 'num_steps_used': int, how many supervision steps were actually run\n",
    "            - 'latency_ms': float, actual inference time\n",
    "            - 'halt_probs': list of halt probabilities at each step\n",
    "\n",
    "    Implementation:\n",
    "        1. Run the model step-by-step (not all T steps at once)\n",
    "        2. After each supervision step, check the halt probability\n",
    "        3. If halt_prob > halt_threshold, stop and return current prediction\n",
    "        4. Otherwise, continue to next supervision step\n",
    "        5. Time the entire process\n",
    "\n",
    "    Hint: For simplicity, run the full forward pass and check halting at each step.\n",
    "    The latency savings in production come from actually stopping the recursion early.\n",
    "    \"\"\"\n",
    "    # TODO: Implement adaptive inference\n",
    "    raise NotImplementedError(\"Implement inference with halting\")"
   ],
   "id": "cell_60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare full vs halted inference\n",
    "def compare_inference_modes(model, test_loader, device, halt_threshold=0.9):\n",
    "    \"\"\"Compare accuracy and latency of full vs halted inference.\"\"\"\n",
    "    model.eval()\n",
    "    full_correct = 0\n",
    "    halt_correct = 0\n",
    "    total = 0\n",
    "    steps_used = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for wafer_maps, batch_labels in test_loader:\n",
    "            wafer_maps, batch_labels = wafer_maps.to(device), batch_labels.to(device)\n",
    "\n",
    "            # Full inference\n",
    "            output = model(wafer_maps)\n",
    "            full_preds = output['final_logits'].argmax(dim=-1)\n",
    "            full_correct += (full_preds == batch_labels).sum().item()\n",
    "\n",
    "            # Halted inference (per-sample)\n",
    "            for i in range(len(wafer_maps)):\n",
    "                result = inference_with_halting(model, wafer_maps[i:i+1],\n",
    "                                                halt_threshold, device)\n",
    "                if result['prediction'] == batch_labels[i].item():\n",
    "                    halt_correct += 1\n",
    "                steps_used.append(result['num_steps_used'])\n",
    "\n",
    "            total += len(batch_labels)\n",
    "\n",
    "    print(f\"\\nFull inference accuracy:  {full_correct/total:.4f}\")\n",
    "    print(f\"Halted inference accuracy: {halt_correct/total:.4f}\")\n",
    "    print(f\"Average steps used: {np.mean(steps_used):.2f} / 3\")\n",
    "    print(f\"Step distribution: {Counter(steps_used)}\")\n",
    "\n",
    "# Run on a subset for speed\n",
    "small_test = torch.utils.data.Subset(test_dataset, range(min(500, len(test_dataset))))\n",
    "small_loader = DataLoader(small_test, batch_size=1, shuffle=False)\n",
    "compare_inference_modes(model, small_loader, DEVICE)"
   ],
   "id": "cell_61"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thought questions:**\n",
    "1. What is the tradeoff between halt_threshold and accuracy? At what threshold does accuracy start to drop noticeably?\n",
    "2. The Jetson Orin Nano runs at INT8 precision with 40 TOPS. How would you quantize the TRM model for deployment? What accuracy loss would you expect?\n",
    "3. The production pipeline has 50ms for classification. How would you allocate the time budget across preprocessing, inference, and postprocessing?\n",
    "\n",
    "---\n",
    "\n",
    "## 3.9 Ethical and Regulatory Analysis\n",
    "\n",
    "### TODO: Ethical Impact Assessment"
   ],
   "id": "cell_62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethical_impact_assessment():\n",
    "    \"\"\"\n",
    "    Write a brief ethical impact assessment for deploying the TRM-based\n",
    "    defect classifier in semiconductor production.\n",
    "\n",
    "    Address the following (print your answers):\n",
    "\n",
    "    1. BIAS AND FAIRNESS\n",
    "       - The WM-811K dataset comes from specific foundries. How might this introduce bias?\n",
    "       - If the model performs poorly on a specific defect type, what is the downstream impact?\n",
    "       - How would you monitor for performance degradation on minority classes over time?\n",
    "\n",
    "    2. AUTOMATION AND HUMAN OVERSIGHT\n",
    "       - The TRM model will replace or augment human inspectors. What is the appropriate\n",
    "         level of human oversight?\n",
    "       - What is the failure mode if the model encounters a novel defect pattern not in training?\n",
    "       - How should the system handle out-of-distribution inputs?\n",
    "\n",
    "    3. REGULATORY COMPLIANCE\n",
    "       - ITAR: Some semiconductor manufacturing data may be ITAR-controlled. What constraints\n",
    "         does this place on model training, deployment, and updates?\n",
    "       - Export controls for international deployment\n",
    "       - Data retention policies for production quality audits\n",
    "\n",
    "    4. ENVIRONMENTAL IMPACT\n",
    "       - Compare energy consumption: TRM edge inference vs cloud CNN inference\n",
    "       - Estimate annual energy savings for a foundry processing 10,000 wafers/day\n",
    "       - Edge: ~15W per Jetson * 40ms per wafer; Cloud: ~50W per GPU * 280ms per wafer\n",
    "\n",
    "    Print your assessment as a structured document with headers and bullet points.\n",
    "    \"\"\"\n",
    "    # TODO: Write ethical impact assessment\n",
    "    raise NotImplementedError(\"Write ethical impact assessment\")\n",
    "\n",
    "ethical_impact_assessment()"
   ],
   "id": "cell_63"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you built a complete pipeline for edge-deployed wafer defect classification using a Tiny Recursive Model:\n",
    "\n",
    "1. **Data**: Loaded and preprocessed the WM-811K wafer map dataset, analyzed class distributions and spatial patterns\n",
    "2. **Baselines**: Implemented rule-based (spatial features + decision tree) and CNN baselines\n",
    "3. **Model**: Built the TRM architecture from scratch -- rotary position embeddings, RMSNorm, SwiGLU, recursive blocks with dual state (solution y + reasoning z), and deep supervision\n",
    "4. **Training**: Trained with AdamW, cosine schedule, EMA, gradient clipping, and class-weighted deep supervision loss\n",
    "5. **Evaluation**: Measured accuracy, macro F1, and compared against baselines\n",
    "6. **Error Analysis**: Categorized failure modes and identified high-confidence misclassifications\n",
    "7. **Deployment**: Profiled latency and implemented adaptive halting for edge inference\n",
    "8. **Ethics**: Assessed bias, automation oversight, regulatory compliance, and environmental impact\n",
    "\n",
    "The key insight: recursive reasoning with a tiny shared-weight network achieves the computational depth of a 42-layer model with only 7M parameters -- making it suitable for edge deployment while maintaining accuracy that exceeds much larger single-pass architectures.\n",
    "\n",
    "For further reading on production deployment, system design, monitoring, and CI/CD for ML, refer to **Section 4** of the full case study document (`case_study.md`)."
   ],
   "id": "cell_64"
  }
 ]
}