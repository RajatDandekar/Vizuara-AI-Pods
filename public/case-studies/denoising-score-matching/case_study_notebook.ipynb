{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Denoising Score Matching Case Study -- Implementation Notebook"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\u2705 GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "print(f\"\\n\ud83d\udce6 Python {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udd25 PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\ud83c\udfb2 Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadiSynth AI: Synthetic Brain MRI Generation with Denoising Score Matching\n",
    "\n",
    "## Case Study Implementation Notebook\n",
    "\n",
    "This notebook implements the core technical components of RadiSynth AI's synthetic medical image generation pipeline using Denoising Score Matching (DSM).\n",
    "\n",
    "We use a simulated brain MRI dataset (generated from simple shapes and textures) to demonstrate the full pipeline. The same architecture and training procedure apply to real MRI data.\n",
    "\n",
    "## 1. Setup and Dependencies"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulated MRI Dataset\n",
    "\n",
    "We create a synthetic dataset that mimics key properties of brain MRI slices: elliptical brain shapes, internal structure (ventricles), and occasional \"tumors.\""
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedMRIDataset(Dataset):\n",
    "    \"\"\"Generates simple simulated brain MRI slices.\"\"\"\n",
    "\n",
    "    def __init__(self, n_samples=5000, img_size=64, tumor_fraction=0.3):\n",
    "        self.n_samples = n_samples\n",
    "        self.img_size = img_size\n",
    "        self.tumor_fraction = tumor_fraction\n",
    "        self.images, self.labels = self._generate()\n",
    "\n",
    "    def _generate(self):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for i in range(self.n_samples):\n",
    "            img = np.zeros((self.img_size, self.img_size), dtype=np.float32)\n",
    "            cx, cy = self.img_size // 2, self.img_size // 2\n",
    "\n",
    "            # Brain outline (ellipse)\n",
    "            Y, X = np.ogrid[:self.img_size, :self.img_size]\n",
    "            a = self.img_size * 0.4 + np.random.randn() * 2\n",
    "            b = self.img_size * 0.35 + np.random.randn() * 2\n",
    "            brain_mask = ((X - cx) / a) ** 2 + ((Y - cy) / b) ** 2 <= 1\n",
    "            img[brain_mask] = 0.7 + np.random.randn() * 0.05\n",
    "\n",
    "            # Ventricles (small ellipses in center)\n",
    "            v_a = self.img_size * 0.08 + np.random.randn() * 1\n",
    "            v_b = self.img_size * 0.12 + np.random.randn() * 1\n",
    "            for offset in [-1, 1]:\n",
    "                vcx = cx + offset * int(self.img_size * 0.07)\n",
    "                v_mask = ((X - vcx) / v_a) ** 2 + ((Y - cy) / v_b) ** 2 <= 1\n",
    "                img[v_mask] = 0.3 + np.random.randn() * 0.03\n",
    "\n",
    "            # Add subtle texture noise\n",
    "            img += np.random.randn(self.img_size, self.img_size) * 0.02\n",
    "            img = np.clip(img, 0, 1)\n",
    "\n",
    "            # Optionally add tumor\n",
    "            has_tumor = np.random.rand() < self.tumor_fraction\n",
    "            if has_tumor:\n",
    "                tx = cx + np.random.randint(-10, 10)\n",
    "                ty = cy + np.random.randint(-10, 10)\n",
    "                tr = np.random.randint(3, 8)\n",
    "                t_mask = (X - tx) ** 2 + (Y - ty) ** 2 <= tr ** 2\n",
    "                t_mask = t_mask & brain_mask\n",
    "                img[t_mask] = 0.9 + np.random.randn() * 0.03\n",
    "\n",
    "            # Normalize to [-1, 1]\n",
    "            img = img * 2 - 1\n",
    "\n",
    "            images.append(torch.tensor(img).unsqueeze(0))  # (1, H, W)\n",
    "            labels.append(1 if has_tumor else 0)\n",
    "\n",
    "        return torch.stack(images), torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset\n",
    "dataset = SimulatedMRIDataset(n_samples=5000, img_size=64)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Image shape: {dataset[0][0].shape}\")\n",
    "print(f\"Healthy: {(dataset.labels == 0).sum()}, Tumor: {(dataset.labels == 1).sum()}\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 5))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    img, label = dataset[i]\n",
    "    ax.imshow(img.squeeze().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.set_title('Tumor' if label == 1 else 'Healthy', fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Simulated Brain MRI Slices', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Score Network Architecture"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"Encode the noise level sigma using sinusoidal embeddings.\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, sigma):\n",
    "        half = self.dim // 2\n",
    "        freqs = torch.exp(-np.log(10000) * torch.arange(half, device=sigma.device) / half)\n",
    "        args = sigma.unsqueeze(-1) * freqs\n",
    "        embedding = torch.cat([args.sin(), args.cos()], dim=-1)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Residual block with GroupNorm and sigma conditioning.\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, sigma_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.sigma_proj = nn.Linear(sigma_dim, out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, sigma_emb):\n",
    "        h = self.act(self.norm1(self.conv1(x)))\n",
    "        # Add sigma conditioning\n",
    "        h = h + self.sigma_proj(sigma_emb)[:, :, None, None]\n",
    "        h = self.act(self.norm2(self.conv2(h)))\n",
    "        return h + self.skip(x)\n",
    "\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"Simplified U-Net for score prediction, conditioned on sigma.\"\"\"\n",
    "    def __init__(self, in_ch=1, base_ch=32, sigma_dim=64):\n",
    "        super().__init__()\n",
    "        self.sigma_embed = nn.Sequential(\n",
    "            SinusoidalPositionEmbedding(sigma_dim),\n",
    "            nn.Linear(sigma_dim, sigma_dim),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = ResBlock(in_ch, base_ch, sigma_dim)\n",
    "        self.enc2 = ResBlock(base_ch, base_ch * 2, sigma_dim)\n",
    "        self.enc3 = ResBlock(base_ch * 2, base_ch * 4, sigma_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResBlock(base_ch * 4, base_ch * 4, sigma_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.up3 = nn.ConvTranspose2d(base_ch * 4, base_ch * 4, 2, stride=2)\n",
    "        self.dec3 = ResBlock(base_ch * 8, base_ch * 2, sigma_dim)\n",
    "        self.up2 = nn.ConvTranspose2d(base_ch * 2, base_ch * 2, 2, stride=2)\n",
    "        self.dec2 = ResBlock(base_ch * 4, base_ch, sigma_dim)\n",
    "        self.up1 = nn.ConvTranspose2d(base_ch, base_ch, 2, stride=2)\n",
    "        self.dec1 = ResBlock(base_ch * 2, base_ch, sigma_dim)\n",
    "\n",
    "        self.final = nn.Conv2d(base_ch, in_ch, 1)\n",
    "\n",
    "    def forward(self, x, sigma):\n",
    "        sigma_emb = self.sigma_embed(sigma)\n",
    "\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x, sigma_emb)\n",
    "        e2 = self.enc2(self.pool(e1), sigma_emb)\n",
    "        e3 = self.enc3(self.pool(e2), sigma_emb)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e3), sigma_emb)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], dim=1), sigma_emb)\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1), sigma_emb)\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1), sigma_emb)\n",
    "\n",
    "        return self.final(d1)\n",
    "\n",
    "model = SimpleUNet().to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Score network parameters: {n_params:,}\")"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Scale DSM Training"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noise levels (geometric sequence)\n",
    "L = 10\n",
    "sigma_max = 25.0\n",
    "sigma_min = 0.01\n",
    "noise_levels = torch.exp(torch.linspace(np.log(sigma_max), np.log(sigma_min), L)).to(device)\n",
    "print(f\"Noise levels: {noise_levels.cpu().numpy().round(3)}\")"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsm_loss_multiscale(model, x, noise_levels, device):\n",
    "    \"\"\"\n",
    "    Multi-scale DSM loss (NCSN-style).\n",
    "\n",
    "    For each sample in the batch:\n",
    "    1. Randomly select a noise level\n",
    "    2. Add noise at that level\n",
    "    3. Predict the score\n",
    "    4. Compute weighted MSE loss\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    # Random noise level for each sample\n",
    "    idx = torch.randint(0, len(noise_levels), (batch_size,), device=device)\n",
    "    sigma = noise_levels[idx]  # (B,)\n",
    "\n",
    "    # Add noise\n",
    "    epsilon = torch.randn_like(x)\n",
    "    x_noisy = x + sigma[:, None, None, None] * epsilon\n",
    "\n",
    "    # Predict score\n",
    "    score_pred = model(x_noisy, sigma)\n",
    "\n",
    "    # Target: -epsilon / sigma\n",
    "    target = -epsilon / sigma[:, None, None, None]\n",
    "\n",
    "    # Weighted MSE loss\n",
    "    loss = (sigma[:, None, None, None] ** 2) * ((score_pred - target) ** 2)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    return loss"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "n_epochs = 50\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    n_batches = 0\n",
    "    for batch_images, batch_labels in dataloader:\n",
    "        batch_images = batch_images.to(device)\n",
    "\n",
    "        loss = dsm_loss_multiscale(model, batch_images, noise_levels, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_loss = epoch_loss / n_batches\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Multi-Scale DSM Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Annealed Langevin Dynamics Sampling"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def annealed_langevin_sample(model, noise_levels, n_samples=16,\n",
    "                              img_shape=(1, 64, 64), n_steps_per_level=100,\n",
    "                              base_step_size=5e-5, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate images using Annealed Langevin Dynamics.\n",
    "\n",
    "    For each noise level from largest to smallest:\n",
    "        Run n_steps of Langevin dynamics with step size proportional to sigma^2.\n",
    "    \"\"\"\n",
    "    # Start from random noise\n",
    "    x = torch.randn(n_samples, *img_shape, device=device)\n",
    "    snapshots = [x.cpu().clone()]\n",
    "\n",
    "    sigma_L = noise_levels[-1]  # smallest sigma\n",
    "\n",
    "    for i, sigma_i in enumerate(noise_levels):\n",
    "        # Step size proportional to sigma^2\n",
    "        step_size = base_step_size * (sigma_i / sigma_L) ** 2\n",
    "\n",
    "        for t in range(n_steps_per_level):\n",
    "            sigma_batch = sigma_i.expand(n_samples)\n",
    "            score = model(x, sigma_batch)\n",
    "            noise = torch.randn_like(x)\n",
    "            x = x + step_size * score + torch.sqrt(2 * step_size) * noise\n",
    "\n",
    "        snapshots.append(x.cpu().clone())\n",
    "\n",
    "    return x.cpu(), snapshots\n",
    "\n",
    "# Generate samples\n",
    "generated, snapshots = annealed_langevin_sample(\n",
    "    model, noise_levels, n_samples=16,\n",
    "    n_steps_per_level=100, device=device\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 5))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(generated[i].squeeze().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Generated Synthetic Brain MRI Slices', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the annealing process\n",
    "n_show = min(len(snapshots), 6)\n",
    "indices = np.linspace(0, len(snapshots) - 1, n_show, dtype=int)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_show, figsize=(4 * n_show, 8))\n",
    "for col, idx in enumerate(indices):\n",
    "    for row in range(2):\n",
    "        sample_idx = row\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(snapshots[idx][sample_idx].squeeze().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "        if idx == 0:\n",
    "            ax.set_title(f'Pure Noise', fontsize=10)\n",
    "        elif idx == len(snapshots) - 1:\n",
    "            ax.set_title(f'Final', fontsize=10)\n",
    "        else:\n",
    "            sigma_idx = idx - 1\n",
    "            if sigma_idx < len(noise_levels):\n",
    "                ax.set_title(f'sigma={noise_levels[sigma_idx].item():.2f}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('Annealed Langevin Dynamics: Noise to Image', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Watch how images gradually emerge from random noise!\")"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement FID computation\n",
    "def compute_simple_fid(real_images, generated_images):\n",
    "    \"\"\"\n",
    "    Compute a simplified FID score using pixel-space statistics.\n",
    "\n",
    "    For a production system, use InceptionV3 features instead.\n",
    "\n",
    "    Args:\n",
    "        real_images: (N, 1, H, W) tensor\n",
    "        generated_images: (M, 1, H, W) tensor\n",
    "\n",
    "    Returns:\n",
    "        fid: float\n",
    "\n",
    "    Steps:\n",
    "        1. Flatten images to vectors\n",
    "        2. Compute mean and covariance of real and generated features\n",
    "        3. Compute Frechet distance between the two Gaussians\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # Implement simplified FID\n",
    "    # FID = ||mu_r - mu_g||^2 + Tr(C_r + C_g - 2*(C_r @ C_g)^{1/2})\n",
    "    # ==============================\n",
    "\n",
    "    real_flat = real_images.view(real_images.shape[0], -1).numpy()\n",
    "    gen_flat = generated_images.view(generated_images.shape[0], -1).numpy()\n",
    "\n",
    "    mu_r = np.mean(real_flat, axis=0)\n",
    "    mu_g = np.mean(gen_flat, axis=0)\n",
    "\n",
    "    # Simplified: just L2 distance between means\n",
    "    fid_approx = np.sum((mu_r - mu_g) ** 2)\n",
    "\n",
    "    return fid_approx\n",
    "\n",
    "# Generate more samples for evaluation\n",
    "eval_generated, _ = annealed_langevin_sample(\n",
    "    model, noise_levels, n_samples=200,\n",
    "    n_steps_per_level=100, device=device\n",
    ")\n",
    "\n",
    "fid = compute_simple_fid(dataset.images[:200], eval_generated)\n",
    "print(f\"Approximate FID (pixel-space): {fid:.4f}\")"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare real vs generated statistics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Pixel intensity distribution\n",
    "axes[0].hist(dataset.images[:500].numpy().flatten(), bins=50,\n",
    "             alpha=0.5, density=True, label='Real', color='blue')\n",
    "axes[0].hist(eval_generated.numpy().flatten(), bins=50,\n",
    "             alpha=0.5, density=True, label='Generated', color='red')\n",
    "axes[0].set_title('Pixel Intensity Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mean image comparison\n",
    "axes[1].imshow(dataset.images[:500].mean(0).squeeze().numpy(), cmap='gray')\n",
    "axes[1].set_title('Mean Real Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(eval_generated.mean(0).squeeze().numpy(), cmap='gray')\n",
    "axes[2].set_title('Mean Generated Image')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Real vs Generated Image Statistics', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Privacy Audit"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Nearest-neighbor privacy check\n",
    "def privacy_check(generated_images, training_images, n_check=100):\n",
    "    \"\"\"\n",
    "    Check that generated images are not memorized copies of training data.\n",
    "\n",
    "    Args:\n",
    "        generated_images: (N_gen, 1, H, W) generated images\n",
    "        training_images: (N_train, 1, H, W) training images\n",
    "        n_check: number of generated images to check\n",
    "\n",
    "    Returns:\n",
    "        min_distance: minimum L2 distance found\n",
    "        distances: list of nearest-neighbor distances\n",
    "    \"\"\"\n",
    "    # ============ TODO ============\n",
    "    # For each generated image:\n",
    "    #   1. Compute L2 distance to all training images\n",
    "    #   2. Record the minimum distance\n",
    "    # ==============================\n",
    "\n",
    "    gen_flat = generated_images[:n_check].view(n_check, -1)\n",
    "    train_flat = training_images.view(len(training_images), -1)\n",
    "\n",
    "    distances = []\n",
    "    for i in range(n_check):\n",
    "        dists = torch.norm(train_flat - gen_flat[i:i+1], dim=1)\n",
    "        distances.append(dists.min().item())\n",
    "\n",
    "    return min(distances), distances\n",
    "\n",
    "min_dist, all_dists = privacy_check(eval_generated, dataset.images)\n",
    "print(f\"Minimum nearest-neighbor distance: {min_dist:.4f}\")\n",
    "print(f\"Mean nearest-neighbor distance: {np.mean(all_dists):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(all_dists, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=min_dist, color='red', linestyle='--', label=f'Min: {min_dist:.3f}')\n",
    "plt.title('Nearest-Neighbor Distance Distribution')\n",
    "plt.xlabel('L2 Distance')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "if min_dist > 0.05:\n",
    "    print(\"PASSED: No generated images are too close to training data.\")\n",
    "else:\n",
    "    print(\"WARNING: Some generated images may be memorized!\")"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Results"
   ],
   "id": "cell_20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Row 1: Real vs Generated\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(3, 8, i + 1)\n",
    "    ax.imshow(dataset.images[i].squeeze().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Real', fontsize=12)\n",
    "\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(3, 8, i + 9)\n",
    "    ax.imshow(generated[i].squeeze().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Generated', fontsize=12)\n",
    "\n",
    "# Row 3: Denoising process for one sample\n",
    "for col, idx in enumerate(np.linspace(0, len(snapshots) - 1, 8, dtype=int)):\n",
    "    ax = fig.add_subplot(3, 8, col + 17)\n",
    "    ax.imshow(snapshots[idx][0].squeeze().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "    if col == 0:\n",
    "        ax.set_ylabel('Process', fontsize=12)\n",
    "\n",
    "plt.suptitle('RadiSynth AI: Synthetic Brain MRI Generation Pipeline', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RadiSynth AI -- Results Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training data:       {len(dataset)} simulated MRI slices\")\n",
    "print(f\"Score network:       SimpleUNet ({n_params:,} parameters)\")\n",
    "print(f\"Noise levels:        {L} (geometric from {sigma_max} to {sigma_min})\")\n",
    "print(f\"Training epochs:     {n_epochs}\")\n",
    "print(f\"Final training loss: {losses[-1]:.4f}\")\n",
    "print(f\"Generated samples:   {len(eval_generated)}\")\n",
    "print(f\"Privacy check:       {'PASSED' if min_dist > 0.05 else 'FAILED'}\")\n",
    "print(f\"Approx FID:          {fid:.4f}\")"
   ],
   "id": "cell_21"
  }
 ]
}