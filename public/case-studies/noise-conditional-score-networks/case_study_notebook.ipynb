{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Noise Conditioned Score Networks Case Study -- Implementation Notebook"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Run this cell first!\n",
    "# Check GPU availability and install dependencies\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\u2705 GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Some cells may run slowly.\")\n",
    "    print(\"   Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "print(f\"\\n\ud83d\udce6 Python {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udd25 PyTorch {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\ud83c\udfb2 Random seed set to {SEED}\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "setup_cell"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerated MRI Reconstruction Using Score-Based Generative Priors -- Implementation Notebook\n",
    "\n",
    "## Case Study Overview\n",
    "\n",
    "In this notebook, we implement a simplified version of the MedScanAI ReconPrior system: using a Noise Conditioned Score Network (NCSN) as a learned prior for MRI image reconstruction from undersampled k-space data.\n",
    "\n",
    "We will work with a synthetic MRI-like dataset to demonstrate the core concepts, then outline how to extend this to real fastMRI data.\n",
    "\n",
    "## Setup and Dependencies"
   ],
   "id": "cell_1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "cell_2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1: Data -- Synthetic MRI-like Images"
   ],
   "id": "cell_3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_mri(n_samples=2000, size=64):\n",
    "    \"\"\"\n",
    "    Generate synthetic MRI-like images (ellipses on dark background).\n",
    "    These simulate simplified brain/knee cross-sections.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for _ in range(n_samples):\n",
    "        img = np.zeros((size, size), dtype=np.float32)\n",
    "        # Background ellipse (body/skull)\n",
    "        y, x = np.ogrid[-size//2:size//2, -size//2:size//2]\n",
    "        a, b = size//2 - 5, size//2 - 8\n",
    "        mask = (x**2 / a**2 + y**2 / b**2) <= 1\n",
    "        img[mask] = 0.3 + np.random.uniform(-0.05, 0.05)\n",
    "\n",
    "        # Internal structures (organs/tissues)\n",
    "        n_structures = np.random.randint(3, 7)\n",
    "        for _ in range(n_structures):\n",
    "            cx = np.random.randint(-size//4, size//4)\n",
    "            cy = np.random.randint(-size//4, size//4)\n",
    "            ra = np.random.randint(3, size//6)\n",
    "            rb = np.random.randint(3, size//6)\n",
    "            angle = np.random.uniform(0, np.pi)\n",
    "            intensity = np.random.uniform(0.4, 0.9)\n",
    "\n",
    "            cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "            xr = cos_a * (x - cx) + sin_a * (y - cy)\n",
    "            yr = -sin_a * (x - cx) + cos_a * (y - cy)\n",
    "            struct_mask = (xr**2 / ra**2 + yr**2 / rb**2) <= 1\n",
    "            img[struct_mask] = intensity\n",
    "\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Generate dataset\n",
    "train_images = generate_synthetic_mri(2000, size=64)\n",
    "test_images = generate_synthetic_mri(200, size=64)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(train_images[i], cmap='gray', vmin=0, vmax=1)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Synthetic MRI-like Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Training images: {train_images.shape}\")"
   ],
   "id": "cell_4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.2: EDA -- k-space and Undersampling"
   ],
   "id": "cell_5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_kspace(image):\n",
    "    \"\"\"Convert image to k-space (2D FFT).\"\"\"\n",
    "    return np.fft.fftshift(np.fft.fft2(image))\n",
    "\n",
    "def kspace_to_image(kspace):\n",
    "    \"\"\"Convert k-space to image (inverse 2D FFT).\"\"\"\n",
    "    return np.abs(np.fft.ifft2(np.fft.ifftshift(kspace)))\n",
    "\n",
    "def create_undersampling_mask(shape, acceleration=4, center_fraction=0.08):\n",
    "    \"\"\"Create random undersampling mask with fully-sampled center.\"\"\"\n",
    "    H, W = shape\n",
    "    mask = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    # Always sample center\n",
    "    center_width = int(W * center_fraction)\n",
    "    center_start = W // 2 - center_width // 2\n",
    "    mask[:, center_start:center_start + center_width] = 1\n",
    "\n",
    "    # Randomly sample remaining lines\n",
    "    n_total_lines = int(W / acceleration)\n",
    "    n_center_lines = center_width\n",
    "    n_random_lines = max(0, n_total_lines - n_center_lines)\n",
    "\n",
    "    available = list(set(range(W)) - set(range(center_start, center_start + center_width)))\n",
    "    if n_random_lines > 0 and len(available) > 0:\n",
    "        selected = np.random.choice(available, size=min(n_random_lines, len(available)), replace=False)\n",
    "        for s in selected:\n",
    "            mask[:, s] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Demonstrate undersampling\n",
    "img = train_images[0]\n",
    "kspace = image_to_kspace(img)\n",
    "mask_4x = create_undersampling_mask(img.shape, acceleration=4)\n",
    "mask_8x = create_undersampling_mask(img.shape, acceleration=8)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "axes[0, 0].imshow(img, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 1].imshow(np.log1p(np.abs(kspace)), cmap='gray')\n",
    "axes[0, 1].set_title('Full k-space (log)')\n",
    "axes[0, 2].imshow(mask_4x, cmap='gray')\n",
    "axes[0, 2].set_title(f'4x Mask ({mask_4x.mean()*100:.0f}% sampled)')\n",
    "axes[0, 3].imshow(mask_8x, cmap='gray')\n",
    "axes[0, 3].set_title(f'8x Mask ({mask_8x.mean()*100:.0f}% sampled)')\n",
    "\n",
    "recon_full = kspace_to_image(kspace)\n",
    "recon_4x = kspace_to_image(kspace * mask_4x)\n",
    "recon_8x = kspace_to_image(kspace * mask_8x)\n",
    "\n",
    "axes[1, 0].imshow(recon_full, cmap='gray')\n",
    "axes[1, 0].set_title('Full Recon')\n",
    "axes[1, 1].imshow(recon_4x, cmap='gray')\n",
    "axes[1, 1].set_title('4x Zero-filled')\n",
    "axes[1, 2].imshow(recon_8x, cmap='gray')\n",
    "axes[1, 2].set_title('8x Zero-filled')\n",
    "axes[1, 3].imshow(np.abs(recon_full - recon_4x), cmap='hot')\n",
    "axes[1, 3].set_title('4x Error Map')\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.3: Baseline -- Zero-Filled Reconstruction"
   ],
   "id": "cell_7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reconstruction(pred, target):\n",
    "    \"\"\"Compute PSNR and simple SSIM proxy.\"\"\"\n",
    "    mse = np.mean((pred - target) ** 2)\n",
    "    psnr = 10 * np.log10(target.max()**2 / (mse + 1e-10))\n",
    "\n",
    "    # Simple SSIM proxy\n",
    "    mu_p, mu_t = pred.mean(), target.mean()\n",
    "    sig_p, sig_t = pred.std(), target.std()\n",
    "    sig_pt = np.mean((pred - mu_p) * (target - mu_t))\n",
    "    c1, c2 = 0.01**2, 0.03**2\n",
    "    ssim = ((2*mu_p*mu_t + c1) * (2*sig_pt + c2)) / \\\n",
    "           ((mu_p**2 + mu_t**2 + c1) * (sig_p**2 + sig_t**2 + c2))\n",
    "\n",
    "    return {'psnr': psnr, 'ssim': ssim, 'mse': mse}\n",
    "\n",
    "# Baseline evaluation\n",
    "results_zf = []\n",
    "for img in test_images[:50]:\n",
    "    ks = image_to_kspace(img)\n",
    "    mask = create_undersampling_mask(img.shape, acceleration=4)\n",
    "    recon = kspace_to_image(ks * mask)\n",
    "    results_zf.append(evaluate_reconstruction(recon, img))\n",
    "\n",
    "mean_psnr = np.mean([r['psnr'] for r in results_zf])\n",
    "mean_ssim = np.mean([r['ssim'] for r in results_zf])\n",
    "print(f\"Zero-filled baseline (4x): PSNR={mean_psnr:.1f} dB, SSIM={mean_ssim:.3f}\")"
   ],
   "id": "cell_8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.4: NCSN Model for MRI"
   ],
   "id": "cell_9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIScoreNet(nn.Module):\n",
    "    \"\"\"Simple CNN-based score network for MRI images.\"\"\"\n",
    "    def __init__(self, n_noise_levels=50, base_ch=32):\n",
    "        super().__init__()\n",
    "        self.sigma_embed = nn.Embedding(n_noise_levels, base_ch)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, base_ch, 3, padding=1), nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, base_ch, 3, padding=1), nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, base_ch*2, 3, stride=2, padding=1), nn.SiLU(),\n",
    "            nn.Conv2d(base_ch*2, base_ch*2, 3, padding=1), nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(base_ch*2, base_ch*2, 3, padding=1), nn.SiLU(),\n",
    "            nn.Conv2d(base_ch*2, base_ch*2, 3, padding=1), nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_ch*2, base_ch, 4, stride=2, padding=1), nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, base_ch, 3, padding=1), nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, 1, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        # FiLM conditioning layers\n",
    "        self.film_scale = nn.Linear(base_ch, base_ch*2)\n",
    "        self.film_bias = nn.Linear(base_ch, base_ch*2)\n",
    "\n",
    "    def forward(self, x, sigma_idx):\n",
    "        emb = self.sigma_embed(sigma_idx)  # (B, base_ch)\n",
    "        scale = self.film_scale(emb).unsqueeze(-1).unsqueeze(-1)  # (B, 2*base_ch, 1, 1)\n",
    "        bias = self.film_bias(emb).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        h = h * (1 + scale) + bias  # FiLM conditioning\n",
    "        h = self.middle(h)\n",
    "        return self.decoder(h)\n",
    "\n",
    "model = MRIScoreNet(n_noise_levels=50).to(device)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "id": "cell_10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.5: Training"
   ],
   "id": "cell_11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images = torch.tensor(images, dtype=torch.float32).unsqueeze(1)  # (N,1,H,W)\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx]\n",
    "\n",
    "train_ds = MRIDataset(train_images)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# Noise schedule\n",
    "L = 50\n",
    "sigma_1, sigma_L = 1.0, 0.01\n",
    "sigmas = torch.tensor([sigma_1 * (sigma_L / sigma_1) ** (i / (L-1)) for i in range(L)]).to(device)\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dl:\n",
    "        batch = batch.to(device)\n",
    "        B = batch.shape[0]\n",
    "\n",
    "        # Random noise levels\n",
    "        idx = torch.randint(0, L, (B,), device=device)\n",
    "        sigma = sigmas[idx].view(B, 1, 1, 1)\n",
    "\n",
    "        # Add noise\n",
    "        epsilon = torch.randn_like(batch)\n",
    "        noisy = batch + sigma * epsilon\n",
    "        target = -epsilon / sigma\n",
    "\n",
    "        # Predict\n",
    "        pred = model(noisy, idx)\n",
    "        loss = (sigma.squeeze()**2 * (pred - target).flatten(1).pow(2).mean(1)).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_dl)\n",
    "    losses.append(epoch_loss)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/50, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('NCSN Training on MRI Data')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "cell_12"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.6: Reconstruction with Data Consistency"
   ],
   "id": "cell_13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncsn_mri_reconstruct(model, kspace, mask, sigmas, n_steps=50, eps=5e-5):\n",
    "    \"\"\"Reconstruct MRI using NCSN + ALD + data consistency.\"\"\"\n",
    "    model.eval()\n",
    "    H, W = kspace.shape\n",
    "\n",
    "    # Initialize from zero-filled\n",
    "    x = torch.tensor(kspace_to_image(kspace * mask), dtype=torch.float32)\n",
    "    x = x.unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, H, W)\n",
    "\n",
    "    kspace_torch = torch.tensor(kspace, dtype=torch.complex64).to(device)\n",
    "    mask_torch = torch.tensor(mask, dtype=torch.float32).to(device)\n",
    "\n",
    "    sigma_L = sigmas[-1].item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, sigma_val in enumerate(sigmas):\n",
    "            alpha = eps * (sigma_val.item() / sigma_L) ** 2\n",
    "            sigma_idx = torch.tensor([i], device=device)\n",
    "\n",
    "            for t in range(n_steps):\n",
    "                # Score update\n",
    "                score = model(x, sigma_idx)\n",
    "                noise = torch.randn_like(x)\n",
    "                x = x + alpha * score + (2 * alpha) ** 0.5 * noise\n",
    "\n",
    "                # Data consistency: replace measured k-space lines\n",
    "                x_np = x.squeeze().cpu().numpy()\n",
    "                x_kspace = np.fft.fftshift(np.fft.fft2(x_np))\n",
    "                # Replace measured frequencies with actual measurements\n",
    "                x_kspace = x_kspace * (1 - mask) + kspace * mask\n",
    "                x_recon = np.abs(np.fft.ifft2(np.fft.ifftshift(x_kspace)))\n",
    "                x = torch.tensor(x_recon, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    return x.squeeze().cpu().numpy()\n",
    "\n",
    "# Test reconstruction\n",
    "test_img = test_images[0]\n",
    "test_ks = image_to_kspace(test_img)\n",
    "test_mask = create_undersampling_mask(test_img.shape, acceleration=4)\n",
    "\n",
    "recon_ncsn = ncsn_mri_reconstruct(model, test_ks, test_mask, sigmas, n_steps=30, eps=1e-5)\n",
    "recon_zf = kspace_to_image(test_ks * test_mask)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axes[0].imshow(test_img, cmap='gray')\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[1].imshow(recon_zf, cmap='gray')\n",
    "axes[1].set_title(f'Zero-filled\\nSSIM={evaluate_reconstruction(recon_zf, test_img)[\"ssim\"]:.3f}')\n",
    "axes[2].imshow(recon_ncsn, cmap='gray')\n",
    "axes[2].set_title(f'NCSN Recon\\nSSIM={evaluate_reconstruction(recon_ncsn, test_img)[\"ssim\"]:.3f}')\n",
    "axes[3].imshow(np.abs(test_img - recon_ncsn), cmap='hot', vmax=0.3)\n",
    "axes[3].set_title('NCSN Error')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cell_14"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.7: Error Analysis"
   ],
   "id": "cell_15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate across test set and analyze failure modes\n",
    "def batch_evaluate(model, test_images, sigmas, acceleration=4, n_eval=50):\n",
    "    \"\"\"\n",
    "    Evaluate NCSN reconstruction on multiple test images.\n",
    "\n",
    "    Returns per-image metrics and identifies failure cases.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i in range(min(n_eval, len(test_images))):\n",
    "        img = test_images[i]\n",
    "        ks = image_to_kspace(img)\n",
    "        mask = create_undersampling_mask(img.shape, acceleration=acceleration)\n",
    "\n",
    "        recon_zf = kspace_to_image(ks * mask)\n",
    "        recon_ncsn = ncsn_mri_reconstruct(model, ks, mask, sigmas, n_steps=20, eps=1e-5)\n",
    "\n",
    "        metrics_zf = evaluate_reconstruction(recon_zf, img)\n",
    "        metrics_ncsn = evaluate_reconstruction(recon_ncsn, img)\n",
    "        results.append({\n",
    "            'idx': i,\n",
    "            'zf_ssim': metrics_zf['ssim'],\n",
    "            'ncsn_ssim': metrics_ncsn['ssim'],\n",
    "            'improvement': metrics_ncsn['ssim'] - metrics_zf['ssim']\n",
    "        })\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Evaluated {i+1}/{n_eval}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# results = batch_evaluate(model, test_images, sigmas)"
   ],
   "id": "cell_16"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.8: Deployment Benchmarking"
   ],
   "id": "cell_17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark inference speed\n",
    "def benchmark_speed(model, sigmas, image_size=64, n_warmup=3, n_runs=10):\n",
    "    \"\"\"\n",
    "    Measure reconstruction speed.\n",
    "\n",
    "    Args:\n",
    "        model: trained MRIScoreNet\n",
    "        sigmas: noise levels\n",
    "        image_size: image dimension\n",
    "        n_warmup: warmup runs (excluded)\n",
    "        n_runs: timed runs\n",
    "\n",
    "    Report: mean and std of reconstruction time per image.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ],
   "id": "cell_18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.9: Ethics Considerations"
   ],
   "id": "cell_19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion cell -- no code needed\n",
    "print(\"\"\"\n",
    "Ethics and Safety Considerations for AI-Accelerated MRI Reconstruction:\n",
    "\n",
    "1. DIAGNOSTIC SAFETY: AI-reconstructed images must not introduce false anatomical\n",
    "   features (hallucinations) that could lead to misdiagnosis. Score-based methods\n",
    "   are less prone to this than direct mapping networks because they combine a\n",
    "   learned prior with data consistency constraints.\n",
    "\n",
    "2. FAILURE MODES: The system must detect when reconstruction quality is insufficient\n",
    "   and flag the case for re-scanning rather than presenting a poor reconstruction\n",
    "   to the radiologist.\n",
    "\n",
    "3. EQUITY: Reconstruction quality must be consistent across patient demographics.\n",
    "   Training data must be representative of the patient population.\n",
    "\n",
    "4. TRANSPARENCY: Radiologists must be informed when AI-assisted reconstruction\n",
    "   was used and have access to the zero-filled baseline for comparison.\n",
    "\n",
    "5. REGULATORY: FDA 510(k) clearance requires extensive clinical validation\n",
    "   demonstrating substantial equivalence to existing reconstruction methods.\n",
    "\"\"\")"
   ],
   "id": "cell_20"
  }
 ]
}